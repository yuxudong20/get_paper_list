M. Yuan, X. Huang, K. Fu, Z. Li and M. Wang, "Boosting 3D Point Cloud Registration by Transferring Multi-modality Knowledge," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11734-11741, doi: 10.1109/ICRA48891.2023.10161411.Abstract: The recent multi-modality models have achieved great performance in many vision tasks because the extracted features contain the multi-modality knowledge. However, most of the current registration descriptors have only concentrated on local geometric structures. This paper proposes a method to boost point cloud registration accuracy by transferring the multi-modality knowledge of pre-trained multi-modality model to a new descriptor neural network. Different to the previous multi-modality methods that requires both modalities, the proposed method only requires point clouds during inference. Specifically, we propose an ensemble descriptor neural network combining pre-trained sparse convolution branch and a new point-based convolution branch. By fine-tuning on a single modality data, the proposed method achieves new state-of-the-art results on 3DMatch and competitive accuracy on 3DLoMatch and KITTI. The code and the trained model will be released at https://github.com/phdymz/DBENet.git. keywords: {Point cloud compression;Knowledge engineering;Three-dimensional displays;Codes;Convolution;Neural networks;Feature extraction},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161411&isnumber=10160212

Z. Zang, H. Zheng, J. Betz and R. Mangharam, "Local_INN: Implicit Map Representation and Localization with Invertible Neural Networks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11742-11748, doi: 10.1109/ICRA48891.2023.10161015.Abstract: Robot localization is an inverse problem of finding a robot's pose using a map and sensor measurements. In recent years, Invertible Neural Networks (INN s) have successfully solved ambiguous inverse problems in various fields. This paper proposes a framework that approaches the localization problem with INN. We design a network that provides implicit map representation in the forward path and localization in the inverse path. By sampling the latent space in evaluation, Local_INN outputs robot poses with covariance, which can be used to estimate the uncertainty. We show that the localization performance of Local_INN is on par with current methods with much lower latency. We show detailed 2D and 3D map reconstruction from Local_INN using poses exterior to the training set. We also provide a global localization algorithm using Local_INN to tackle the kidnapping problem. keywords: {Location awareness;Training;Uncertainty;Three-dimensional displays;Inverse problems;Soft sensors;Neural networks},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161015&isnumber=10160212

J. Ruan, L. He, Y. Guan and H. Zhang, "Combining Scene Coordinate Regression and Absolute Pose Regression for Visual Relocalization," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11749-11755, doi: 10.1109/ICRA48891.2023.10160317.Abstract: Visual relocalization is a fundamental problem in computer vision and robotics. Recently, regression-based methods become popular and they can be categorized into two classes: absolute pose regression and scene coordinate regression. In this work, we present a combined regression network that jointly learns scene coordinate regression and absolute pose regression for single-image visual relocalization. The proposed network composes of a feature encoder and two regression branches with uncertainty modeling. In particular, we design a deep feature conditioning module, aiming at propagating the coarse pose information in absolute pose regression to inform the predictions in scene coordinate regression. The proposed network is trained in an end-to-end fashion to learn both regression tasks. Moreover, we propose an uncertainty-driven RANSAC algorithm that incorporates the predicted scene coordinates and their uncertainties to solve the camera pose during inference. To the best of our knowledge, this work is the first to combine scene coordinate regression and pose regression in a hierarchical framework for visual relocalization. Experiments on indoor and outdoor benchmarks demonstrate the effectiveness and the superiority of the proposed method over the state-of-the-art methods. keywords: {Visualization;Computer vision;Uncertainty;Robot kinematics;Benchmark testing;Predictive models;Prediction algorithms},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160317&isnumber=10160212

H. Damirchi, R. Khorrambakht, H. D. Taghirad and B. Moshiri, "A Consistency-Based Loss for Deep Odometry Through Uncertainty Propagation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11756-11762, doi: 10.1109/ICRA48891.2023.10160954.Abstract: Conventionally, deep odometry networks use objective functions that only penalize short-term deviations from the true path. Since such an objective does not impose any constraints on the long-term deviations from the path, a second consistency-based loss term may be added to lower long-term drift. However, maintaining a balance between the two loss terms is challenging and often treated as a design hyperparameter. To mitigate this balancing issue, we propose to use the uncertainty over both odometry and the long-term transformations in a maximum likelihood setting and allow the network to tune the weighting between the two loss terms. To this end, we derive the odometry uncertainty alongside the pose outputs using the network itself and to derive the covariance matrix over the integrated transformation, we propose to propagate the odometry uncertainty through each iteration. This formulation provides an adaptive and statistically consistent method to weigh the incremental and integrated loss terms against each other, noting the increase in uncertainty as more steps are integrated over. We show that our approach to consistency-based losses allows the network to surpass the accuracy of the state-of-the-art visual odometry approaches. Then, the efficacy of the derived uncertainty as weighting medium is visualized and the performance benefits of uncertainty quantification are shown in a pose-graph based localization scenario. keywords: {Location awareness;Visualization;Maximum likelihood estimation;Uncertainty;Automation;Propagation losses;Linear programming},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160954&isnumber=10160212

M. Ibrahim, N. Akhtar, S. Anwar, M. Wise and A. Mian, "Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11763-11770, doi: 10.1109/ICRA48891.2023.10161128.Abstract: Precise localization is critical for autonomous vehicles. We present a self-supervised learning method that employs transformers for the first time for the task of outdoor localization using LiDAR data. We propose a pre-text task that reorganizes the slices of a 360° LiDAR scan to leverage its axial properties. Our model, called Slice Transformer, employs multi-head attention while systematically processing the slices. To the best of our knowledge, this is the first instance of leveraging multi-head attention for outdoor point clouds. We additionally introduce the Perth-Wadataset, which provides a large-scale LiDAR map of Perth city in Western Australia, covering ~4km2area. Localization annotations are provided for Perth - Wa.The proposed localization method is thoroughly evaluated on Perth-WA and Appollo-SouthBay datasets. We also establish the efficacy of our self-supervised learning approach for the common downstream task of object classification using ModelNet40 and ScanNN datasets. The code and Perth-WA data will be publicly released. keywords: {Location awareness;Point cloud compression;Laser radar;Annotations;Urban areas;Self-supervised learning;Transformers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161128&isnumber=10160212

F. Lu, L. Zhang, S. Dong, B. Chen and C. Yuan, "AANet: Aggregation and Alignment Network with Semi-hard Positive Sample Mining for Hierarchical Place Recognition," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11771-11778, doi: 10.1109/ICRA48891.2023.10160734.Abstract: Visual place recognition (VPR) is one of the research hotspots in robotics, which uses visual information to locate robots. Recently, the hierarchical two-stage VPR methods have become popular in this field due to the trade-off between accuracy and efficiency. These methods retrieve the top-k candidate images using the global features in the first stage, then re-rank the candidates by matching the local features in the second stage. However, they usually require additional al-gorithms (e.g. RANSAC) for geometric consistency verification in re-ranking, which is time-consuming. Here we propose a Dynamically Aligning Local Features (DALF) algorithm to align the local features under spatial constraints. It is significantly more efficient than the methods that need geometric consistency verification. We present a unified network capable of extracting global features for retrieving candidates via an aggregation module and aligning local features for re-ranking via the DALF alignment module. We call this network AANet. Meanwhile, many works use the simplest positive samples in triplet for weakly supervised training, which limits the ability of the network to recognize harder positive pairs. To address this issue, we propose a Semi-hard Positive Sample Mining (ShPSM) strategy to select appropriate hard positive images for training more robust VPR networks. Extensive experiments on four benchmark VPR datasets show that the proposed AANet can outperform several state-of-the-art methods with less time consumption. The code is released at https://github.com/Lu-Feng/AANet. keywords: {Training;Visualization;Codes;Automation;Heuristic algorithms;Computer architecture;Benchmark testing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160734&isnumber=10160212

S. Adebola et al., "Can Machines Garden? Systematically Comparing the AlphaGarden vs. Professional Horticulturalists," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11779-11785, doi: 10.1109/ICRA48891.2023.10161497.Abstract: The AlphaGarden is an automated testbed for indoor polyculture farming which combines a first-order plant simulator, a gantry robot, a seed planting algorithm, plant phenotyping and tracking algorithms, irrigation sensors and algorithms, and custom pruning tools and algorithms. In this paper, we systematically compare the performance of the AlphaGarden to professional horticulturalists on the staff of the UC Berkeley Oxford Tract Greenhouse. The humans and the machine tend side-by-side polyculture gardens with the same seed arrangement. We compare performance in terms of canopy coverage, plant diversity, and water consumption. Results from two 60-day cycles suggest that the automated AlphaGarden performs comparably to professional horticulturalists in terms of coverage and diversity, and reduces water consumption by as much as 44%. Code, videos, and datasets are available at https//sites.google.com/berkeley.edulsystematiccomparison keywords: {Irrigation;Automation;Robot sensing systems;Seeds (agriculture);Sensors;Videos;Farming},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161497&isnumber=10160212

G. Roggiolani et al., "On Domain-Specific Pre- Training for Effective Semantic Perception in Agricultural Robotics," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11786-11793, doi: 10.1109/ICRA48891.2023.10160624.Abstract: Agricultural robots have the prospect to enable more efficient and sustainable agricultural production of food, feed, and fiber. Perception of crops and weeds is a central component of agricultural robots that aim to monitor fields and assess the plants as well as their growth stage in an automatic manner. Semantic perception mostly relies on deep learning using supervised approaches, which require time and qualified workers to label fairly large amounts of data. In this paper, we look into the problem of reducing the amount of labels without compromising the final segmentation performance. For robots operating in the field, pre-training networks in a supervised way is already a popular method to reduce the number of required labeled images. We investigate the possibility of pre-training in a self-supervised fashion using data from the target domain. To better exploit this data, we propose a set of domain-specific augmentation strategies. We evaluate our pre-training on semantic segmentation and leaf instance segmentation, two important tasks in our domain. The experimental results suggest that pre-training with domain-specific data paired with our data augmentation strategy leads to superior performance compared to commonly used pre-trainings. Furthermore, the pre-trained networks obtain similar performance to the fully supervised with less labeled data. keywords: {Training;Agricultural robots;Semantic segmentation;Plants (biology);Semantics;Production;Optical fiber networks},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160624&isnumber=10160212

R. Falque, T. Vidal-Calleja and A. Alempijevic, "Semantic Keypoint Extraction for Scanned Animals using Multi-Depth-Camera Systems," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11794-11801, doi: 10.1109/ICRA48891.2023.10160307.Abstract: Keypoint annotation in pointclouds is an important task for 3D reconstruction, object tracking and alignment, in particular in deformable or moving scenes. In the context of agriculture robotics, it is a critical task for livestock automation to work toward condition assessment or behaviour recognition. In this work, we propose a novel approach for semantic keypoint annotation in pointclouds, by reformulating the keypoint extraction as a regression problem of the distance between the keypoints and the rest of the pointcloud. We use the distance on the pointcloud manifold mapped into a radial basis function (RBF), which is then learned using an encoder-decoder architecture. Special consideration is given to the data augmentation specific to multi-depth-camera systems by considering noise over the extrinsic calibration and camera frame dropout. Additionally, we investigate computationally efficient non-rigid deformation methods that can be applied to animal pointclouds. Our method is tested on data collected in the field, on moving beef cattle, with a calibrated system of multiple hardware-synchronised RGB-D cameras. keywords: {Manifolds;Three-dimensional displays;Annotations;Animals;Deformation;Semantics;Cameras;3D deep learning;keypoints annotation;multi-depth-camera systems;livestock},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160307&isnumber=10160212

E. Ayoub, P. Levesque and I. Sharf, "Grasp Planning with CNN for Log-loading Forestry Machine," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11802-11808, doi: 10.1109/ICRA48891.2023.10161562.Abstract: Log loading constitutes a key operation in timber harvesting, and despite the recent spike of interest in introducing automation to the forestry sector, efficient and intelligent grasping of logs remains unresolved. This paper presents a grasp planning pipeline that relies on the identification of logs' characteristics and pose in the environment of a log-loading machine, to generate high quality grasps. The proposed pipeline involves replicating identified logs in a virtual environment where grasp planning is carried out by using a convolutional neural network and a virtual depth camera. The network relies solely on depth information and the virtual camera can be positioned at a strategically selected location or to follow a certain trajectory to enhance exposure of the logs, all this without having to move the log-loader's crane. The grasp planning pipeline is evaluated through simulated grasping trials and experiments on a large-scale log-loading test-bed with several configurations of wood logs ranging from a single to multiple logs. The grasp planning pipeline proved to be successful with a grasping rate of 98.33 % in the simulated trials and 96.67 % in the experimental trials. The grasp planner was able to overcome log characterization and localization uncertainties, thus allowing the log-loader to pick individual logs, and multiple logs at once when possible. keywords: {Training;Uncertainty;Automation;Pipelines;Virtual environments;Grasping;Forestry},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161562&isnumber=10160212

G. Chen, H. Muriki, A. Sharkey, C. Pradalier, Y. Chen and F. Dellaert, "A Hybrid Cable-Driven Robot for Non-Destructive Leafy Plant Monitoring and Mass Estimation using Structure from Motion," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11809-11816, doi: 10.1109/ICRA48891.2023.10161045.Abstract: We propose a novel hybrid cable-based robot with manipulator and camera for high-accuracy, medium-throughput plant monitoring in a vertical hydroponic farm and, as an example application, demonstrate non-destructive plant mass estimation. Plant monitoring with high temporal and spatial resolution is important to both farmers and researchers to detect anomalies and develop predictive models for plant growth. The availability of high-quality, off-the-shelf structure-from-motion (SfM) and photogrammetry packages has enabled a vibrant community of roboticists to apply computer vision for non-destructive plant monitoring. While existing approaches tend to focus on either high-throughput (e.g. satellite, unmanned aerial vehicle (UAV), vehicle-mounted, conveyor-belt imagery) or high-accuracy/robustness to occlusions (e.g. turn-table scanner or robot arm), we propose a middle-ground that achieves high accuracy with a medium-throughput, highly automated robot. Our design pairs the workspace scalability of a cable-driven parallel robot (CDPR) with the dexterity of a 4 degree-of-freedom (DoF) robot arm to autonomously image many plants from a variety of viewpoints. We describe our robot design and demonstrate it experimentally by collecting daily photographs of 54 plants from 64 viewpoints each. We show that our approach can produce scientifically useful measurements, operate fully autonomously after initial calibration, and produce better reconstructions and plant property estimates than those of over-canopy methods (e.g. UAV). As example applications, we show that our system can successfully estimate plant mass with a Mean Absolute Error (MAE) of 0.586g and, when used to perform hypothesis testing on the relationship between mass and age, produces p-values comparable to ground-truth data (p=0.0020 and p=0.0016, respectively). keywords: {Structure from motion;Satellites;Scalability;Estimation;Manipulators;Autonomous aerial vehicles;Spatial resolution},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161045&isnumber=10160212

J. C. Choton and P. Prabhakar, "Optimal Multi-Robot Coverage Path Planning for Agricultural Fields using Motion Dynamics," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11817-11823, doi: 10.1109/ICRA48891.2023.10160265.Abstract: Coverage path planning (CPP) is the task of computing an optimal path within a region to completely scan or survey the area of interest by using robotic sensor footprints. In this work, we propose a novel approach to find the multi-robot optimal coverage path of an agricultural field using motion dynamics while minimizing the mission time. Our approach consists of three steps: (i) divide the agricultural field into convex polygonal areas to optimally distribute them among the robots, (ii) generate an optimal coverage path to ensure minimum coverage time for each of the polygonal areas, and (iii) generate the trajectory for each coverage path using Dubins motion dynamics. Several experiments and simulations were performed to check the validity and feasibility of our approach, and the results and limitations are discussed. keywords: {Surveys;Heuristic algorithms;Dynamics;Merging;Aerospace electronics;Robot sensing systems;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160265&isnumber=10160212

M. V. Gasparino, V. A. H. Higuti, A. N. Sivakumar, A. E. B. Velasquez, M. Becker and G. Chowdhary, "CropNav: a Framework for Autonomous Navigation in Real Farms," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11824-11830, doi: 10.1109/ICRA48891.2023.10160990.Abstract: Small robots that can operate under the plant canopy can enable new possibilities in agriculture. However, unlike larger autonomous tractors, autonomous navigation for such under canopy robots remains an open challenge because Global Navigation Satellite System (GNSS) is unreliable under the plant canopy. We present a hybrid navigation system that autonomously switches between different sets of sensing modalities to enable full field navigation, both inside and outside of crop. By choosing the appropriate path reference source, the robot can accommodate for loss of GNSS signal quality and leverage row-crop structure to autonomously navigate. However, such switching can be tricky and difficult to execute over scale. Our system provides a solution by automatically switching between an exteroceptive sensing based system, such as Light Detection And Ranging (LiDAR) row-following navigation and waypoints path tracking. In addition, we show how our system can detect when the navigate fails and recover automatically extending the autonomous time and mitigating the necessity of human intervention. Our system shows an improvement of about 750 m per intervention over GNSS-based navigation and 500 m over row following navigation. keywords: {Global navigation satellite system;Plants (biology);Crops;Switches;Predictive models;Robot sensing systems;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160990&isnumber=10160212

A. Qiu, C. Young, A. L. Gunderman, M. Azizkhani, Y. Chen and A. -P. Hu, "Tendon-Driven Soft Robotic Gripper with Integrated Ripeness Sensing for Blackberry Harvesting," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11831-11837, doi: 10.1109/ICRA48891.2023.10160893.Abstract: Growing global demand for food, coupled with continuing labor shortages, motivate the need for automated agricultural harvesting. While some specialty crops (e.g., apples, peaches, blueberries) can be harvested via existing harvesting modalities, fruits such as blackberries and raspberries require delicate handling to mitigate fruit damage that could significantly impact marketability. This motivates the development of soft robotic solutions that enable efficient, delicate harvesting. This paper presents the design, fabrication, and feasibility testing of a tendon-driven soft gripping system focused on blackberries, which are a fragile fruit susceptible to post-harvest damage. The gripper is low-cost and small form factor, allowing for the integration of a micro-servo for tendon retraction, a near-infrared (NIR) based blackberry ripeness sensor utilizing the reflectance modality for identifying fully ripe blackberries, and an endoscopic camera for visual servoing. The gripper was used to harvest 139 berries with manual positioning in two separate field tests. Field testing found an average retention force of 2.06 N and 6.08 N for ripe and unripe blackberries, respectively. Sensor tests identified an average reflectance of 16.78 and 21.70 for ripe and unripe blackberries, respectively, indicating a clear distinction between the two ripeness levels. Finally, the soft robotic gripper was integrated onto a UR5 robot arm and successfully harvested fifteen artificial blackberries in a lab setting using visual servoing. keywords: {Reflectivity;Force;Personal digital devices;Soft robotics;Robot sensing systems;Manipulators;Visual servoing;Soft Robotics;Agricultural Automation;Soft Grippers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160893&isnumber=10160212

S. Newdick, N. Ongole, T. G. Chen, E. Schmerling, M. R. Cutkosky and M. Pavone, "Motion Planning for a Climbing Robot with Stochastic Grasps," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11838-11844, doi: 10.1109/ICRA48891.2023.10160218.Abstract: ReachBot is a robot that uses extendable and retractable booms as limbs to move around unpredictable environments such as martian caves. Each boom is capped by a microspine gripper designed for grasping rocky surfaces. Motion planning for ReachBot must be versatile to accommo-date variable terrain features and robust to mitigate risks from the stochastic nature of grasping with spines. In this paper, we introduce a graph traversal algorithm to select a discrete sequence of grasps based on available terrain features suitable for grasping. This discrete plan is complemented by a decoupled motion planner that considers the alternating phases of body movement and end-effector movement, using a combination of sampling-based planning and sequential convex programming to optimize individual phases. We use our motion planner to plan a trajectory across a simulated 2D cave environment with at least 90% probability of success and demonstrate improved robustness over a baseline trajectory. Finally, we use a simplified prototype to verify a body movement trajectory generated by our motion planning algorithm. keywords: {Solid modeling;Three-dimensional displays;Stochastic processes;Prototypes;Grasping;Robustness;Hardware},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160218&isnumber=10160212

W. F. R. Ribeiro, K. Uno, M. Imai, K. Murase and K. Yoshida, "RAMP: Reaction-Aware Motion Planning of Multi-Legged Robots for Locomotion in Microgravity," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11845-11851, doi: 10.1109/ICRA48891.2023.10161185.Abstract: Robotic mobility in microgravity is necessary to expand human utilization and exploration of outer space. Bio-inspired multi-legged robots are a possible solution for safe and precise locomotion. However, a dynamic motion of a robot in microgravity can lead to failures due to gripper detachment caused by excessive motion reactions. We propose a novel Reaction-Aware Motion Planning (RAMP) to improve locomotion safety in microgravity, decreasing the risk of losing contact with the terrain surface by reducing the robot's momentum change. RAMP minimizes the swing momentum with a Low-Reaction Swing Trajectory (LRST) while distributing this momentum to the whole body, ensuring zero velocity for the supporting grippers and minimizing motion reactions. We verify the proposed approach with dynamic simulations indicating the capability of RAMP to generate a safe motion without detachment of the supporting grippers, resulting in the robot reaching its specified location. We further validate RAMP in experiments with an air-floating system, demonstrating a significant reduction in reaction forces and improved mobility in microgravity. keywords: {Legged locomotion;Automation;Dynamics;Numerical simulation;Planning;Trajectory;Space exploration},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161185&isnumber=10160212

M. Endo, T. Taniai, R. Yonetani and G. Ishigami, "Risk-aware Path Planning via Probabilistic Fusion of Traversability Prediction for Planetary Rovers on Heterogeneous Terrains," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11852-11858, doi: 10.1109/ICRA48891.2023.10161466.Abstract: Machine learning (ML) plays a crucial role in assessing traversability for autonomous rover operations on deformable terrains but suffers from inevitable prediction errors. Especially for heterogeneous terrains where the geological features vary from place to place, erroneous traversability prediction can become more apparent, increasing the risk of unrecoverable rover's wheel slip and immobilization. In this work, we propose a new path planning algorithm that explicitly accounts for such erroneous prediction. The key idea is the probabilistic fusion of distinctive ML models for terrain type classification and slip prediction into a single distribution. This gives us a multimodal slip distribution accounting for heterogeneous terrains and further allows statistical risk assessment to be applied to derive risk-aware traversing costs for path planning. Extensive simulation experiments have demonstrated that the proposed method is able to generate more feasible paths on heterogeneous terrains compared to existing methods. keywords: {Space vehicles;Uncertainty;Wheels;Predictive models;Prediction algorithms;Probabilistic logic;Path planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161466&isnumber=10160212

M. De Stefano, R. Vijayan, A. Stemmer, F. Elhardt and C. Ott, "A Gravity Compensation Strategy for On-ground Validation of Orbital Manipulators," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11859-11865, doi: 10.1109/ICRA48891.2023.10161480.Abstract: The on-ground validation of orbital manipulators is a challenging task because the robot is designed for a gravity-free operational environment, but it is validated under the effect of gravity. As a consequence, joint torque limits can be easily reached in certain configurations when gravity is actively compensated by the joints. Hence, the workspace for on-ground testing is restricted. In this paper, an optimal strategy is proposed for achieving gravity compensation of an orbital manipulator arm on ground. The strategy minimizes the joint torques acting on the manipulator by solving an optimization problem and it computes the necessary forces to be tracked by an external carrier. Hence, full gravity compensation is achieved for the orbital manipulator. Experimental results validate the effectiveness of the method on the DLR CAESAR space robot, which uses a cable suspended system as external carrier to track the desired gravity compensation force, resulting from the proposed method. keywords: {Space vehicles;Torque;Automation;Arms;Manipulators;Orbits;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161480&isnumber=10160212

M. Jawaid, E. Elms, Y. Latif and T. -J. Chin, "Towards Bridging the Space Domain Gap for Satellite Pose Estimation using Event Sensing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11866-11873, doi: 10.1109/ICRA48891.2023.10160531.Abstract: Deep models trained using synthetic data require domain adaptation to bridge the gap between the simulation and target environments. State-of-the-art domain adaptation methods often demand sufficient amounts of (unlabelled) data from the target domain. However, this need is difficult to fulfil when the target domain is an extreme environment, such as space. In this paper, our target problem is close proximity satellite pose estimation, where it is costly to obtain images of satellites from actual rendezvous missions. We demonstrate that event sensing offers a promising solution to generalise from the simulation to the target domain under stark illumination differences. Our main contribution is an event-based satellite pose estimation technique, trained purely on synthetic event data with basic data augmentation to improve robustness against practical (noisy) event sensors. Underpinning our method is a novel dataset with carefully calibrated ground truth, comprising of real event data obtained by emulating satellite rendezvous scenarios in the lab under drastic lighting conditions. Results on the dataset showed that our event-based satellite pose estimation method, trained only on synthetic data without adaptation, could generalise to the target domain effectively. keywords: {Adaptation models;Satellites;Pose estimation;Lighting;Robot sensing systems;Robustness;Data models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160531&isnumber=10160212

D. Hirano, S. Mitani, T. Nishishita and T. Saito, "Hardware-in-the-Loop Simulator with Low-Thrust Actuator for Free-Flying Robot's Omni-Directional Control," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11874-11879, doi: 10.1109/ICRA48891.2023.10161499.Abstract: Small free-flying robots to assist astronauts and perform experiments need a propulsion system to move freely in microgravity. Hardware-in-the-loop (HIL) simulators can simultaneously verify guidance, navigation, and control (GNC) systems, including flight hardware and software, in three dimensions. However, it is difficult to incorporate a small free-flying robot into the HIL simulator because of the low propulsive force and gravity compensation associated with its attitude changes. This paper proposes a HIL simulator with a propulsion subsystem mounted on a statically fixed force/torque sensor and a GNC subsystem mounted on a dynamically movable robotic arm. This simulator allows us to verify the GNC algorithms comprehensively using actual navigation sensors and propulsive actuators in an emulated flight environment. The actual capabilities of this simulator were successfully demonstrated in motion verifications of a free-flying robot, the Int-Ball2. keywords: {Actuators;Solid modeling;Navigation;Software algorithms;Propulsion;Robot sensing systems;Manipulators},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161499&isnumber=10160212

J. Wanner, E. Sihite, A. Ramezani and M. Gharib, "Loitering and Trajectory Tracking of Suspended Payloads in Cable-Driven Balloons Using UGVs," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11880-11886, doi: 10.1109/ICRA48891.2023.10160696.Abstract: Investigations of unmanned aerial vehicles (UAV s) for planetary exploration and payload manipulation have become a strong focus of research within space robotics. Among possible solutions, balloon-based systems possess merits that make them extremely attractive, such as their simple operation mechanism and endured operation time. However, there are many hurdles to overcome to achieve robust trajectory tracking performance for balloon-based applications. In this work, in order to facilitate the control and versatile use of balloons for near-surface planetary payload manipulation, a novel robotic platform and control strategy featuring the coordinated servoing of multiple unmanned ground vehicles (UGVs) to actuate a cable-driven balloon and the suspended payload is proposed. An earthbound prototype and dynamic model of this system are designed to allow for the investigation of payload trajectory tracking performance using a tailored Model Predictive Controller in simulation and experiment. keywords: {Uncertainty;Trajectory tracking;Robot kinematics;Prototypes;Computer architecture;Predictive models;Autonomous aerial vehicles},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160696&isnumber=10160212

E. M. Hoffman et al., "Design and Validation of a Multi-Arm Relocatable Manipulator for Space Applications," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11887-11893, doi: 10.1109/ICRA48891.2023.10160389.Abstract: This work presents the computational design and validation of the Multi-Arm Relocatable Manipulator (MARM), a three-limb robot for space applications, with particular reference to the MIRROR (i.e., the Multi-arm Installation Robot for Readying ORUs and Reflectors) use-case scenario as proposed by the European Space Agency. A holistic computational design and validation pipeline is proposed, with the aim of comparing different limb designs, as well as ensuring that valid limb candidates enable MARM to perform the complex loco-manipulation tasks required. Moti-vated by the task complexity in terms of kinematic reachability, (self)-collision avoidance, contact wrench limits, and motor torque limits affecting Earth experiments, this work leverages on multiple state-of-art planning and control approaches to aid the robot design and validation. These include sampling-based planning on manifolds, non-linear trajectory optimization, and quadratic programs for inverse dynamics computations with constraints. Finally, we present the attained MARM design and conduct preliminary tests for hardware validation through a set of lab experiments. keywords: {Torque;Tracking;Pipelines;European Space Agency;Kinematics;Hardware;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160389&isnumber=10160212

J. Mrázek, P. Ondika, I. Černá and J. Barnat, "Tentacle-Based Shape Shifting of Metamorphic Robots Using Fast Inverse Kinematics," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11894-11900, doi: 10.1109/ICRA48891.2023.10160352.Abstract: We present a new approach to tackle the problem of metamorphic robots' reconfiguration. Given the chain-type metamorphic robot's initial and target configuration, we compute a reconfiguration plan that is provably physically collision-free. Our solution employs a specific heuristic. The robot initially reconfigures to a shape that resembles an octopus with many tentacles. After that, the tentacles gradually reconnect to each other using inverse kinematics, separating one tentacle from the body and keeping the other one connected. This strategy eventually leads to a snake-like structure of the robot. For the target configuration, we compute the reconfiguration plan with the same procedure, however, we reverse the plan to reconfigure the robot from the snake-like structure to the target shape. According to our experimental evaluation, our newly introduced strategy for finding reconfiguration plans is successful. It efficiently finds collision-free plans even for robots consisting of hundreds of modules. keywords: {Automation;Shape;Kinematics;Computational efficiency;Collision avoidance;Computer crime;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160352&isnumber=10160212

O. Wali, M. T. Shahab and E. Feron, "A Non-planar Assembly of Modular Tetrahedral-shaped Aerial Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11901-11907, doi: 10.1109/ICRA48891.2023.10161301.Abstract: This paper presents a new design of aerial vehicles with tetrahedral geometry. We call this design the TetraQuad. The TetraQuad is a fractal modular aerial robot. A characteristic of fractals is that they have a geometric shape that can be assembled to generate the same geometry on a larger scale. Therefore multiple TetraQuad modules can be assembled to produce a larger scaled tetrahedral shaped aerial vehicle. The advantage is to have modular aerial robots that assemble in the vertical direction; this increases the rigidity of the structure, as well as reduces the wake interaction of the elevated propellers in the assembly. This work presents a design and analysis of the TetraQuad module as well as assemblies of multiple modules. A modular controller strategy is discussed. The functionality of the controller is illustrated using simulations. We validate our design with experimental flight tests. keywords: {Geometry;Automation;Shape;Propellers;Autonomous aerial vehicles;Fractals;Rigidity},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161301&isnumber=10160212

J. Whitman and H. Choset, "Learning Modular Robot Visual-motor Locomotion Policies," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11908-11914, doi: 10.1109/ICRA48891.2023.10160845.Abstract: Control policy learning for modular robot locomotion has previously been limited to proprioceptive feedback and flat terrain. This paper develops policies for modular systems with vision traversing more challenging environments. These modular robots can be reconfigured to form many different designs, where each design needs a controller to function. Though one could create a policy for individual designs and environments, such an approach is not scalable given the wide range of potential designs and environments. To address this challenge, we create a visual-motor policy that can generalize to both new designs and environments. The policy itself is modular, in that it is divided into components, each of which corresponds to a type of module (e.g., a leg, wheel, or body). The policy components can be recombined during training to learn to control multiple designs. We develop a deep reinforcement learning algorithm where visual observations are input to a modular policy interacting with multiple environments at once. We apply this algorithm to train robots with combinations of legs and wheels, then demonstrate the policy controlling real robots climbing stairs and curbs. keywords: {Legged locomotion;Training;Adaptation models;Visualization;Machine vision;Wheels;Propioception},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160845&isnumber=10160212

B. Piranda, F. Lassabe and J. Bourgeois, "DisCo: A Multiagent 3D Coordinate System for Lattice Based Modular Self-Reconfigurable Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11915-11921, doi: 10.1109/ICRA48891.2023.10160878.Abstract: Localizing each module in a modular self-reconfigurable robot (MSR) is of paramount importance. In MSR, the communication graph is directly mapped to the real topology which makes the localization problem easy to solve. However, some types of connectors can lose the orientation of the modules, making the problem intractable. In this work, we propose to build a coordinate system for 3D lattice-based modular robots using a multiagent system. We present DisCo algorithm, that uses one agent per module which can only communicate with its connected neighbors and that does not need a central coordination system. We show that the agents can tackle any kinds of 3D lattice and we illustrate it with a Face Centered Cubic lattice (12 neighbors) and a cubic lattice (6 neighbors). Using communications and only four states, DisCo can also deduce the orientation of modules if the connectors do not provide this information. keywords: {Connectors;Three-dimensional displays;Shape;Robot kinematics;Heuristic algorithms;Voting;Lattices},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160878&isnumber=10160212

J. Xu and D. Saldaña, "Finding Optimal Modular Robots for Aerial Tasks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11922-11928, doi: 10.1109/ICRA48891.2023.10160555.Abstract: Traditional aerial vehicles have limitations in their capabilities due to actuator constraints, such as motor saturation. The hardware components and their arrangement are designed to satisfy specific requirements and are difficult to modify during operation. To address this problem, we introduce a versatile modular multi-rotor vehicle that can change its capabilities by reconfiguration. Our modular robot consists of homogeneous cuboid modules, propelled by quadrotors with tilted rotors. Depending on the number of modules and their configuration, the robot can expand its actuation capabilities. In this paper, we build a mathematical model for the actuation capability of a modular multi-rotor vehicle and develop methods to determine if a vehicle is capable of satisfying a task requirement. Based on this result, we find the optimal configurations for a given task. Our approach is validated in realistic $\mathbf{3D}$ simulations, showing that our modular system can adapt to tasks with varying requirements. keywords: {Adaptation models;Actuators;Automation;Rotors;Propulsion;Mathematical models;Hardware},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160555&isnumber=10160212

J. Baca, S. I. Ullah and P. Rangel, "Coaxial Modular Aerial System and the Reconfiguration Applications," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11929-11935, doi: 10.1109/ICRA48891.2023.10161064.Abstract: This paper presents a coaxial modular aerial system (CMAS) formed by homogeneous modules driven by their center of mass. CMAS is designed to perform independent and cooperative flight with or without payload. Properties of the modularity concept allow the system to adapt to different situations and/or tasks by adding/removing modules to/from a configuration. The CMAS module is based on a coaxial motor and a two degree-of-freedom mechanism that transfers its center of mass from one side to another to make the module navigate around. The magnetic-based connector mechanism allows the module to be attached to other modules and to different metallic surfaces. A decentralized and asynchronous 3D path planning algorithm is implemented to avoid the trajectories of other modules/obstacles and ensures safe reconfiguration of the modules. Simulations within various environments show the applicability of the reconfiguration algorithm. keywords: {Connectors;Three-dimensional displays;Automation;Navigation;Trajectory;Task analysis;Payloads},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161064&isnumber=10160212

K. Suryavanshi, S. Hamaza, V. van der Wijk and J. Herder, "ADAPT: A 3 Degrees of Freedom Reconfigurable Force Balanced Parallel Manipulator for Aerial Applications," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11936-11942, doi: 10.1109/ICRA48891.2023.10160451.Abstract: In this paper, we present the ADAPT, a novel reconfigurable force-balanced parallel manipulator for spatial motions and interaction capabilities underneath a drone. The reconfigurable aspect allows different motion-based 3-DoF operation modes like translational, rotational, planar, and so on, without the need for disassembly. For the purpose of this study, the manipulator is used in translation mode only. A kinematic model is developed and validated for the manipulator. The design and motion capabilities are also validated both by conducting dynamics simulations of a simplified model on MSC ADAMS, and experiments on the physical setup. The force-balanced nature of this novel design decouples the motion of the manipulator's end-effector from the base, zeroing the reaction forces, making this design ideally suited for aerial manipulation applications, or generic floating-base applications. keywords: {Jacobian matrices;Adaptation models;Force measurement;Force;3-DOF;Prototypes;Kinematics;reactionless force balancing;configurable robot;mechanism design;parallel robot;aerial manipulation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160451&isnumber=10160212

W. Wang, Z. Zhao, Z. Jiao, Y. Zhu, S. -C. Zhu and H. Liu, "Rearrange Indoor Scenes for Human-Robot Co-Activity," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11943-11949, doi: 10.1109/ICRA48891.2023.10160303.Abstract: We present an optimization-based framework for rearranging indoor furniture to accommodate human-robot co-activities better. The rearrangement aims to afford sufficient accessible space for robot activities without compromising everyday human activities. To retain human activities, our algorithm preserves the functional relations among furniture by integrating spatial and semantic co-occurrence extracted from SUNCG and ConceptNet, respectively. By defining the robot's accessible space by the amount of open space it can traverse and the number of objects it can reach, we formulate the rearrangement for human-robot co-activity as an optimization problem, solved by adaptive simulated annealing (ASA) and covariance matrix adaptation evolution strategy (CMA-ES). Our experiments on the SUNCG dataset quantitatively show that rearranged scenes provide a robot with 14% more accessible space and 30% more objects to interact with on average. The quality of the rearranged scenes is qualitatively validated by a human study, indicating the efficacy of the proposed strategy. keywords: {Automation;Semantics;Layout;Simulated annealing;Space exploration;IEEE activities;Covariance matrices},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160303&isnumber=10160212

R. C. Quesada and Y. Demiris, "Design and Evaluation of an Augmented Reality Head-Mounted Display User Interface for Controlling Legged Manipulators," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11950-11956, doi: 10.1109/ICRA48891.2023.10161278.Abstract: Designing an intuitive User Interface (UI) for controlling assistive robots remains challenging. Most existing UIs leverage traditional control interfaces such as joysticks, hand-held controllers, and 2D UIs. Thus, users have limited availability to use their hands for other tasks. Furthermore, although there is extensive research regarding legged manipulators, comparatively little is on their UIs. Towards extending the state-of-art in this domain, we provide a user study comparing an Augmented Reality (AR) Head-Mounted Display (HMD) UI we developed for controlling a legged manipulator against off-the-shelf control methods for such robots. We made this comparison baseline across multiple factors relevant to a successful interaction. The results from our user study ($N=17$) show that although the AR UI increases immersion, off-the-shelf control methods outperformed the AR UI in terms of time performance and cognitive workload. Nonetheless, a follow-up pilot study incorporating the lessons learned shows that AR UIs can outpace hand-held-based control methods and reduce the cognitive requirements when designers include hands-free interactions and cognitive offloading principles into the UI. keywords: {Legged locomotion;Head-mounted displays;Automation;Resists;User interfaces;Manipulators;Assistive robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161278&isnumber=10160212

T. L. Baldi, N. D'Aurizio, S. Gurgone, D. Borzelli, A. D'Avella and D. Prattichizzo, "Exploiting Intrinsic Kinematic Null Space for Supernumerary Robotic Limbs Control," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11957-11963, doi: 10.1109/ICRA48891.2023.10160964.Abstract: Supernumerary robotic limbs (SRLs) gained increasing interest in the last years for their applicability as healthcare and assistive technologies. These devices can either support or augment human sensorimotor capabilities, allowing users to complete tasks that are more complex than those feasible for their natural limbs. However, for a successful coordination between natural and artificial limbs, intuitiveness of interaction and perception of autonomy are key enabling features, especially for people suffering from motor disorders and impairments. The development of suitable human-robot interfaces is thus fundamental to foster the adoption of SRLs. With this work, we describe how to control an extra degree of freedom by taking advantage of what we defined the Intrinsic Kinematic Null Space, i.e. the redundancy of the human kinematic chain involved in the ongoing task. Obtained results demonstrated that the proposed control strategy is effective for performing complex tasks with a supernumerary robotic finger, and that practice improves users' control ability. keywords: {Automation;Robot kinematics;Redundancy;Fingers;Null space;Kinematics;Medical services},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160964&isnumber=10160212

A. Olivares-Alarcos, A. Andriella, S. Foix and G. Alenyà, "Robot explanatory narratives of collaborative and adaptive experiences," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11964-11971, doi: 10.1109/ICRA48891.2023.10161359.Abstract: In the future, robots are expected to autonomously interact and/or collaborate with humans, who will increase the uncertainty during the execution of tasks, provoking online adaptations of robots' plans. Hence, trustworthy robots must be able to store, retrieve and narrate important knowledge about their collaborations and adaptations. In this article, it is proposed a sound methodology that integrates three main elements. First, an ontology for collaborative robotics and adaptation to model the domain knowledge. Second, an episodic memory for time-indexed knowledge storage and retrieval. Third, a novel algorithm to extract the relevant knowledge and generate textual explanatory narratives. The algorithm produces three different types of outputs, varying the specificity, for diverse uses and preferences. A pilot study was conducted to evaluate the usefulness of the narratives, obtaining promising results. Finally, we discuss how the methodology can be generalized to other ontologies and experiences. This work boosts robot explainability, especially in cases where robots need to narrate the details of their short and long-term past experiences. keywords: {Uncertainty;Natural languages;Knowledge based systems;Collaboration;Knowledge graphs;Ontologies;Data mining},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161359&isnumber=10160212

H. Stedman, B. B. Kocer, N. van Zalk, M. Kovac and V. M. Pawar, "Evaluating Immersive Teleoperation Interfaces: Coordinating Robot Radiation Monitoring Tasks in Nuclear Facilities," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11972-11978, doi: 10.1109/ICRA48891.2023.10161011.Abstract: We present a virtual reality (VR) teleoperation interface for a ground-based robot, featuring dense 3D environment reconstruction and a low latency video stream, with which operators can immersively explore remote environments. At the UK Atomic Energy Authority's (UKAEA) Remote Applications in Challenging Environments (RACE) facility, we applied the interface in a user study where trained robotics operators completed simulated nuclear monitoring and decommissioning style tasks to compare VR and traditional teleoperation interface designs. We found that operators in the VR condition took longer to complete the experiment, had reduced collisions, and rated the generated 3D map with higher importance when compared to non-VR operators. Additional physiological data suggested that VR operators had a lower objective cognitive workload during the experiment but also experienced increased physical demand. Overall the presented results show that VR interfaces may benefit work patterns in teleoperation tasks within the nuclear industry, but further work is needed to investigate how such interfaces can be integrated into real world decommissioning workflows. keywords: {Visualization;Radiation monitoring;Three-dimensional displays;Service robots;Robot kinematics;Pipelines;Virtual reality;Virtual reality and interfaces;telerobotics and teleoperation;human-centered robotics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161011&isnumber=10160212

K. Fan, M. Jouaiti, A. Noormohammadi-As, C. L. Nehaniv and K. Dautenhahn, "A Social Referencing Disambiguation Framework for Domestic Service Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11979-11985, doi: 10.1109/ICRA48891.2023.10161168.Abstract: The successful integration of domestic service robots into home environments can bring significant services and convenience to the general population and possibly mitigate important societal issues, such as care provision for older adults. However, home environments are complex, dynamic and object-rich. It is, thus, very probable that service robots will encounter ambiguity while interacting with household items. To enable service robots to be more adaptive, we proposed a learning so-cial referencing computational framework and experimentally evaluated the framework on a mobile manipulator robot, Fetch, in object selection scenarios. The framework allows the robot to (1) detect and analyze the ambiguity level based on the robot's view and user's command, (2) assess the human's attention level and attract their attention, (3) disambiguate references to objects using human feedback and (4) learn novel objects after clarification from the user. System evaluation results are presented. The framework is modular and can be applied to different robotic platforms. keywords: {Deep learning;Automation;Service robots;Computational modeling;Sociology;Statistics;Older adults},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161168&isnumber=10160212

M. Matarese, F. Cocchella, F. Rea and A. Sciutti, "Ex(plainable) Machina: how social-implicit XAI affects complex human-robot teaming tasks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11986-11993, doi: 10.1109/ICRA48891.2023.10160839.Abstract: In this paper, we investigated how shared experience-based counterfactual explanations affected people's performance and robots' persuasiveness during a decision-making task in a social HRI context. We used the Connect 4 game as a complex decision-making task where participants and the robot had to play as a team against the computer. We compared two strategies of explanation generation (classical vs shared experience-based) and investigated their differences in terms of team performance, the robot's persuasive power, and participants' perception of the robot and self. Our results showed that the two explanation strategies led to comparable performances. Moreover, shared experience-based explanations - based on the team's previous games - gave higher persuasiveness to the robot's suggestions than classical ones. Finally, we noted that low-performers tend to follow the robot more than high-performers, providing insights into the potential danger for non-expert users interacting with expert explainable robots. keywords: {Human computer interaction;Automation;Decision making;Human-robot interaction;Games;Task analysis;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160839&isnumber=10160212

M. Kang, M. Yoon and S. -E. Yoon, "Towards Safe Remote Manipulation: User Command Adjustment based on Risk Prediction for Dynamic Obstacles," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 11994-12000, doi: 10.1109/ICRA48891.2023.10160690.Abstract: Real-time remote manipulation requires careful operations by a user to ensure the safety of a robot, which is designed to follow user's commands, against dynamic obstacles. However, a user may give commands to a robot at the risk of collision with dynamic obstacles due to a user's unfamiliar control ability or unexpected situations. In this paper, we propose a risk-aware user command adjustment method to avoid potential collision with dynamic obstacles. Our method consists of a network that predicts the risk of dynamic obstacles and another network that synthesizes commands to avoid obstacles. Based on the predicted risk, our method decides an adjusted command between a user command and a command to avoid collisions. We evaluate our method in problems that face collisions with dynamic obstacles when following given commands and in problems with static obstacles. We show that our method improves safety against the risk of dynamic obstacles or follows user commands when there is no risk. We also demonstrate the feasibility of our method using the real fetch manipulator with seven-degrees-of-freedom. keywords: {Automation;Semantics;Robot sensing systems;Real-time systems;Safety;Collision avoidance;Manipulator dynamics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160690&isnumber=10160212

M. Jouaiti, N. Azizi and K. Dautenhahn, "Computational Methods to Support Prototyping of an Adaptive Robot Joystick Controller for Children with Upper Limb Impairments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12001-12007, doi: 10.1109/ICRA48891.2023.10160808.Abstract: Between 2% to 5% of children are affected by Developmental Coordination Disorders in Canada and have been diagnosed with upper limb impairments, which affect their daily lives and reduces their autonomy. Motor impairments can be part of progressive disorders, so despite regular therapy, progress remains fleeting. Affected individuals therefore consistently face many barriers, including entertainment opportunities, as availability of off-the-shelf inclusive technology is very limited. Our long-term goal is to develop a play-mediator robot, which would facilitate play between children with motor impairments and their peers or family members. Here, games that the robot can play are remotely controlled by the participants, using appropriate interfaces (e.g. joysticks). In this paper, we take the first step towards that goal and develop an adaptive joystick controller that can compensate for individual deficits. We monitor movement statistics to determine if re-calibration of the controller is necessary. Moreover, we propose a computational model of data ‘distortion’, as a tool for developers to test their technology in the very early stages of prototype development, without requiring access to participants. This work is validated with data from healthy adults and children with upper limb impairments. keywords: {Pediatrics;Robot kinematics;Computational modeling;Prototypes;Medical treatment;Entertainment industry;Games},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160808&isnumber=10160212

C. McGinn, R. Scott, N. Donnelly, M. F. Cullinan, A. Winfield and P. Treusch, "Ethical Assessment of a Hospital Disinfection Robot," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12008-12014, doi: 10.1109/ICRA48891.2023.10160903.Abstract: Robots have the potential to deliver very positive impacts for society, however, it's critical that in preparing for real-world deployments, we recognize and take steps to mitigate against the potential harms, both direct and indirect, that they may cause. In this paper, we explore how the ethics canvas (EC) and the ethical risk assessment (ERA) methodology defined in British Standard 8611 can be combined to better align robot technologies with ethics and their socio-cultural context of operation. We illustrate this through a practical case-study involving the real-world introduction of a disinfection robot to a radiology department in a European hospital. Using the EC, we identified 49 distinct ways that the technology was likely to impact key stakeholders and 11 ways that failure or misuse of the technology was likely to impact service provision. From this data, 8 mitigating measures were identified. Then, using the ERA tool, 9 risks were identified that were considered to represent a high likelihood of occurrence. From these insights, a further 8 mitigation measures were proposed. The combined use of both tools was found to be complementary, since the EC fostered a bottom-up, subjective critical thinking process whereas the ERA provided a broader, more top-down objective view. This example provides a practical template for robotics practitioners to better understand and manage the ethical and socio-cultural dimensions of their work, and contributes towards the standardization of ethical assessments in robotics with an emphasis on the move from principles to practice. keywords: {Training;Ethics;Automation;Hospitals;Europe;Radiology;Stakeholders},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160903&isnumber=10160212

S. Liu et al., "Intention Aware Robot Crowd Navigation with Attention-Based Interaction Graph," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12015-12021, doi: 10.1109/ICRA48891.2023.10160660.Abstract: We study the problem of safe and intention-aware robot navigation in dense and interactive crowds. Most previous reinforcement learning (RL) based methods fail to consider different types of interactions among all agents or ignore the intentions of people, which results in performance degradation. In this paper, we propose a novel recurrent graph neural network with attention mechanisms to capture heterogeneous interactions among agents through space and time. To encourage longsighted robot behaviors, we infer the intentions of dynamic agents by predicting their future trajectories for several timesteps. The predictions are incorporated into a model-free RL framework to prevent the robot from intruding into the intended paths of other agents. We demonstrate that our method enables the robot to achieve good navigation performance and non-invasiveness in challenging crowd navigation scenarios. We successfully transfer the policy learned in simulation to a real-world TurtleBot 2i. Our code and videos are available at https://sites.google.com/view/intention-aware-crowdnav/home. keywords: {Degradation;Codes;Navigation;Reinforcement learning;Predictive models;Graph neural networks;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160660&isnumber=10160212

A. Higgins, A. Llewellyn, E. Dures and P. Caleb-Solly, "A Study into Understanding User Requirements to Inform the Design of Customizable Robotic Pain Management Devices," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12022-12030, doi: 10.1109/ICRA48891.2023.10161495.Abstract: Previous research into using robots for pain man-agement has shown promise. However to date, there seems to have been little research investigating user requirements for robotic pain management devices which could be used by adults living with chronic pain, and how these might be translated into custom products. We carried out a user study comprising online surveys and interviews with people who have lived experience of chronic pain to investigate their perspectives. We had a total of 44 participants in our study. Our research revealed a preference for robotic devices for pain management which have an abstract or animal-like form, noting that contact points with the body should feel soft, warm, and light. Study participants also felt that the user should initiate the interaction and should have control of the robot, as well as the type and intensity of touch. Favored touch types included massaging, rubbing, and stroking. From the emerging requirements, given the diversity of experiences, design-related attributes identified could be used for a form-customization application, such as interactive evolutionary computation (IEC), as a means to personalize the embodiment of robotic devices. Prioritized form factors for customization through included size, weight, and feel. keywords: {Surveys;Pain;User centered design;IEC;Medical services;Evolutionary computation;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161495&isnumber=10160212

Y. -J. Mun, M. Itkina, S. Liu and K. Driggs-Campbell, "Occlusion-Aware Crowd Navigation Using People as Sensors," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12031-12037, doi: 10.1109/ICRA48891.2023.10160715.Abstract: Autonomous navigation in crowded spaces poses a challenge for mobile robots due to the highly dynamic, partially observable environment. Occlusions are highly prevalent in such settings due to a limited sensor field of view and obstructing human agents. Previous work has shown that observed interactive behaviors of human agents can be used to estimate potential obstacles despite occlusions. We propose integrating such social inference techniques into the planning pipeline. We use a variational autoencoder with a specially designed loss function to learn representations that are meaningful for occlusion inference. This work adopts a deep reinforcement learning approach to incorporate the learned representation into occlusion-aware planning. In simulation, our occlusion-aware policy achieves comparable collision avoidance performance to fully observable navigation by estimating agents in occluded spaces. We demonstrate successful policy transfer from simulation to the real-world Turtlebot 2i. To the best of our knowledge, this work is the first to use social occlusion inference for crowd navigation. Our implementation is available at https://github.com/yejimun/PaS_CrowdNav. keywords: {Deep learning;Pedestrians;Navigation;Pipelines;Reinforcement learning;Robot sensing systems;Feature extraction},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160715&isnumber=10160212

A. F. F. Silva, L. E. Almeida and D. G. Macharet, "Efficiently Approaching Groups of People in a Socially Acceptable Manner in Environments with Obstacles," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12038-12044, doi: 10.1109/ICRA48891.2023.10160378.Abstract: Advancements in mobile robotics have allowed humans and robots to interact in different environments and ways. A problem of great interest in Human-Robot Interaction is how to approach individuals, e.g., to gather information, in a socially acceptable manner. We present a new method for planning sequential visits to various groups of people in cluttered environments. The problem is formulated as a Set Orienteering Problem, where each group denotes a cluster with a set of possible approaching points considering different F-formations. We use the concept of a social probabilistic roadmap to determine safe paths between groups. Simulations considering different cases show that methodology produces efficient tours that maximize the number of approached individuals while respecting social norms of distance and a limited budget. keywords: {Automation;Human-robot interaction;Probabilistic logic;Planning;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160378&isnumber=10160212

Y. Xu, T. Chakhachiro, T. Kathuria and M. Ghaffari, "SoLo T-DIRL: Socially-Aware Dynamic Local Planner based on Trajectory-Ranked Deep Inverse Reinforcement Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12045-12051, doi: 10.1109/ICRA48891.2023.10160536.Abstract: This work proposes a novel framework for socially-aware robot navigation in dynamic, crowded environments using a Deep Inverse Reinforcement Learning. To address the social navigation problem, our multi-modal learning based planner explicitly considers social interaction factors, as well as social-awareness factors, into the DIRL pipeline to learn a reward function from human demonstrations. Moreover, we propose a novel trajectory ranking score using the sudden velocity change of pedestrians around the robot to address the sub-optimality in human demonstrations. Our evaluation shows that this method can successfully make a robot navigate in a crowded social environment and outperforms the state-of-art social navigation methods in terms of the success rate, navigation time, and invasion rate. keywords: {Visualization;Pedestrians;Automation;Navigation;Pipelines;Human-robot interaction;Reinforcement learning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160536&isnumber=10160212

Z. Zhou and M. Brandão, "Noise and Environmental Justice in Drone Fleet Delivery Paths: A Simulation-Based Audit and Algorithm for Fairer Impact Distribution," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12052-12057, doi: 10.1109/ICRA48891.2023.10160821.Abstract: Despite the growing interest in the use of drone fleets for delivery of food and parcels, the negative impact of such technology is still poorly understood. In this paper we investigate the impact of such fleets in terms of noise pollution and environmental justice. We use simulation with real population data to analyze the spatial distribution of noise, and find that: 1) noise increases rapidly with fleet size; and 2) drone fleets can produce noise hotspots that extend far beyond warehouses or charging stations, at levels that lead to annoyance and interference of human activities. This, we will show, leads to concerns of fairness of noise distribution. We then propose an algorithm that successfully balances the spatial distribution of noise across the city, and discuss the limitations of such purely technical approaches. We complement the work with a discussion of environmental justice, showing how careless UAV fleet development and regulation can lead to reinforcing well-being deficiencies of poor and marginalized communities. keywords: {Graphical models;Pollution;Urban areas;Sociology;Interference;Data models;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160821&isnumber=10160212

F. Porcini, A. Filippeschi, M. Solazzi, C. A. Avizzano and A. Frisoli, "Actuator Capabilities Aware Limitation for TDPA Passivity Controller Action," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12058-12064, doi: 10.1109/ICRA48891.2023.10160958.Abstract: Haptic interaction often requires stabilizing controllers for safety. The Time-Domain Passivity Approach guarantees passivity (then stability) by observing and dissipating energy generated from active elements in a network. The dissipating action is performed by a Passivity Controller, whose action is commanded to the physically limited robot actuators. Thus, the controller stabilizing action should be in turn limited in order to command displayable references to the actuators. This problem is rarely taken into account in the literature and when it is, the limitation is neither directly related to the actuator power limits, nor to the robot's current configuration. The limits of the currently adopted strategies leave room for improvement. In this paper, a new strategy to limit the Passivity Controller action is proposed taking into account both the physical limits of the actuators and the robot configuration. This new strategy is experimentally tested against the classical one based on the sampling time. In the experiment, a human interacts with a virtual wall in a Virtual Environment through a haptic interface. The wall induces an unstable behavior passivated with the two limitation strategies. The results clearly state the benefits introduced by the proposed strategy in two relevant cases. keywords: {Actuators;Automation;Virtual environments;Haptic interfaces;Safety;Behavioral sciences;Time-domain analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160958&isnumber=10160212

X. Zhou, P. Paik and S. F. Atashzar, "Upper-limb Geometric MyoPassivity Map for Physical Human-Robot Interaction," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12065-12070, doi: 10.1109/ICRA48891.2023.10161188.Abstract: The intrinsic biomechanical characteristic of the human upper limb plays a central role in absorbing the interactive energy during physical human-robot interaction (pHRI). We have recently shown that based on the concept of “Excess of Passivity (EoP),” from nonlinear control theory, it is possible to decode such energetic behavior for both upper and lower limbs [1], [2]. The extracted knowledge can be used in the design of controllers (such as [2]-[5]) for optimizing the transparency and fidelity of force fields in human-robot interaction and in haptic systems. In this paper, for the first time, we investigate the frequency behavior of the passivity map for the upper limb when the muscle co-activation was controlled in real- time through visual electromyographic feedback. Five healthy subjects (age: 27±5) were included in this study. The energetic behavior was evaluated at two stimulation frequencies at eight interaction directions over two controlled muscle co-activation levels. Electromyography (EMG) was captured using the Delsys Wireless Trigno system. Results showed a correlation between EMG and EoP, which was further amplified by decreasing the frequency. The proposed energetic behavior is named the Geometric MyoPassivity (GMP) map. The findings indicate that the GMP map has the potential to be used in real-time to quantify the absorbable energy, thus passivity margin of stability for upper limb interaction during pHRI. keywords: {Biomechanics;Frequency modulation;Force;Human-robot interaction;Muscles;Electromyography;Frequency estimation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161188&isnumber=10160212

M. Drolet, J. Campbell and H. B. Amor, "Learning and Blending Robot Hugging Behaviors in Time and Space," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12071-12077, doi: 10.1109/ICRA48891.2023.10160587.Abstract: We introduce an imitation learning-based physical human-robot interaction algorithm capable of predicting appropriate robot responses in complex interactions involving a superposition of multiple interactions. Our proposed algorithm, Blending Bayesian Interaction Primitives (B-BIP) allows us to achieve responsive interactions in complex hugging scenarios, capable of reciprocating and adapting to a hug's motion and timing. We show that this algorithm is a generalization of prior work, for which the original formulation reduces to the particular case of a single interaction, and evaluate our method through both an extensive user study and empirical experiments. Our algorithm yields significantly better quantitative prediction error and more-favorable participant responses with respect to accuracy, responsiveness, and timing, when compared to existing state-of-the-art methods. keywords: {Correlation;Automation;Statistical analysis;Human-robot interaction;Switches;Prediction algorithms;Timing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160587&isnumber=10160212

Y. Chen et al., "Quadruped Guidance Robot for the Visually Impaired: A Comfort-Based Approach," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12078-12084, doi: 10.1109/ICRA48891.2023.10160854.Abstract: Guidance robots that can guide people and avoid various obstacles, could potentially be owned by more visually impaired people at a fairly low cost. Most of the previous guidance robots for the visually impaired ignored the human response behavior and comfort, treating the human as an appendage dragged by the robot, which can lead to imprecise guidance of the human and sudden changes in the traction force experienced by the human. In this paper, we propose a novel quadruped guidance robot system with a comfort-based concept. We design a controllable traction device that can adjust the length and force between human and robot to ensure comfort. To allow the human to be guided safely and comfortably to the target position in complex environments, our proposed human motion planner can plan the traction force with the force-based human motion model. To track the planned force, we also propose a robot motion planner that can generate the specific robot motion command and design the force control device. Our system has been deployed on Unitree Laikago quadrupedal platform and validated in real-world scenarios. (Video11Video demonstration: https://youtu.be/gd-RcYOqGuo.) keywords: {Robot motion;Target tracking;Costs;Automation;Force;Behavioral sciences;Quadrupedal robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160854&isnumber=10160212

G. Solak and A. Ajoudani, "Online Learning and Suppression of Vibration in Collaborative Robots with Power Tools," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12085-12091, doi: 10.1109/ICRA48891.2023.10161190.Abstract: Vibration suppression is an important skill for future robots that will collaborate with humans in industrial settings. The vibration through physical interaction is a common problem in such settings, especially in operations involving hand-held vibrating tools. The existing human-robot collaboration (HRC) works addressing this problem mostly focus on the oscillations caused by the human operator, and suppress them by adapting the admittance parameters. This, however, usually results in stiffer robot behavior and contributes to reducing the overall performance of the task, in particular when impedance planning is a requirement. In this work, we focus on the vibration coming from external sources such as power tools and suppress it actively. We learn the vibration using the bandlimited multiple Fourier linear combiner (BMFLC) algorithm and apply it as a feedforward Cartesian force to cancel the vibration. We combine the feedforward force control with variable impedance learning and show that it improves the vibration suppression performance in simulation and real-world experiments. The feedforward approach can suppress the vibration better while keeping a more compliant set of impedance parameters, which is crucial in HRC. keywords: {Vibrations;Damping;Service robots;Force;Collaboration;Planning;Impedance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161190&isnumber=10160212

A. Mohammad, M. Schappler and T. Ortmaier, "Towards Human-Robot Collaboration with Parallel Robots by Kinetostatic Analysis, Impedance Control and Contact Detection," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12092-12098, doi: 10.1109/ICRA48891.2023.10161217.Abstract: Parallel robots provide the potential to be lever-aged for human-robot collaboration (HRC) due to low collision energies even at high speeds resulting from their reduced moving masses. However, the risk of unintended contact with the leg chains increases compared to the structure of serial robots. As a first step towards HRC, contact cases on the whole parallel robot structure are investigated and a disturbance observer based on generalized momenta and measurements of motor current is applied. In addition, a Kalman filter and a second-order sliding-mode observer based on generalized momenta are compared in terms of error and detection time. Gearless direct drives with low friction improve external force estimation and enable low impedance. The experimental validation is performed with two force-torque sensors and a kinetostatic model. This allows a new identification method of the motor torque constant of an assembled parallel robot to estimate external forces from the motor current and via a dynamics model. A Cartesian impedance control scheme for compliant robot-environmental dynamics with stiffness from 0.1-2N/mm and the force observation for low forces over the entire structure are validated. The observers are used for collisions and clamping at velocities of 0.4-0.9 m/s for detection within 9–58 ms and a reaction in the form of a zero-g mode. keywords: {Legged locomotion;Parallel robots;Robot kinematics;Force;Collaboration;Estimation;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161217&isnumber=10160212

S. W. Han and M. J. Kim, "Proprioceptive Sensor-Based Simultaneous Multi-Contact Point Localization and Force Identification for Robotic Arms," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12099-12105, doi: 10.1109/ICRA48891.2023.10161173.Abstract: In this paper, we propose an algorithm that estimates contact point and force simultaneously. We consider a collaborative robot equipped with proprioceptive sensors, in particular, joint torque sensors (JTSs) and a base force/torque (F/T) sensor. The proposed method has the following advan-tages. First, fast computation is achieved by proper preprocessing of robot meshes. Second, multi-contact can be identified with the aid of the base F/T sensor, while this is challenging when the robot is equipped with only JTSs. The proposed method is a modification of the standard particle filter to cope with mesh preprocessing and with available sensor data. In simulation validation, for a 7 degree-of-freedom robot, the algorithm runs at 2200Hz with 99.96% success rate for the single-contact case. In terms of the run-time, the proposed method was ≥3.5X faster compared to the existing methods. Dual and triple contacts are also reported in the manuscript. keywords: {Location awareness;Torque;Force;Propioception;Manipulators;Particle filters;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161173&isnumber=10160212

N. Csomay-Shanklin, V. D. Dorobantu and A. D. Ames, "Nonlinear Model Predictive Control of a 3D Hopping Robot: Leveraging Lie Group Integrators for Dynamically Stable Behaviors," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12106-12112, doi: 10.1109/ICRA48891.2023.10160873.Abstract: Achieving stable hopping has been a hallmark challenge in the field of dynamic legged locomotion. Controlled hopping is notably difficult due to extended periods of under-actuation combined with very short ground phases wherein ground interactions must be modulated to regulate global state. In this work, we explore the use of hybrid nonlinear model predictive control paired with a low-level feedback controller in a multi-rate hierarchy to achieve dynamically stable motions on a novel 3D hopping robot. In order to demonstrate richer behaviors on the manifold of rotations, both the planning and feedback layers must be designed in a geometrically consistent fashion; therefore, we develop the necessary tools to employ Lie group integrators and appropriate feedback controllers. We experimentally demonstrate stable 3D hopping on a novel robot, as well as trajectory tracking and flipping in simulation. keywords: {Manifolds;Legged locomotion;Solid modeling;Three-dimensional displays;Trajectory tracking;Behavioral sciences;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160873&isnumber=10160212

T. Greco and D. E. Koditschek, "Anchoring Sagittal Plane Templates in a Spatial Quadruped," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12113-12119, doi: 10.1109/ICRA48891.2023.10161488.Abstract: This paper introduces a new controller that stabilizes the motion of a spatial quadruped around sagittal-plane templates. It enables highly dynamic gaits and transitional maneuvers formed from parallel and sequential compositions of such planar templates in settings that require significant out-of-plane reactivity. The controller admits formal guarantees of stability with some modest assumptions. Experimental results validate the reliable execution of those planar template-based maneuvers, even in the face of large lateral, yaw, and roll incurring disturbances. This spatial anchor, fixed in parallel composition with a variety of different parallel and sequential compositions of sagittal plane templates, illustrates the robust portability of provably interoperable modular control components across a variety of hardware platforms and behaviors. keywords: {Perturbation methods;Software algorithms;Hardware;Stability analysis;Software;Behavioral sciences;Quadrupedal robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161488&isnumber=10160212

J. Kang, H. -B. Kim, K. H. Choi and K. -S. Kim, "External Force Estimation of Legged Robots via a Factor Graph Framework with a Disturbance Observer," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12120-12126, doi: 10.1109/ICRA48891.2023.10161525.Abstract: Recently, legged robots have been used for various purposes, such as exploring unknown terrain or interacting with the world. For control and planning legged systems during interactive operations, it is essential to estimate and respond to external forces. However, in legged system, it becomes difficult to estimate forces due to highly dynamic situations. There are several studies that use a force sensor on the foot and end effector, but these approaches have disadvantages in terms of cost and sustainability. Therefore, in this paper, we propose an improved method for estimating external forces without a force sensor. First, each leg force was obtained using the system dynamics of the robot with a disturbance observer. Then, by preintegration, it was tightly coupled with other sensors to estimate the pose and external force simultaneously. Despite the impact and slip, we estimate external forces accurately in standing and walking motions. Moreover, we compared pose estimation performance with VINS-Mono [1], and there is no significant accuracy degradation in spite of highly dynamic force residual. keywords: {Legged locomotion;System dynamics;Force;Dynamics;Pose estimation;Robot sensing systems;Disturbance observers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161525&isnumber=10160212

W. Sato, J. Nishii, M. Hayashibe and D. Owaki, "Morphological Characteristics That Enable Stable and Efficient Walking in Hexapod Robot Driven by Reflex-based Intra-limb Coordination," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12127-12133, doi: 10.1109/ICRA48891.2023.10161107.Abstract: Insects exhibit adaptive walking behavior in an unstructured environment, despite having only an extremely small number of neurons (105 to 106). This suggests that not only the brain nervous system but also properties of the physical body, such as the morphological characteristics, play an essential role in generating such adaptive behavior. Our study aims at investigating the effect of body morphological characteristics on the walking performance in a robot model, which is designed to mimic an insect. To this end, we constructed an insect-like hexapod model in a simulation environment that implements a reflex-based intra-limb coordination control. Herein, for a set of walking parameters, which were optimized to maximize the energy efficiency at the target speed, we investigated the effects of changes in the standard posture of the two leg joints on the walking success rate for various initial conditions and cost of transport (CoT) as an index of energy efficiency. Simulation results indicated that robots with specific morphological characteristics similar to those of insects exhibited high gait stability and energetic efficiency. Because only the reflex-based control was employed, the inter-leg coordination occurred spontaneously, suggesting that our approach would lead to a useful design methodology from the perspective of computational cost in generating the walking locomotion. keywords: {Legged locomotion;Adaptation models;Robot kinematics;Insects;Simulation;Stability criteria;Energy efficiency},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161107&isnumber=10160212

S. Surana, B. Lim and A. Cully, "Efficient Learning of Locomotion Skills through the Discovery of Diverse Environmental Trajectory Generator Priors," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12134-12141, doi: 10.1109/ICRA48891.2023.10161267.Abstract: Data-driven learning based methods have recently been particularly successful at learning robust locomotion controllers for a variety of unstructured terrains. Prior work has shown that incorporating good locomotion priors in the form of trajectory generators (TGs) is effective at efficiently learning complex locomotion skills. However, defining a good, single TG as tasks/environments become increasingly more complex remains a challenging problem as it requires extensive tuning and risks reducing the effectiveness of the prior. In this paper, we present Evolved Environmental Trajectory Generators (EETG), a method that learns a diverse set of specialised locomotion priors using Quality-Diversity algorithms while maintaining a single policy within the Policies Modulating TG (PMTG) architecture. The results demonstrate that EETG enables a quadruped robot to successfully traverse a wide range of environments, such as slopes, stairs, rough terrain, and balance beams. Our experiments show that learning a diverse set of specialized TG priors is significantly (5 times) more efficient than using a single, fixed prior when dealing with a wide range of environments. keywords: {Learning systems;Automation;Stairs;Generators;Trajectory;Quadrupedal robots;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161267&isnumber=10160212

W. Ubellacker and A. D. Ames, "Robust Locomotion on Legged Robots through Planning on Motion Primitive Graphs," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12142-12148, doi: 10.1109/ICRA48891.2023.10160672.Abstract: The functional demands of robotic systems often require completing various tasks or behaviors under the effect of disturbances or uncertain environments. Of increasing interest is the autonomy for dynamic robots, such as multirotors, motor vehicles, and legged platforms. Here, disturbances and environmental conditions can have significant impact on the successful performance of the individual dynamic behaviors, referred to as “motion primitives”. Despite this, robustness can be achieved by switching to and transitioning through suitable motion primitives. This paper contributes such a method by presenting an abstraction of the motion primitive dynamics and a corresponding”motion primitive transfer function”. From this, a mixed discrete and continuous “motion primitive graph” is constructed, and an algorithm capable of online search of this graph is detailed. The result is a framework capable of realizing holistic robustness on dynamic systems. This is experimentally demonstrated for a set of motion primitives on a quadrupedal robot, subject to various environmental and intentional disturbances. keywords: {Legged locomotion;Heuristic algorithms;Dynamics;Transfer functions;Probabilistic logic;Robustness;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160672&isnumber=10160212

Y. Ma, F. Farshidian and M. Hutter, "Learning Arm-Assisted Fall Damage Reduction and Recovery for Legged Mobile Manipulators," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12149-12155, doi: 10.1109/ICRA48891.2023.10160582.Abstract: Adaptive falling and recovery skills greatly extend the applicability of robot deployments. In the case of legged mobile manipulators, the robot arm could adaptively stop the fall and assist the recovery. Prior works on falling and recovery strategies for legged mobile manipulators usually rely on assumptions such as inelastic collisions and falling in defined directions to enable real-time computation. This paper presents a learning-based approach to reducing fall damage and recovery. An asymmetric actor-critic training structure is used to train a time-invariant policy with time-varying reward functions. In simulated experiments, the policy recovers from 98.9% of initial falling configurations. It reduces base contact impulse, peak joint internal forces, and base acceleration during the fall compared to the baseline methods. The trained control policy is deployed and extensively tested on the ALMA robot hardware. A video summarizing the proposed method and the hardware tests is available at https://youtu.be/avwg2HqGi8s keywords: {Training;Legged locomotion;Adaptation models;Torque;Automation;Manipulators;Hardware},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160582&isnumber=10160212

M. Sombolestan and Q. Nguyen, "Hierarchical Adaptive Loco-manipulation Control for Quadruped Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12156-12162, doi: 10.1109/ICRA48891.2023.10160523.Abstract: Legged robots have shown remarkable advantages in navigating uneven terrain. However, realizing effective loco-motion and manipulation tasks on quadruped robots is still challenging. In addition, object and terrain parameters are generally unknown to the robot in these problems. Therefore, this paper proposes a hierarchical adaptive control framework that enables legged robots to perform loco-manipulation tasks without any given assumption on the object's mass, the friction coefficient, or the slope of the terrain. In our approach, we first present an adaptive manipulation control to regulate the contact force to manipulate an unknown object on unknown terrain. We then introduce a unified model predictive control (MPC) for loco-manipulation that takes into account the manipulation force in our robot dynamics. The proposed MPC framework thus can effectively regulate the interaction force between the robot and the object while keeping the robot balance. Experimental validation of our proposed approach is successfully conducted on a Unitree A1 robot, allowing it to manipulate an unknown time-varying load up to 7 kg (60% of the robot's weight). Moreover, our framework enables fast adaptation to unknown slopes or different surfaces with different friction coefficients. keywords: {Legged locomotion;Uncertainty;Navigation;Trajectory tracking;Friction;Force;Quadrupedal robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160523&isnumber=10160212

M. Maravgakis, D. -E. Argiropoulos, S. Piperakis and P. Trahanias, "Probabilistic Contact State Estimation for Legged Robots using Inertial Information," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12163-12169, doi: 10.1109/ICRA48891.2023.10161485.Abstract: Legged robot navigation in unstructured and slippery terrains depends heavily on the ability to accurately identify the quality of contact between the robot's feet and the ground. Contact state estimation is regarded as a challenging problem and is typically addressed by exploiting force measurements, joint encoders and/or robot kinematics and dynamics. In contrast to most state of the art approaches, the current work introduces a novel probabilistic method for estimating the contact state based solely on proprioceptive sensing, as it is readily available by Inertial Measurement Units (IMUs) mounted on the robot's end effectors. Capitalizing on the uncertainty of IMU measurements, our method estimates the probability of stable contact. This is accomplished by approximating the multimodal probability density function over a batch of data points for each axis of the IMU with Kernel Density Estimation. The proposed method has been extensively assessed against both real and simulated scenarios on bipedal and quadrupedal robotic platforms such as ATLAS, TALOS and Unitree's GO1. keywords: {Legged locomotion;Uncertainty;Robot kinematics;Training data;Robot sensing systems;Probabilistic logic;Time measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161485&isnumber=10160212

D. Sójka, M. R. Nowicki and P. Skrzypczyński, "Learning an Efficient Terrain Representation for Haptic Localization of a Legged Robot," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12170-12176, doi: 10.1109/ICRA48891.2023.10160340.Abstract: Although haptic sensing has recently been used for legged robot localization in extreme environments where a camera or LiDAR might fail, the problem of efficiently representing the haptic signatures in a learned prior map is still open. This paper introduces an approach to terrain representation for haptic localization inspired by recent trends in machine learning. It combines this approach with the proven Monte Carlo algorithm to obtain an accurate, computation-efficient, and practical method for localizing legged robots under adversarial environmental conditions. We apply the triplet loss concept to learn highly descriptive embeddings in a transformer-based neural network. As the training haptic data are not labeled, the positive and negative examples are discriminated by their geometric locations discovered while training. We demonstrate experimentally that the proposed approach outperforms by a large margin the previous solutions to haptic localization of legged robots concerning the accuracy, inference time, and the amount of data stored in the map. As far as we know, this is the first approach that completely removes the need to use a dense terrain map for accurate haptic localization, thus paving the way to practical applications. keywords: {Location awareness;Legged locomotion;Training;Three-dimensional displays;Robot vision systems;Neural networks;Transformers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160340&isnumber=10160212

B. Forrai, T. Miki, D. Gehrig, M. Hutter and D. Scaramuzza, "Event-based Agile Object Catching with a Quadrupedal Robot," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12177-12183, doi: 10.1109/ICRA48891.2023.10161392.Abstract: Quadrupedal robots are conquering various applications in indoor and outdoor environments due to their capability to navigate challenging uneven terrains. Exteroceptive information greatly enhances this capability since perceiving their surroundings allows them to adapt their controller and thus achieve higher levels of robustness. However, sensors such as LiDARs and RGB cameras do not provide sufficient information to quickly and precisely react in a highly dynamic environment since they suffer from a bandwidth-latency trade-off. They require significant bandwidth at high frame rates while featuring significant perceptual latency at lower frame rates, thereby limiting their versatility on resource constrained platforms. In this work, we tackle this problem by equipping our quadruped with an event camera, which does not suffer from this tradeoff due to its asynchronous and sparse operation. In leveraging the low latency of the events, we push the limits of quadruped agility and demonstrate high-speed ball catching for the first time. We show that our quadruped equipped with an event-camera can catch objects with speeds up to 15 m/s from 4 meters, with a success rate of 83%. Using a VGA event camera, our method runs at 100 Hz on an NVIDIA Jetson Orin. keywords: {Visualization;Laser radar;Robot vision systems;Cameras;Robustness;Sensor systems;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161392&isnumber=10160212

K. Ye and K. Karydis, "Evaluation of Legged Robot Landing Capability Under Aggressive Linear and Angular Velocities," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12184-12190, doi: 10.1109/ICRA48891.2023.10161440.Abstract: This paper proposes a method to evaluate the capability of aggressive legged robot landing under significant touchdown linear and angular velocities upon impact. Our approach builds upon the Planar Inverted Pendulum with Flywheel (PIPF) model and introduces a landing framework for the first stance step on a non-dimensional basis. We develop a nonlinear framework with iterative constrained trajectory optimization to stabilize the first stance step prior to N-step Capturability analysis. Performance maps across many different initial conditions reveal approximately linear boundaries as well as the effect of inertia, body incidence angle and leg attacking angle on the boundary shape. Our method also yields the engineering insight that body inertia affects the performance map the most, hence its optimization can be prioritized when the target is to improve robot landing efficacy. keywords: {Legged locomotion;Automation;Shape;Angular velocity;Mathematical models;Flywheels;Iterative methods},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161440&isnumber=10160212

G. Colin, Y. Sim and J. Ramos, "Bipedal Robot Walking Control Using Human Whole-Body Dynamic Telelocomotion," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12191-12197, doi: 10.1109/ICRA48891.2023.10160278.Abstract: For humanoids to be deployed in demanding situations, such as search and rescue, highly intelligent decision making and proficient sensorimotor skill is expected. A promising solution is to leverage human prowess by interconnecting robot and human via teleoperation. Towards creating seamless operation, this paper presents a dynamic telelocomotion framework that synchronizes the gait of a human pilot with the walking of a bipedal robot. First, we introduce a method to generate a virtual human walking model from the stepping behavior of a human pilot which serves as a reference for the robot to walk. Second, the dynamics of the walking reference and robot walking are synchronized by applying forces to the human pilot and the robot to achieve dynamic similarity between the two systems. This enables the human pilot to continuously perceive and cancel any asynchrony between the walking reference and robot. A consistent step placement strategy for the robot is derived to maintain dynamic similarity through step transitions. Using our human-machine-interface, we demonstrate that the human pilot can achieve stable and synchronous teleoperation of a simulated robot through stepping-in-place, walking, and disturbance rejection experiments. This work provides a fundamental step towards transferring human intelligence and reflexes to humanoid robots. keywords: {Legged locomotion;Automation;Human intelligence;Dynamics;Decision making;Humanoid robots;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160278&isnumber=10160212

M. -J. Kim, D. Lim, G. Park and J. Park, "Foot Stepping Algorithm of Humanoids with Double Support Time Adjustment based on Capture Point Control," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12198-12204, doi: 10.1109/ICRA48891.2023.10160297.Abstract: Recently, foot stepping strategies of humanoid robots have been actively developed for robust balancing of humanoids against disturbances. In this paper, a novel stepping algorithm adjusting double support phase (DSP) time is proposed. First, the stepping algorithm is proposed based on a model predictive control (MPC) framework for capture point (CP) control and footstep adjustment. Next, when the remaining step time is not enough to adjust the footstep, the DSP scaling method brings the next swing phase forward by reducing the DSP time, which enables the robot to maintain the balance robustly. The robust balance control performance of the proposed method is validated through simulations and experiments when the robot is walking in the presence of external pushes. A more stable balancing performance is realized compared to state-of-the-art stepping controllers. keywords: {Legged locomotion;Automation;Perturbation methods;Government;Humanoid robots;Prediction algorithms;Robustness},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160297&isnumber=10160212

D. Crowley, J. Dao, H. Duan, K. Green, J. Hurst and A. Fern, "Optimizing Bipedal Locomotion for The 100m Dash With Comparison to Human Running," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12205-12211, doi: 10.1109/ICRA48891.2023.10160436.Abstract: In this paper, we explore the space of running gaits for the bipedal robot Cassie. Our first contribution is to present an approach for optimizing gait efficiency across a spectrum of speeds with the aim of enabling extremely high-speed running on hardware. This raises the question of how the resulting gaits compare to human running mechanics, which are known to be highly efficient in comparison to quadrupeds. Our second contribution is to conduct this comparison based on established human biomechanical studies. We find that despite morphological differences between Cassie and humans, key properties of the gaits are highly similar across a wide range of speeds. Finally, our third contribution is to integrate the optimized running gaits into a full controller that satisfies the rules of the real-world task of the 100m dash, including starting and stopping from a standing position. We demonstrate this controller on hardware to establish the Guinness World Record for Fastest 100m by a Bipedal Robot. keywords: {Training;Biomechanics;Technological innovation;Systematics;Hardware;Software;Space exploration},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160436&isnumber=10160212

T. Kamimura and A. Sano, "Effect of the Dynamics of a Horizontally Wobbling Mass on Biped Walking Performance," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12212-12217, doi: 10.1109/ICRA48891.2023.10160772.Abstract: We have developed biped robots with a passive dynamic walking mechanism. This study proposes a compass model with a wobbling mass connected to the upper body and oscillating in the horizontal direction to clarify the influence of the horizontal dynamics of the upper body on bipedal walking. The limit cycles of the model were numerically searched, and their stability and energy efficiency was investigated. Several qualitatively different limit cycles were obtained depending mainly on the spring constant that supports the wobbling mass. Specific types of solutions decreased the stability while reducing the risk of accidental falling and improving the energy efficiency. The obtained results were attributed to the wobbling mass moving in the opposite direction to the upper body, thereby preventing large changes in acceleration and deceleration while walking. The relationship between the locomotion of the proposed model and the actual biped robot and human gaits was investigated. keywords: {Legged locomotion;Dynamics;Limit-cycles;Stability analysis;Energy efficiency;Numerical models;Compass},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160772&isnumber=10160212

M. Tucker, N. Csomay-Shanklin and A. D. Ames, "Robust Bipedal Locomotion: Leveraging Saltation Matrices for Gait Optimization," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12218-12225, doi: 10.1109/ICRA48891.2023.10161309.Abstract: The ability to generate robust walking gaits on bipedal robots is key to their successful realization on hard-ware. To this end, this work extends the method of Hybrid Zero Dynamics (HZD) – which traditionally only accounts for locomotive stability via periodicity constraints under perfect impact events – through the inclusion of the saltation matrix with a view toward synthesizing robust walking gaits. By jointly minimizing the norm of the extended saltation matrix and the torque of the robot directly in the gait generation process, we demonstrate that the synthesized gaits are more robust than gaits generated with either term alone; these results are shown in simulation and on hardware for the AMBER-3M planar biped and the Atalante lower-body exoskeleton (both with and without a human subject). The end result is experimental validation that combining saltation matrices with HZD methods produces more robust bipedal walking in practice. keywords: {Legged locomotion;Transmission line matrix methods;Torque;Exoskeletons;Hardware;Stability analysis;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161309&isnumber=10160212

J. Shim, C. Mastalli, T. Corbères, S. Tonneau, V. Ivan and S. Vijayakumar, "Topology-Based MPC for Automatic Footstep Placement and Contact Surface Selection," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12226-12232, doi: 10.1109/ICRA48891.2023.10160333.Abstract: State-of-the-art approaches to footstep planning assume reduced-order dynamics when solving the combinatorial problem of selecting contact surfaces in real time. However, in exchange for computational efficiency, these approaches ignore joint torque limits and limb dynamics. In this work, we address these limitations by presenting a topology-based approach that enables model predictive control (MPC) to simultaneously plan full-body motions, torque commands, footstep placements, and contact surfaces in real time. To determine if a robot's foot is inside a contact surface, we borrow the winding number concept from topology. We then use this winding number and potential field to create a contact-surface penalty function. By using this penalty function, MPC can select a contact surface from all candidate surfaces in the vicinity and determine footstep placements within it. We demonstrate the benefits of our approach by showing the impact of considering full-body dynamics, which includes joint torque limits and limb dynamics, on the selection of footstep placements and contact surfaces. Furthermore, we validate the feasibility of deploying our topology-based approach in an MPC scheme and explore its potential capabilities through a series of experimental and simulation trials. keywords: {Torque;Windings;Dynamics;Pipelines;Humanoid robots;Real-time systems;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160333&isnumber=10160212

M. Elobaid, G. Romualdi, G. Nava, L. Rapetti, H. A. Omer Mohamed and D. Pucci, "Online Non-linear Centroidal MPC for Humanoid Robots Payload Carrying with Contact-Stable Force Parametrization," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12233-12239, doi: 10.1109/ICRA48891.2023.10161086.Abstract: In this paper we consider the problem of allowing a humanoid robot that is subject to a persistent disturbance, in the form of a payload-carrying task, to follow given planned footsteps. To solve this problem, we combine an online nonlinear centroidal Model Predictive Controller - MPC with a contact stable force parametrization. The cost function of the MPC is augmented with terms handling the disturbance and regularizing the parameter. The performance of the resulting controller is validated both in simulations and on the humanoid robot iCub. Finally, the effect of using the parametrization on the computational time of the controller is briefly studied. keywords: {Automation;Computational modeling;Force;Humanoid robots;Predictive models;Cost function;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161086&isnumber=10160212

J. Colombel, D. Daney and F. Charpillet, "Holistic view of Inverse Optimal Control by introducing projections on singularity curves," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12240-12246, doi: 10.1109/ICRA48891.2023.10161163.Abstract: Inverse optimal control (IOC) is a framework used in many fields, especially in robotics and human motion analysis. In this context, various methods of resolution have been proposed in the literature. This article presents Projected Inverse Optimal Control (PIOC), an approach that offers a simple and comprehensive view of IOC methods. Especially, we explain how uncertainties can be properly addressed in our view. Thus, this article highlights how classical methods can be understood as projections of trajectories in the solution space of the underlying Direct Optimal Control (DOC) problem. This perspective allows for an examination of projections other than the classical methods, which can be fruitful for researchers in the field. As an example, we propose a projection that allows us to choose the underlying cost functions of an IOC problem from a set. The IOC's sub-problems are also addressed, such as modelling observed trajectories, noise measurement and the reliability of solutions obtained by IOC. Our proposal is supported by a simple and canonical example throughout the document. keywords: {Deep learning;Uncertainty;Optimal control;Robot sensing systems;Cost function;Trajectory;Reliability;Inverse Optimal Control;Human Motion Analysis;Identification},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161163&isnumber=10160212

J. Welde, M. D. Kvalheim and V. Kumar, "The Role of Symmetry in Constructing Geometric Flat Outputs for Free-Flying Robotic Systems," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12247-12253, doi: 10.1109/ICRA48891.2023.10160628.Abstract: Mechanical systems naturally evolve on principal bundles describing their inherent symmetries. The ensuing factorization of the configuration manifold into a symmetry group and an internal shape space has provided deep insights into the locomotion of many robotic and biological systems. On the other hand, the property of differential flatness has enabled efficient, effective planning and control algorithms for various robotic systems. Yet, a practical means of finding a flat output for an arbitrary robotic system remains an open question. In this work, we demonstrate surprising new connections between these two domains, for the first time employing symmetry directly to construct a flat output. We provide sufficient conditions for the existence of a trivialization of the bundle in which the group variables themselves are a flat output. We call this a geometric flat output, since it is equivariant (i.e. it preserves the symmetry) and often global or almost global, properties not typically enjoyed by other flat outputs. In such a trivialization, the motion planning problem is easily solved, since a given trajectory for the group variables will fully determine the trajectory for the shape variables that exactly achieves this motion. We provide a partial catalog of robotic systems with geometric flat outputs and worked examples for the planar rocket, planar aerial manipulator, and quadrotor. keywords: {Sufficient conditions;Rockets;Shape;Aerospace electronics;Manipulators;Planning;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160628&isnumber=10160212

F. Han and J. Yi, "On the Learned Balance Manifold of Underactuated Balance Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12254-12260, doi: 10.1109/ICRA48891.2023.10161088.Abstract: Tracking control of underactuated balance robots needs to estimate balance profiles, that is, balance equilibrium manifold (BEM) of the unactuated subsystems. We present a learning-based approach to obtain the balance manifold for underactuated balance robots. We first establish the relationship between the BEM and the zero dynamics of the underactuated balance robots. The analysis shows that the BEM is a close approximation of the equilibria of the zero dynamics under perfectly tracking control. A Gaussian process learning-based method is proposed to estimate and obtain the BEM and zero dynamics, avoiding the direct inversion of the physics-based robot dynamic model. We demonstrate the analysis and applications experimentally on a rotary inverted pendulum and a bipedal robot. keywords: {Manifolds;Learning systems;Analytical models;Automation;Robot control;Estimation;Gaussian processes},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161088&isnumber=10160212

S. Bhat and I. Stenius, "Controlling an Underactuated AUV as an Inverted Pendulum using Nonlinear Model Predictive Control and Behavior Trees," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12261-12267, doi: 10.1109/ICRA48891.2023.10160926.Abstract: Agile and hydrobatic maneuvering capabilities can enhance AUV operations in increasingly challenging scenarios. In this paper, we explore the ability of an underactuated AUV to transition to and hold a pitch angle close to 90 degrees at a particular depth, like an inverted pendulum. Holding such an orientation can be valuable in observing a calving glacier, under-ice launch and recovery, underwater docking, inspecting vertical structures, and observing targets above the water surface. However, such control is challenging because of underactuation, rapid response times and varying stability in different configurations. To address this, a control policy is derived offline using nonlinear MPC in a high-fidelity simulation environment in Simulink. For real-time control, a hybrid controller using a behavior tree (BT) is developed based on the optimal MPC policy and applied on the AUV system. The BT controller considers Safety, Transit and Stabilize behaviors. The control algorithm is validated with simulations in Simulink and Stonefish-ROS as well as field experiments with the hydrobatic SAM AUV, showing repeatable performance in the inverted pendulum maneuver. keywords: {Software packages;Prediction algorithms;Real-time systems;Stability analysis;Behavioral sciences;Safety;Steady-state},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160926&isnumber=10160212

S. Wang, X. Chu and K. W. S. Au, "Towards Exact Interaction Force Control for Underactuated Quadrupedal Systems with Orthogonal Projection and Quadratic Programming," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12268-12274, doi: 10.1109/ICRA48891.2023.10160835.Abstract: Projected Inverse Dynamics Control (PIDC) is commonly used in robots subject to contact, especially in quadrupedal systems. Many methods based on such dynamics have been developed for quadrupedal locomotion tasks, and only a few works studied simple interactions between the robot and environment, such as pressing an E-stop button. To facilitate the interaction requiring exact force control for safety, we propose a novel interaction force control scheme for under-actuated quadrupedal systems relying on projection techniques and Quadratic Programming (QP). This algorithm allows the robot to apply a desired interaction force to the environment without using force sensors while satisfying physical constraints and inducing minimal base motion. Unlike previous projection-based methods, the QP design uses two selection matrices in its hierarchical structure, facilitating the decoupling between force and motion control. The proposed algorithm is verified with a quadrupedal robot in a high-fidelity simulator. Compared to the QP designs without the strategy of using two selection matrices and the PIDC method for contact force control, our method provided more accurate contact force tracking performance with minimal base movement, paving the way to approach the exact interaction force control for underactuated quadrupedal systems. keywords: {Tracking;Force;Pressing;Robot sensing systems;Safety;Quadrupedal robots;Quadratic programming},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160835&isnumber=10160212

T. Kaneko, G. Minamoto, Y. Hirose and T. Sakai, "Reinforcement Learning for Laser Welding Speed Control Minimizing Bead Width Error," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12275-12281, doi: 10.1109/ICRA48891.2023.10161334.Abstract: In this paper, we propose a method for reinforcement learning-based laser welding control. Conventional methods apply standard reinforcement learning formulations to welding tasks, but we show that this formulation can minimize bead width or penetration depth errors only when the welding speed is constant. Therefore, conventional methods are suboptimal for training control parameters including the welding speed. The proposed method discounts future rewards with respect to the welding length instead of time steps to solve this issue. This is easily implemented by (1) modifying the discount factor used for $Q$-function updates in existing reinforcement learning algorithms and (2) using an appropriate reward function. Experimental results using simulators show that the proposed method achieves performance that is superior to conventional methods. keywords: {Training;Automation;Welding;Lasers;Velocity control;Reinforcement learning;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161334&isnumber=10160212

J. Lee, M. Seo, A. Bylard, R. Sun and L. Sentis, "Real-Time Model Predictive Control for Industrial Manipulators with Singularity-Tolerant Hierarchical Task Control," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12282-12288, doi: 10.1109/ICRA48891.2023.10161138.Abstract: This paper proposes a real-time model predictive control (MPC) strategy for accomplishing multiple tasks using robots within a finite-time horizon. In industrial robotic applications, it is crucial to consider various constraints to ensure that joint position, velocity, and torque limits are not exceeded. In addition, singularity-free and smooth motions require executing tasks continuously and safely. Instead of formulating nonlinear MPC problems, we devise linear MPC problems using kinematic and dynamic models linearized along nominal trajectories produced by hierarchical controllers. These linear MPC problems are solvable via the use of Quadratic Pro-gramming; therefore, we significantly reduce the computation time of the proposed MPC framework so the resulting update frequency is higher than 1 kHz. Our proposed MPC framework is more efficient in reducing task tracking errors than a baseline based on operational space control (OSC). We validate our approach in numerical simulations and in real experiments using an industrial manipulator. More specifically, we deploy our method in two practical scenarios for robotic logistics: 1) controlling a robot carrying heavy payloads while accounting for torque limits, and 2) controlling the end-effector while avoiding singularities. keywords: {Torque;Service robots;Computational modeling;Real-time systems;Trajectory;Task analysis;Manipulator dynamics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161138&isnumber=10160212

H. He et al., "High-Speed High-Accuracy Spatial Curve Tracking Using Motion Primitives in Industrial Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12289-12295, doi: 10.1109/ICRA48891.2023.10161022.Abstract: Industrial robots are increasingly deployed in applications requiring an end effector tool to closely track a specified path, such as in spraying and welding. Performance and productivity present possibly conflicting objectives: tracking accuracy, path speed, and motion uniformity. Industrial robots are programmed through motion primitives consisting of waypoints connected by pre-defined motion segments, with specified parameters such as path speed and blending zone. The actual executed robot motion depends on the robot joint servo controller and joint motion constraints (e.g., velocity, acceleration limits) which are largely unknown to the users. Programming a robot to achieve the desired performance today is time-consuming and mostly manual, requiring tuning a large number of coupled parameters in the motion primitives. The performance also depends on the choice of additional param-eters: possible redundant degrees of freedom, location of the target curve, and the robot configuration. This paper presents a systematic approach to optimize robot motion parameters. The approach first selects the static parameters, then chooses the motion primitives, and finally iteratively updates the waypoints to minimize the tracking error. The ultimate performance objective is to maximize the path speed subject to the tracking accuracy and speed uniformity constraints over the entire path. We have demonstrated the effectiveness of this approach both in simulation and on physical systems for ABB and FANUC robots applied to two challenging example curves. Comparing with the baseline using the current industry practice, the optimized performance shows over 100% performance improvement. keywords: {Robot motion;Target tracking;Systematics;Tracking;Service robots;Welding;Spraying;Industrial Robot;Motion Primitive;Path Opti-mization;Redundancy Resolution;Trajectory Tracking},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161022&isnumber=10160212

H. Y. Park and J. H. Kim, "A New Robust Control Framework for Robot Manipulators without Velocity Measurements: A Modified Dual-loop Control Scheme," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12296-12301, doi: 10.1109/ICRA48891.2023.10160485.Abstract: This paper proposes a new framework for the computed torque method (CTM) of robot manipulators without velocity measurements. We first introduce the Luenberger-observer-based CTM with only position measurements. We then clarify that the external disturbance affects not only the tracking performances with respect to the plant but also the estimation accuracies relevant to the state observer. To address this problem, we establish a new architecture for the so-called dual-loop control scheme, by which both the tracking performances and estimation accuracies can be simultaneously improved, in contrast to its existing structure. A guideline for taking control parameters corresponding to the proposed control structure is also provided with respect to the stabilization of the overall closed-loop systems. Finally, simulation and experimental results are provided to demonstrate the validity and practical feasibility of the developed structure. keywords: {Robust control;Estimation error;Torque;Trajectory tracking;Computer architecture;Position measurement;Manipulators},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160485&isnumber=10160212

B. Balci, J. Donovan, J. Roberts and P. Corke, "Optimal Workpiece Placement Based on Robot Reach, Manipulability and Joint Torques," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12302-12308, doi: 10.1109/ICRA48891.2023.10161031.Abstract: Workpiece placement with respect to an industrial robot plays an important role in robotic manufacturing due to its influence on the configuration-dependent properties of industrial robots. Suboptimal placements of the workpiece may increase the required joint torques and decrease the dexterity of the robot. The focus of this work is to identify an optimal workpiece pose that enables a robot to carry out surface finishing with configurations that require the lowest possible joint torques while having maximum possible manipulability. We present a non-linear optimization-based algorithm to solve this problem and demonstrate the algorithm's capability on dif-ferent workpieces which we share to facilitate further research in this area. keywords: {Automation;Service robots;Industrial robots;Manufacturing;Surface finishing;Optimization},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161031&isnumber=10160212

X. Yang, O. Lakhal, A. Belarouci, K. Youcef-Toumi and R. Merzouki, "Experimental Workflow Implementation for Automatic Detection of Filament Deviation in 3D Robotic Printing Process," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12309-12315, doi: 10.1109/ICRA48891.2023.10161457.Abstract: Robotic 3D Concrete Printing (3DCP) is a process of additive manufacturing using building materials. The system that performs 3DCP is a complex system consisting of multiple parts that are independent of each other. However, conventional 3DCP workflows usually lack automatic monitoring of print quality which can be easily affected for various reasons. This paper proposes an integrated workflow of automatic detection of filament deviation in a 3DCP process. The deformation of the filament is adopted as the criterion for print quality evaluation. A Deep Learning-morphology-based filament width estimation method is developed, and a filament deviation detection algorithm with presence of parametric uncertainties is proposed. This workflow allows to detect width deviations in the printed filament by considering several parameters of the printing system. The integrated workflow is implemented and tested through on-site printing tests. keywords: {Uncertainty;Three-dimensional displays;Deformation;Morphology;Estimation;Transforms;Three-dimensional printing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161457&isnumber=10160212

S. K. Das, M. H. Uddin, D. O. Popa and S. Baidya, "Neuro-Adaptive Dynamic Control with Edge-Computing for Collaborative Digital Twin of an Industrial Robotic Manipulator," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12316-12323, doi: 10.1109/ICRA48891.2023.10161113.Abstract: With the advancement of industrial manufacturing and an increase in introduction of robots in the workspace, the need of safe operation, communication and information sharing is paramount. The work presented here focuses on cyber-physical system integration through Digital Twin (DT) technology. Our novel DT architecture is based on a model-free Neuro-Adaptive controller (NAC), and an edge-computing scheme for scene monitoring. The NAC can account for varying robot dynamics in both real and virtual environments, and allows for the DT system to expand the realm of cyber-physical integration without expensive model tuning. The edge-computing device introduced in our architecture, observes the robot's workspace from a distance with a wider field of view. This wide viewpoint, enhances the detection and mitigation of any obstacles entering the robot's workspace during operation. We experimentally evaluated the performance of our proposed architecture by introducing dynamic obstacles during a pick-and-place task that both the physical robot and its digital twin had to avoid. Results show that the proposed DT architecture successfully integrates the novel controller and edge-computing elements and successfully performs the given navigation task. The results also show that NAC outperforms a PD controller with more than 70% improvement in joint tracking error between the physical and virtual robots. It was observed that the latency experienced while using NAC is about 48 % lower than when Proportional-Derivative (PD) controller was operational. keywords: {Performance evaluation;Service robots;Operating systems;Virtual environments;Digital twins;PD control;Task analysis;Industry 5.0;Digital Twin;Edge-Computing;Neuro-Adaptive Controller (NAC);Smart Manufacturing;Simulation;Robot Operating System (ROS)},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161113&isnumber=10160212

Y. Kim, A. Kramberger, A. G. Buch and C. Sloth, "Contact-Based Pose Estimation of Workpieces for Robotic Setups," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12324-12330, doi: 10.1109/ICRA48891.2023.10161465.Abstract: This paper presents a method for contact-based pose estimation of workpieces using a collaborative robot. The proposed pose estimation exploits positions and surface normal vectors along an arbitrary path on an object with known geometry, where surface normal vectors are estimated based on contact forces measured by the robot. When data is only available along a single path, it is difficult to find initial correspondences between source data (recorded points and normal vectors) and target data (CAD of an object); hence, a novel weighted incremental spatial search approach for generating correspondences based on point pair features is proposed. Subsequently, robust pose estimation is employed to reduce the effect of erroneous correspondences. The proposed pose estimation is verified in simulation on three paths on two objects and with different levels of noise on the source data to quantify the robustness of the algorithm. Finally, the method is experimentally validated to provide an average pose rotation and translation accuracy of $\mathbf{0.55}^{\circ}$ and 0.51 mm, respectively, when using the robust estimation cost function Geman-McClure. keywords: {Geometry;Solid modeling;Force measurement;Simulation;Pose estimation;Collaboration;Position measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161465&isnumber=10160212

B. Parilusyan, M. Teyssier, Z. Guillaume, T. Charlet, C. Duhart and M. Serrano, "Local Layer Splitting: An Additive Manufacturing Method to Define the Mechanical Properties of Soft Pneumatic Actuators During Fabrication," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12331-12337, doi: 10.1109/ICRA48891.2023.10161245.Abstract: Additive manufacturing of silicone is increasingly being explored to complement the traditional molding fabrication technique for Soft Pneumatic Actuators (SPAs). However, the mechanical behavior of SPAs is defined by their 3D form, which leads to prioritizing the SPAs mechanical properties over their aspect. In this paper, we propose a novel SPA fabrication method where the mechanical properties of a silicone part are defined during the fabrication phase rather than the 3D modeling phase, leading to the object's mechanical properties being independent of the object's aspect. This novel SPA fabrication method, named Local Layer Splitting (LLS), consists of local modifications of the printing layer height to integrate stiffness variation, thus generating controlled mechanical deformation when pressured. We discovered that silicone printing layer height impacts the final stiffness of the material, and it could be used to program bending deformation to actuators during printing. We first characterize the effect of the layer height parameters on 3D-printed silicone stiffness with tensile tests. Then, we present a custom slicer we developed to generate G-codes with local layer height variations depending on the x and y positions. We then characterize the bending and force achievable by SPAs made with the LLS process and find that they match those of state-of-the-art SPAs. Finally, we present and discuss how the LLS method impacts the SPAs design by shifting the bending behavior integration from the SPAs 3D conception to their fabrication phase. keywords: {Fabrication;Pneumatic actuators;Three-dimensional displays;Deformation;Shape;Thumb;Bending},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161245&isnumber=10160212

T. Zhang, Y. Huang, P. Kukulski, N. Dutta, G. Fang and C. C. L. Wang, "Support Generation for Robot-Assisted 3D Printing with Curved Layers," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12338-12344, doi: 10.1109/ICRA48891.2023.10161432.Abstract: Robot-assisted 3D printing has drawn a lot of attention by its capability to fabricate curved layers that are optimized according to different objectives. However, the support generation algorithm based on a fixed printing direction for planar layers cannot be directly applied for curved layers as the orientation of material accumulation is dynamically varied. In this paper, we propose a skeleton-based support generation method for robot-assisted 3D printing with curved layers. The support is represented as an implicit solid so that the problems of numerical robustness can be effectively avoided. The effectiveness of our algorithm is verified on a dual-material printing platform that consists of a robotic arm and a newly designed dual-material extruder. Experiments have been successfully conducted on our system to fabricate a variety of freeform models. keywords: {Automation;Heuristic algorithms;Three-dimensional printing;Solids;Manipulators;Robustness;Numerical models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161432&isnumber=10160212

K. Liao, T. Tricard, M. Piovarči, H. -P. Seidel and V. Babaei, "Learning Deposition Policies for Fused Multi-Material 3D Printing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12345-12352, doi: 10.1109/ICRA48891.2023.10160465.Abstract: 3D printing based on continuous deposition of materials, such as filament-based 3D printing, has seen widespread adoption thanks to its versatility in working with a wide range of materials. An important shortcoming of this type of technology is its limited multi-material capabilities. While there are simple hardware designs that enable multi-material printing in principle, the required software is heavily underdeveloped. A typical hardware design fuses together individual materials fed into a single chamber from multiple inlets before they are deposited. This design, however, introduces a time delay between the intended material mixture and its actual deposition. In this work, inspired by diverse path planning research in robotics, we show that this mechanical challenge can be addressed via improved printer control. We propose to formulate the search for optimal multi-material printing policies in a reinforcement learning setup. We put forward a simple numerical deposition model that takes into account the non-linear material mixing and delayed material deposition. To validate our system we focus on color fabrication, a problem known for its strict requirements for varying material mixtures at a high spatial frequency. We demonstrate that our learned control policy outperforms state-of-the-art hand-crafted algorithms. keywords: {Fabrication;Software algorithms;Color;Reinforcement learning;Three-dimensional printing;Hardware;Software},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160465&isnumber=10160212

Z. Wu, S. Su, Q. Chen and R. Fan, "Transparent Objects: A Corner Case in Stereo Matching," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12353-12359, doi: 10.1109/ICRA48891.2023.10161385.Abstract: Stereo matching is a common technique used in 3D perception, but transparent objects such as reflective and penetrable glass pose a challenge as their disparities are often estimated inaccurately. In this paper, we propose transparency-aware stereo (TA-Stereo), an effective solution to tackle this issue. TA-Stereo first utilizes a semantic segmentation or salient object detection network to identify transparent objects, and then homogenizes them to enable stereo matching algorithms to handle them as non-transparent objects. To validate the effectiveness of our proposed TA-Stereo strategy, we collect 260 images containing transparent objects from the KITTI Stereo 2012 and 2015 datasets and manually label pixel-level ground truth. We evaluate our strategy with six deep stereo networks and two types of transparent object detection methods. Our experiments demonstrate that TA-Stereo significantly improves the disparity accuracy of transparent objects. Our project webpage can be accessed at mias.group/TA-Stereo. keywords: {Three-dimensional displays;Automation;Semantic segmentation;Object detection;Glass;Reflection;Object recognition},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161385&isnumber=10160212

Y. Feng, B. Xue, M. Liu, Q. Chen and R. Fan, "D2NT: A High-Performing Depth-to-Normal Translator," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12360-12366, doi: 10.1109/ICRA48891.2023.10161000.Abstract: Surface normal holds significant importance in visual environmental perception, serving as a source of rich geometric information. However, the state-of-the-art (SoTA) surface normal estimators (SNEs) generally suffer from an unsatisfactory trade-off between efficiency and accuracy. To resolve this dilemma, this paper first presents a superfast depth-to-normal translator (D2NT), which can directly translate depth images into surface normal maps without calculating 3D coordinates. We then propose a discontinuity-aware gradient (DAG) filter, which adaptively generates gradient convolution kernels to improve depth gradient estimation. Finally, we propose a surface normal refinement module that can easily be integrated into any depth-to-normal SNEs, substantially improving the surface normal estimation accuracy. Our proposed algorithm demonstrates the best accuracy among all other existing real-time SNEs and achieves the SoTA trade-off between efficiency and accuracy. keywords: {Visualization;Three-dimensional displays;Image resolution;Automation;Convolution;Estimation;Filtering algorithms},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161000&isnumber=10160212

B. Cui, K. Zhu, S. Li and X. Yin, "Security-Aware Reinforcement Learning under Linear Temporal Logic Specifications," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12367-12373, doi: 10.1109/ICRA48891.2023.10160753.Abstract: In this paper, we investigate the problem of reinforcement learning under linear temporal logic (LTL) specifications for Markov decision processes (MDPs) with security constraints. We consider an outside passive intruder (observer) that can observe the external output behavior of the system through an output projection. We assume that the secret of the system is a subset of the initial states. The security constraint requires that the observer can never infer for sure that the agent was initiated from a secret state. Our objective is to learn a control policy that achieves the LTL task while ensuring security. To solve the problem of shaping the reward for reinforcement learning, we propose an approach based on the initial-state estimator and the limit deterministic Büchi automata. We illustrate the proposed approach by a case study of mobile robot example. keywords: {Automation;Learning automata;Reinforcement learning;Observers;Markov processes;Behavioral sciences;Security},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160753&isnumber=10160212

Z. Wu, W. Wang, J. Zhang, Q. Lyu, H. Zhang and D. Wang, "Global Localization in Repetitive and Ambiguous Environments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12374-12380, doi: 10.1109/ICRA48891.2023.10161479.Abstract: Accurate global localization is an essential ingredient for autonomous mobile robots (AMRs) operating in enclosed or partially enclosed repetitive environments (e.g., office corridors, industrial warehouses, transportation centers). In such environments, the Global Navigation Satellite System (GNSS) signals are unreliable or severely degraded. The highly ambiguous structures in such challenging scenarios would also lead the ordinary geometric feature-based LiDAR/visual localization methods to fail. The ambient magnetic field (MF) has exhibited high distinctiveness at different location, which makes it a viable alternative for infrastructure-free AMR localization. However, few of the previous research has been focused on the orientation-dependency and similar-sequential-route limitations of MF-based localization. Thus, this paper proposes a novel probabilistic global localization system with 2-D LiDAR and rotation-invariant magnetic field for AMRs operating in challenging repetitive and ambiguous environments. The proposed localization system mainly consists of: 1) Two-step Initialization: laser distance and MF sequence based matching, and 2) MF-based Pose Tracking: recursive multi-dimensional MF sequence based matching. Extensive experimental results demonstrate the advantageous localization performances of the proposed localization system over the existing methods. keywords: {Location awareness;Global navigation satellite system;Laser radar;Lasers;Transportation;Lead;Probabilistic logic},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161479&isnumber=10160212

M. Braun and S. Wrede, "Grey-Box Learning of Adaptive Manipulation Primitives for Robotic Assembly," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12381-12387, doi: 10.1109/ICRA48891.2023.10161077.Abstract: Autonomous learning of robotic manipulation tasks is a promising approach to reduce manual engineering effort and increase flexibility in the future of industrial manufacturing. Although a lot of research has been done especially robotic assembly tasks requiring contact-rich compliant interaction remain a challenge for learning-based methods, since large amounts of interaction data are required. Incorporation of prior knowledge has long been seen as a possibility to make learning-based approaches tractable. The question is how can we enable process experts to encode their prior knowledge in grey-box models so that it can be used for learning robotic manipulation tasks? For that reason we propose a new grey-box learning approach, “Adaptive Manipulation Primitives” (AMP), introduced in this paper. AMPs combine compliant manipulation task specifications based on Manipulation Primitives Nets with Policy Gradient Reinforcement Learning. Our framework is evaluated in a real-world robotic assembly task. It is shown that learning to assemble industrial connector modules is possible with comparatively few real-world trials. keywords: {Robotic assembly;Learning systems;Connectors;Adaptation models;Automation;Service robots;Reinforcement learning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161077&isnumber=10160212

A. Cebulla, T. Asfour and T. Kröger, "Speeding Up Assembly Sequence Planning Through Learning Removability Probabilities," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12388-12394, doi: 10.1109/ICRA48891.2023.10160920.Abstract: Industry 4.0 facilitates a high number of product variants, posing significant challenges for modern manufacturing. One of them is the automatic creation of assembly sequences. This can be achieved with the assembly-by-disassembly (AbD) approach, which is currently highly inefficient. We aim at speeding up AbD by leveraging deep learning. AbD relies on iteratively testing parts for removal, which makes the order in which parts are tested highly relevant for its run-time. We optimize this order by training a graph neural network (GNN) based on the shape of parts and the shape of local part connections. For each part, it predicts a removability probability. We use these probabilities to optimize the order in which parts are tested for removal. This reduces the number of parts tested by approximately 64%-90%, depending on the tested product. Further improvements are achieved by combining our approach with bookkeeping, another approach for speeding up AbD. Finally, we separately analyze the impact of the parts and their connections on the removability probabilities predicted by the GNN. We found that most of the important information regarding a part's removability can be derived from its connections alone. keywords: {Training;Deep learning;Shape;Graph neural networks;Planning;Fourth Industrial Revolution;Testing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160920&isnumber=10160212

L. Ma et al., "Planning Assembly Sequence with Graph Transformer," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12395-12401, doi: 10.1109/ICRA48891.2023.10160424.Abstract: Assembly Sequence Planning (ASP) is the essential process for modern manufacturing, proven to be NP-complete thus its effective and efficient solution has been a challenge for researchers in the field. In this paper, we present a graph-transformer based framework for the ASP problem which is trained and demonstrated on a self-collected ASP database. The ASP database contains a self-collected set of LEGO models. The LEGO model is abstracted to a heterogeneous graph structure after a thorough analysis of the original structure and feature extraction. The ground truth assembly sequence is first generated by brute-force search and then adjusted manually to be in line with human rational habits. Based on this self-collected ASP dataset, we propose a heterogeneous graph-transformer framework to learn the latent rules for assembly planning. We evaluated the proposed framework in a series of experiments. The results show that the similarity of the predicted and ground truth sequences can reach 0.44, a medium correlation measured by Kendall's τ. Meanwhile, we compared the different effects of node features and edge features and generated a feasible and reasonable assembly sequence as a benchmark for further research. Our dataset and code are available on: htps://github.com/AIR-DISCOVER/ICRA_ASP. keywords: {Analytical models;Correlation;Codes;Automation;Databases;Benchmark testing;Transformers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160424&isnumber=10160212

B. -S. Lu, T. -I. Chen, H. -Y. Lee and W. H. Hsu, "CFVS: Coarse-to-Fine Visual Servoing for 6-DoF Object-Agnostic Peg-In-Hole Assembly," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12402-12408, doi: 10.1109/ICRA48891.2023.10160525.Abstract: Robotic peg-in-hole assembly remains a challenging task due to its high accuracy demand. Previous work tends to simplify the problem by restricting the degree of freedom of the end-effector, or limiting the distance between the target and the initial pose position, which prevents them from being deployed in real-world manufacturing. Thus, we present a Coarse-to-Fine Visual Servoing (CFVS) peg-in-hole method, achieving 6-DoF end-effector motion control based on 3D visual feedback. CFVS can handle arbitrary tilt angles and large initial alignment errors through a fast pose estimation before refinement. Furthermore, by introducing a confidence map to ignore the irrelevant contour of objects, CFVS is robust against noise and can deal with various targets beyond training data. Extensive experiments show CFVS outperforms state-of-the-art methods and obtains 100%, 91%, and 82% average success rates in 3-DoF, 4-DoF, and 6-DoF peg-in-hole, respectively. keywords: {Visualization;Three-dimensional displays;Shape;Pose estimation;Training data;6-DOF;Visual servoing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160525&isnumber=10160212

G. Scher, S. Sadraddini and H. Kress-Gazit, "Probabilistic Rare-Event Verification for Temporal Logic Robot Tasks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12409-12415, doi: 10.1109/ICRA48891.2023.10161083.Abstract: We present a method for calculating the probability that a robot successfully performs a task described using Signal Temporal Logic (STL). We focus on cases where the failure probability is very small, hence a traditional Monte-Carlo method becomes inefficient due to the large number of samples required to observe failures. Using elliptical sliced sampling, normalizing flows, and Bayesian optimization, we develop an algorithm that, under mild assumptions, is applicable to black-box systems, and can be applied to uncertainty sources with non-Gaussian probabilities. We demonstrate the application of our method on three different simulated robots. keywords: {Uncertainty;Monte Carlo methods;Automation;Closed box;Probabilistic logic;Bayes methods;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161083&isnumber=10160212

W. Liu, M. Nishioka and C. Belta, "Safe Model-based Control from Signal Temporal Logic Specifications Using Recurrent Neural Networks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12416-12422, doi: 10.1109/ICRA48891.2023.10161201.Abstract: We propose a policy search approach to learn controllers from specifications given as Signal Temporal Logic (STL) formulae. The system model, which is unknown but assumed to be an affine control system, is learned together with the control policy. The model is implemented as two feedforward neural networks (FNNs) - one for the drift, and one for the control directions. To capture the history dependency of STL specifications, we use a recurrent neural network (RNN) to implement the control policy. In contrast to prevalent model-free methods, the learning approach proposed here takes advantage of the learned model and is more efficient. We use control barrier functions (CBFs) with the learned model to improve the safety of the system. We validate our algorithm via simulations and experiments. The results show that our approach can satisfy the given specification within very few system runs, and can be used for on-line control. keywords: {Training;Fuzzy control;Recurrent neural networks;Automation;Control systems;Robustness;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161201&isnumber=10160212

G. A. Cardona, K. Leahy and C. -I. Vasile, "Temporal Logic Swarm Control with Splitting and Merging," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12423-12429, doi: 10.1109/ICRA48891.2023.10160335.Abstract: This paper presents an agent-agnostic framework to control swarms of robots tasked with temporal and logical missions expressed as Metric Temporal Logic (MTL) formulas. We consider agents that can receive global commands from a high-level planner, but no inter-agent communication. Moreover, agents are grouped into sub-swarms whose number can vary over the mission time horizon due to splitting and merging. However, a strict upper bound on the maximum number of sub-swarms is imposed to ensure their safe operation in the environment. We propose a two-phase approach. In the first phase, we compute the trajectories of the sub-swarms, splitting, and merging actions using a Mixed Integer Linear Programming approach that ensures the satisfaction of the MTL specification with minimal swarm division over the mission time horizon. Moreover, it enforces the upper bound on the number of sub-swarms. In the second phase, splitting fractions for sub-swarms resulting from splitting actions are computed. A distributed randomized protocol with no interagent communication ensures agent assignments matching the splitting fractions. Finally, we show the operation and performance of the approach in simulations with multiple tasks that require swarm splitting or merging. keywords: {Measurement;Upper bound;Protocols;Merging;Dynamics;Trajectory;Mixed integer linear programming},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160335&isnumber=10160212

A. Badithela, J. B. Graebener, W. Ubellacker, E. V. Mazumdar, A. D. Ames and R. M. Murray, "Synthesizing Reactive Test Environments for Autonomous Systems: Testing Reach-Avoid Specifications with Multi-Commodity Flows," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12430-12436, doi: 10.1109/ICRA48891.2023.10160841.Abstract: We study automated test generation for testing discrete decision-making modules in autonomous systems. Linear temporal logic is used to encode the system specification - requirements of the system under test - and the test specification, which is unknown to the system and describes the desired test behavior. The reactive test synthesis problem is to find constraints on system actions such that in a test execution, both the system and test specifications are satisfied. To do this, we use the specifications and their corresponding Büchi automata to construct the specification product automaton. Then, a virtual product graph representing all possible test executions of the system is constructed from the transition system and the specification product automaton. The main result of this paper is framing the test synthesis problem as a multi-commodity network flow optimization. This optimization is used to derive reactive constraints on system actions, which constitute the test environment. The resulting test environment ensures that the system meets the test specification while also satisfying the system specification. We illustrate this framework in simulation using grid world examples and demonstrate it on hardware with the Unitree A1 quadruped, where we test dynamic locomotion behaviors reactively. keywords: {Automation;Autonomous systems;Decision making;Automata;Hardware;Behavioral sciences;Test pattern generators},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160841&isnumber=10160212

X. Luo, J. -T. Lin and T. K. Morimoto, "HaPPArray: Haptic Pneumatic Pouch Array for Feedback in handheld Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12437-12442, doi: 10.1109/ICRA48891.2023.10160648.Abstract: Haptic feedback can provide operators of hand-held robots with active guidance during challenging tasks and with critical information on environment interactions. Yet for such haptic feedback to be effective, it must be lightweight, capable of integration into a hand-held form factor, and capable of displaying easily discernible cues. We present the design and evaluation of HaPPArray - a haptic pneumatic pouch array - where the pneumatic pouches can be actuated alone or in sequence to provide information to the user. A 3x3 array of pouches was integrated into a handle, representative of an interface for a hand-held robot. When actuated individually, users were able to correctly identify the pouch being actuated with 86% accuracy, and when actuated in sequence, users were able to correctly identify the associated direction cue with 89 % accuracy. These results, along with a demonstration of how the direction cues can be used for haptic guidance of a medical robot, suggest that HaPPArray can be an effective approach for providing haptic feedback for hand-held robots. keywords: {Medical robotics;Automation;Pneumatic systems;Haptic interfaces;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160648&isnumber=10160212

