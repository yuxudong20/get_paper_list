G. Cao, J. Jiang, N. Mao, D. Bollegala, M. Li and S. Luo, "Vis2Hap: Vision-based Haptic Rendering by Cross-modal Generation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12443-12449, doi: 10.1109/ICRA48891.2023.10160373.Abstract: To assist robots in teleoperation tasks, haptic rendering which allows human operators access a virtual touch feeling has been developed in recent years. Most previous haptic rendering methods strongly rely on data collected by tactile sensors. However, tactile data is not widely available for robots due to their limited reachable space and the restrictions of tactile sensors. To eliminate the need for tactile data, in this paper we propose a novel method named as Vis2Hap to generate haptic rendering from visual inputs that can be obtained from a distance without physical interaction. We take the surface texture of objects as key cues to be conveyed to the human operator. To this end, a generative model is designed to simulate the roughness and slipperiness of the object's surface. To embed haptic cues in Vis2Hap, we use height maps from tactile sensors and spectrograms from friction coefficients as the intermediate outputs of the generative model. Once Vis2Hap is trained, it can be used to generate height maps and spectrograms of new surface textures, from which a friction image can be obtained and displayed on a haptic display. The user study demonstrates that our proposed Vis2Hap method enables users to access a realistic haptic feeling similar to that of physical objects. The proposed vision-based haptic rendering has the potential to enhance human operators' perception of the remote environment and facilitate robotic manipulation. keywords: {Visualization;Friction;Two dimensional displays;Tactile sensors;Rendering (computer graphics);Surface roughness;Fabrics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160373&isnumber=10160212

Y. Noguchi, Y. Guo and F. Tanaka, "A Plug-In Weight-Shifting Module That Adds Emotional Expressiveness to Inanimate Objects in Handheld Interaction," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12450-12456, doi: 10.1109/ICRA48891.2023.10160659.Abstract: A plug-in weight-shifting module that can be inserted into a variety of objects is presented. The module is equipped with a movable weight inside its body. Three-dimensional weight shifts are presented by controlling one-dimensional translational and two-dimensional rotational movements. To explore the use case of this weight-shifting module, eight weight shift patterns expressing certain emotions were created through a workshop and a qualitative analysis. User tests, to which three different embodiments and scenarios were applied, examined the following three cases: the weight shift patterns were presented to the user by a) a stuffed toy-style robot that mediated human messaging, b) a cushion that made the user relax, and c) a container that enhanced the user's movie-watching experience. User interviews revealed the feasibility of the module and its weight shift patterns for the user's perception of emotions. keywords: {Three-dimensional displays;Automation;Conferences;Containers;Interviews;Robots;robot/agent expression;weight-shifting;emotion;sketch-drawing;OMOY-3D},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160659&isnumber=10160212

M. I. Awan, T. Ogay, W. Hassan, D. Ko, S. Kang and S. Jeon, "Model-Mediated Teleoperation for Remote Haptic Texture Sharing: Initial Study of Online Texture Modeling and Rendering," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12457-12463, doi: 10.1109/ICRA48891.2023.10160503.Abstract: While model-mediated teleoperation (MMT) is an effective alternative for ensuring both transparency and stability, its potential in transmitting surface haptic texture is not yet explored. This paper introduces the first MMT framework capable of sharing surface haptic texture. The follower side collects physical signals contributing to haptic texture perception, e.g., high frequency acceleration, and streams them to the leader side. The leader side uses the signals to build and update a local measurement-based texture simulation model that reflects the remote surface. At the same time, the leader runs local simulation using the model, resulting in non-delayed, stable, and accurate feedback of texture. Considering that rendering haptic texture needs tougher real-time requirements, e.g., higher update rate and lower action-feedback latency, MMT can be a perfect platform for remote texture sharing. An initial proof-of-concept system supporting single and homogeneous surface is implemented and evaluated, demonstrating the potential of the approach. keywords: {Buildings;Rendering (computer graphics);Stability analysis;Real-time systems;Hardware;Data models;Haptic interfaces},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160503&isnumber=10160212

C. A. Braun et al., "Using a Collaborative Robotic Arm as Human-Machine Interface: System Setup and Application to Pose Control Tasks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12464-12470, doi: 10.1109/ICRA48891.2023.10161348.Abstract: While robotic arms have been used in a vast range of application areas, so far no extensive reports on the utilization as human-machine interface exist. Compared to HMI devices from literature, the robotic arm used in this work (KUKA LBR iiwa 14 R820) features a relatively large workspace and is able to generate force and torque feedback that surpasses the capabilities of literature devices. We describe the setup allowing to use the robotic arm as HMI and analytically determine the optimal initial pose of it based on the manipulability measure of Yoshikawa. To demonstrate that the robotic arm is able to serve as HMI, we report on a comparative study with a state of the art haptic HMI featuring 20 participants. Additionally, two applications from the context of planetary exploration are presented: The first considers the teleoperation of the pan-tilt unit of a lightweight rover unit and illustrates how the large workspace of the HMI benefits the precision of the teleoperation compared to a setup with a smaller workspace. The second experiment showcases the use of the force feedback of the HMI to enable a cooperation between the operator and a supporting path-following automation in a shared control of a simulated ground robot. Both the study and the applications highlight the performance, precision and reliability of our proposed system. keywords: {Automation;Torque;Force feedback;Force;Manipulators;Particle measurements;Extraterrestrial measurements},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161348&isnumber=10160212

C. Wang and J. P. Whitney, "Disturbance Observer Based Contact Detection for Motorized Hydraulic Actuators," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12471-12477, doi: 10.1109/ICRA48891.2023.10161250.Abstract: Contact detection without endpoint tactile sensing is challenging; friction and inertia obscure the sensing of low amplitude and high frequency forces. In this work we explore fluidic transmissions as series-elastic actuators, coupled to remotely-located direct-drive brushless motors, in a bid to maximize low-impedance sensitivity to contact while maintaining high bandwidth. We employ a disturbance observer to remove motor friction and further reduce minimum impedance. Using a 2-DOF remotely-actuated hydraulically-coupled robotic gripper, we demonstrate a maximum endpoint Z-width of 40dB and a robust contact detection threshold of 0.2N, without endpoint tactile sensing or joint position sensing. These results enable wiring-free and joint sensor-free arm and end-effector design, which are of particular interest for human-robot interaction, harsh-environment, magnetically-sensitive, and low-cost robotic manipulators that must maintain high bandwidth and high contact sensitivity. keywords: {Brushless motors;Sensitivity;Friction;Force;Hysteresis motors;Robot sensing systems;Magnetic hysteresis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161250&isnumber=10160212

N. L. Williams, N. Rewkowski, J. Li and M. C. Lin, "A Framework for Active Haptic Guidance Using Robotic Haptic Proxies," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12478-12485, doi: 10.1109/ICRA48891.2023.10160996.Abstract: Haptic feedback is an important component of creating an immersive mixed reality experience. Traditionally, haptic forces are rendered in response to the user's interactions with the virtual environment. In this work, we explore the idea of rendering haptic forces in a proactive manner, with the explicit intention to influence the user's behavior through compelling haptic forces. To this end, we present a framework for active haptic guidance in mixed reality, using one or more robotic haptic proxies to influence user behavior and deliver a safer and more immersive virtual experience. We provide details on common challenges that need to be overcome when implementing active haptic guidance, and discuss example applications that show how active haptic guidance can be used to influence the user's behavior. Finally, we apply active haptic guidance to a virtual reality navigation problem, and conduct a user study that demonstrates how active haptic guidance creates a safer and more immersive experience for users. keywords: {Automation;Navigation;Mixed reality;Virtual environments;Immersive experience;Rendering (computer graphics);Haptic interfaces},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160996&isnumber=10160212

C. Zhang, C. Wang, Q. Yang and M. Zhang, "An Optimized Portable Cable-Driven Haptic Robot Enables Free Motion and Hard Contact," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12486-12492, doi: 10.1109/ICRA48891.2023.10161115.Abstract: Task-oriented training with haptic rendering can boost robot-aided motor learning to tasks with similar dynamics. Although multi-DOF robots better match the rendering of real task scenarios, single-DOF haptic robots show great potential for home use with enhanced task rendering performance. This study presents our attempts to optimize and develop a single-DOF cable-driven robot with appropriate workspace and force rendering capacity. The core technologies consist of two aspects: 1) a multi-objective optimization method was adopted to obtain optimal configuration of the haptic robot; and 2) a slider-crank-mechanism-based portable cable-driven robot was developed. Performance evaluation experiments demonstrated that 1) the robot has a workspace larger than 300 mm; 2) the robot can achieve 40 N force output and 40 N. mm-1stiffness for hard contact; 3) the root mean square of the resistance during free motion is 0.93 N; 4) in the purely passive case (without motor compensation), the average resistance to back drive the motor is 2.5 N. These lead us to believe that the developed robot holds the promise to serve as a robotic rehabilitation training platform for home use on the neurological-impaired patients. keywords: {Training;Resistance;Performance evaluation;Gears;Force;Optimization methods;Rendering (computer graphics)},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161115&isnumber=10160212

L. Zhan et al., "Enable Natural Tactile Interaction for Robot Dog based on Large-format Distributed Flexible Pressure Sensors," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12493-12499, doi: 10.1109/ICRA48891.2023.10161049.Abstract: Touch is an important channel for human-robot interaction, while it is challenging for robots to recognize human touch accurately and make appropriate responses. In this paper, we design and implement a set of large-format distributed flexible pressure sensors on a robot dog to enable natural human-robot tactile interaction. Through a heuristic study, we sorted out 81 tactile gestures commonly used when humans interact with real dogs and 44 dog reactions. A gesture classification algorithm based on ResNet is proposed to recognize these 81 human gestures, and the classification accuracy reaches 98.7%. In addition, an action prediction algorithm based on Transformer is proposed to predict dog actions from human gestures, reaching a 1-gram BLEU score of 0.87. Finally, we compare the tactile interaction with the voice interaction during a freedom human-robot-dog interactive playing study. The results show that tactile interaction plays a more significant role in alleviating user anxiety, stimulating user excitement and improving the acceptability of robot dogs. keywords: {Pressure sensors;Automation;Anxiety disorders;Human-robot interaction;Dogs;Robot sensing systems;Transformers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161049&isnumber=10160212

R. Nayeem, S. Bazzi, M. Sadeghi, R. S. Razavian and D. Sternad, "Multi-modal Interactive Perception in Human Control of Complex Objects," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12500-12506, doi: 10.1109/ICRA48891.2023.10160375.Abstract: Tactile sensing has been increasingly utilized in robot control of unknown objects to infer physical properties and optimize manipulation. However, there is limited understanding about the contribution of different sensory modalities during interactive perception in complex interaction both in robots and in humans. This study investigated the effect of visual and haptic information on humans' exploratory interactions with a ‘cup of coffee’, an object with nonlinear internal dynamics. Subjects were instructed to rhythmically transport a virtual cup with a rolling ball inside between two targets at a specified frequency, using a robotic interface. The cup and targets were displayed on a screen, and force feedback from the cup-and-ball dynamics was provided via the robotic manipulandum. Subjects were encouraged to explore and prepare the dynamics by “shaking” the cup-and-ball system to find the best initial conditions prior to the task. Two groups of subjects received the full haptic feedback about the cup-and-ball movement during the task; however, for one group the ball movement was visually occluded. Visual information about the ball movement had two distinctive effects on the performance: it reduced preparation time needed to understand the dynamics and, importantly, it led to simpler, more linear input-output interactions between hand and object. The results highlight how visual and haptic information regarding nonlinear internal dynamics have distinct roles for the interactive perception of complex objects. keywords: {Visualization;Automation;Dynamics;Robot control;Force feedback;Robot sensing systems;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160375&isnumber=10160212

S. Groß et al., "Soft Sensing Skins for Arbitrary Objects: An Automatic Framework," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12507-12513, doi: 10.1109/ICRA48891.2023.10161344.Abstract: Tactile sensors are becoming more prevalent in numerous research domains, including robotics, human-robot interaction, and grasping. As the development of customized soft tactile skin for various applications continues to gain momentum, there is an increasing demand for the automation of design and manufacturing processes based on user specifications. Our work presents a partially automated framework for designing and customizing silicone-based skin-like sensors for objects of arbitrary shapes. We assess the performance of stretch and contact sensors featuring custom patterns on complex surfaces, subjecting them to position control, grasping, and manipulation scenarios. Our study's findings demonstrate the feasibility of fabricating skin-like sensors effectively within a semi-automated framework, with potential applications in the aforementioned research domains. keywords: {Automation;Manufacturing processes;Shape;Soft sensors;Tactile sensors;Position control;Human-robot interaction},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161344&isnumber=10160212

M. Rothammer and J. -H. Ryu, "Error-Domain Conservativity Control to Transparently Increase the Stability Range of Time-Discretized Controllers," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12514-12520, doi: 10.1109/ICRA48891.2023.10161459.Abstract: Time-discretization introduces an explicit time dependency for control laws that were originally designed to depend exclusively on an error variable: At different times, the control actions at the same error value might differ. Integrating the control action over the error reveals that this time dependency translates into the energy. It can directly cause active behavior when energy values at given error values decrease over time, potentially destabilizing the system. In this work, we aim to prevent energy values at given error values from decreasing over time. To this end, energies are recorded when error values are encountered for the first time. Linear interpolation of the recorded energy values provides a lower limit for energy as a function of the error value. This limit is enforced using an adaptive damping. The main contributions of this work include increasing the stability range with minimal amplitude control modifications, while promoting a symmetric behavior of control actions and energy. The approach's characteristics are shown in simulation and validated in experiments. keywords: {Motion planning;Damping;Interpolation;Adaptation models;Automation;Stability analysis;Haptic interfaces;Haptics;Adaptive Control},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161459&isnumber=10160212

P. Kremer, N. Nourani-Vatani and S. Park, "A Digital Twin for Teleoperation of Vehicles in Urban Environments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12521-12527, doi: 10.1109/ICRA48891.2023.10161556.Abstract: Teleoperated driving (ToD) is increasingly considered as a fallback solution for autonomous driving. Up to now, ToD requires a highly reliable mobile network capable of transmitting multiple video streams with low latency. Recently, significant advancements have been made in vehicular sensors and perception algorithms, which have huge implications for the challenges faced in ToD. We envisage that a real-time digital twin that tracks the remote vehicle's environment will play a crucial role in reducing the required communication band-width and providing a more convenient teleoperator interface, ultimately enhancing safety of ToD in crowded environments. Furthermore, it would allow various degrees of cooperation between automated driving functionalities and human teleoperators. In this paper, the concept of digital twin for ToD is outlined and a proof of concept is implemented using a real-world vehicle simulator and a teleoperator hardware setup. A significant reduction in required bandwidth is reported by transmitting less video data and reconstructing the scene from the digital twin. keywords: {Teleoperators;Urban areas;Streaming media;Real-time systems;Hardware;Digital twins;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161556&isnumber=10160212

M. Bowman and X. Zhang, "WE-Filter: Adaptive Acceptance Criteria for Filter-based Shared Autonomy," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12528-12534, doi: 10.1109/ICRA48891.2023.10161228.Abstract: Filter-based shared control aims to accept and augment an operator's ability to control a robot. Current solutions accept actions based on their direction aligning with the robot's optimal policy. These strategies reject a human's small corrective actions if they conflict with the robot's direction and accept too aggressive actions as long as they are consistent with the robot's direction. Such strategies may cause task failures and the operator's feeling of loss of control. To close the gap, we propose WE-Filter, which has flexible, adaptive criteria allowing the operator's small corrective actions and tempering too aggressive ones. Inspired by classical work-energy impact problems between two dynamic, interactive bodies, both inputs' properties (direction and magnitude) are inherently considered, creating intuitive, adaptive bounds to accept sensible actions. The model identifies behaviors before and after impact. The rationale is that each timestep of shared control acts as an impact between the operator's and the robot's policies, where post-impact behaviors depend on their previous behaviors. As time continues, a series of impacts occur. The aim is to minimize impacts that occur to reach an agreement faster and reduce strong reactionary behaviors. Our model determines flexible acceptance criteria to bound a mismatch of magnitude and finds a replacement action for conflicting policies. The WE-Filter achieves better task performance, the ratio of accepted actions, and action similarity than the existing methods. keywords: {Adaptation models;Automation;Behavioral sciences;Task analysis;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161228&isnumber=10160212

R. Brilli, M. Legittimo, F. Crocetti, M. Leomanni, M. L. Fravolini and G. Costante, "Monocular Reactive Collision Avoidance for MAV Teleoperation with Deep Reinforcement Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12535-12541, doi: 10.1109/ICRA48891.2023.10160427.Abstract: Enabling Micro Aerial Vehicles (MAVs) with semi-autonomous capabilities to assist their teleoperation is crucial in several applications. Remote human operators do not have, in general, the situational awareness to perceive obstacles near the drone, nor the readiness to provide commands to avoid collisions. In this work, we devise a novel teleoperation setting that asks the operator to provide a simple high-level signal encoding the speed and the direction they expect the drone to follow. We then endow the MAV with an end-to-end Deep Reinforcement Learning (DRL) model that computes control commands to track the desired trajectory while performing collision avoidance. Differently from State-of-the-Art (SotA) works, it allows the robot to move freely in the 3D space, requires only the current RGB image captured by a monocular camera and the current robot position, and does not make any assumption about obstacle shape and size. We show the effectiveness and the generalization capabilities of our strategy by comparing it against a SotA baseline in photorealistic simulated environments. keywords: {Deep learning;Three-dimensional displays;Tracking;Shape;Robot vision systems;Reinforcement learning;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160427&isnumber=10160212

A. Padmanabha et al., "HAT: Head-Worn Assistive Teleoperation of Mobile Manipulators," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12542-12548, doi: 10.1109/ICRA48891.2023.10160431.Abstract: Mobile manipulators in the home can provide increased autonomy to individuals with severe motor impairments, who often cannot complete activities of daily living (ADLs) without the help of a caregiver. Teleoperation of an assistive mobile manipulator could enable an individual with motor impairments to independently perform self-care and household tasks, yet limited motor function can impede one's ability to interface with a robot. In this work, we present a unique inertial-based wearable assistive interface, embedded in a familiar head-worn garment, for individuals with severe motor impairments to teleoperate and perform physical tasks with a mobile manipulator. We evaluate this wearable interface with both able-bodied ($\mathrm{N}=16$) and individuals with motor impairments ($\mathrm{N}=2$) for performing ADLs and everyday household tasks. Our results show that the wearable interface enabled participants to complete physical tasks with low error rates, high perceived ease of use, and low workload measures. Overall, this inertial-based wearable serves as a new assistive interface option for control of mobile manipulators in the home. keywords: {Automation;Error analysis;Atmospheric measurements;Clothing;Measurement uncertainty;Manipulators;Particle measurements},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160431&isnumber=10160212

W. K. Do, B. Jurewicz and M. Kennedy, "DenseTact 2.0: Optical Tactile Sensor for Shape and Force Reconstruction," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12549-12555, doi: 10.1109/ICRA48891.2023.10161150.Abstract: Collaborative robots stand to have an immense impact on both human welfare in domestic service applications and industrial superiority in advanced manufacturing with dexterous assembly. The outstanding challenge is providing robotic fingertips with a physical design that makes them adept at performing dexterous tasks that require high-resolution, calibrated shape reconstruction and force sensing. In this work, we present DenseTact 2.0, an optical-tactile sensor capable of visualizing the deformed surface of a soft fingertip and using that image in a neural network to perform both calibrated shape reconstruction and 6-axis wrench estimation. We demon-strate the sensor accuracy of 0.3633mm per pixel for shape reconstruction, 0.410N for forces, 0.387N. mm for torques, and the ability to calibrate new fingers through transfer learning, which achieves comparable performance with only 12% of the non-transfer learning dataset size. keywords: {Integrated optics;Surface reconstruction;Shape;Service robots;Force;Transfer learning;Estimation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161150&isnumber=10160212

S. Rupavatharam et al., "SonicFinger: Pre-touch and Contact Detection Tactile Sensor for Reactive Pregrasping," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12556-12562, doi: 10.1109/ICRA48891.2023.10161074.Abstract: Robot end effectors with proximity detection and contact sensing capabilities can reactively position the gripper to align objects and ensure successful grasps. In this paper, we introduce SonicFinger, an acoustic aura based sensing system capable of full-surface pre-touch and contact sensing. A single piezoelectric transducer embedded within a novel 3D printed finger is excited using a monotone to create an acoustic aura encompassing the finger; this enables pre-touch sensing and gripper alignment, while changes in finger-transducer acoustic coupling indicate contact. SonicFinger is low-cost, compact, and easy to manufacture and assemble. Sensing capabilities are evaluated using a set of objects with various physical properties such as optical reflectivity, dielectric constants, mechanical properties, and acoustic absorption. A dataset with over 8,000 proximity and contact events is collected. Our system shows a pre-touch detection true positive rate (TPR) of 92.4% and a true negative rate (TNR) of 95.3%. Contact detection experiments show a TPR of 93.7% and a TNR of 98.7%. Furthermore, pretouch detection information from Sonic Finger is used to adjust the robot grippers pose to align a target object at the center of both fingers. keywords: {Reflectivity;Three-dimensional displays;Piezoelectric transducers;Tactile sensors;Robot sensing systems;Acoustics;Mechanical factors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161074&isnumber=10160212

S. Kim, D. K. Jha, D. Romeres, P. Patre and A. Rodriguez, "Simultaneous Tactile Estimation and Control of Extrinsic Contact," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12563-12569, doi: 10.1109/ICRA48891.2023.10161158.Abstract: We propose a method that simultaneously estimates and controls extrinsic contact with tactile feedback. The method enables challenging manipulation tasks that require controlling light forces and accurate motions in contact, such as balancing an unknown object on a thin rod standing upright. A factor graph-based framework fuses a sequence of tactile and kinematic measurements to estimate and control the interaction between gripper-object-environment, including the location and wrench at the extrinsic contact between the grasped object and the environment and the grasp wrench transferred from the gripper to the object. The same framework simultaneously plans the gripper motions that make it possible to estimate the state while satisfying regularizing control objectives to prevent slip, such as minimizing the grasp wrench and minimizing frictional force at the extrinsic contact. We show results with sub-millimeter contact localization error and good slip prevention even on slippery environments, for multiple contact formations (point, line, patch contact) and transitions between them. See supplementary video and results at https://sites.google.com/view/sim-tact. keywords: {Location awareness;Automation;Fuses;Force;Tactile sensors;Estimation;Kinematics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161158&isnumber=10160212

K. Althoefer, Y. Ling, W. Li, X. Qian, W. W. Lee and P. Qi, "A Miniaturised Camera-based Multi-Modal Tactile Sensor," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12570-12575, doi: 10.1109/ICRA48891.2023.10160634.Abstract: In conjunction with huge recent progress in cam-era and computer vision technology, camera-based sensors have increasingly shown considerable promise in relation to tactile sensing. In comparison to competing technologies (be they resistive, capacitive or magnetic based), they offer super-high-resolution, while suffering from fewer wiring problems. The human tactile system is composed of various types of mechanoreceptors, each able to perceive and process distinct information such as force, pressure, texture, etc. Camera-based tactile sensors such as GelSight mainly focus on high-resolution geometric sensing on a flat surface, and their force measurement capabilities are limited by the hysteresis and non-linearity of the silicone material. In this paper, we present a miniaturised dome-shaped camera-based tactile sensor that allows accurate force and tactile sensing in a single coherent system. The key novelty of the sensor design is as follows. First, we demonstrate how to build a smooth silicone hemispheric sensing medium with uniform markers on its curved surface. Second, we enhance the illumination of the rounded silicone with diffused LEDs. Third, we construct a force-sensitive mechanical structure in a compact form factor with usage of springs to accurately perceive forces. Our multi-modal sensor is able to acquire tactile information from multi-axis forces, local force distribution, and contact geometry, all in real-time. We apply an end-to-end deep learning method to process all the information. keywords: {Wiring;Mechanical sensors;Multimodal sensors;Force;Tactile sensors;Magnetic hysteresis;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160634&isnumber=10160212

C. Higuera, S. Dong, B. Boots and M. Mukadam, "Neural Contact Fields: Tracking Extrinsic Contact with Tactile Sensing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12576-12582, doi: 10.1109/ICRA48891.2023.10160526.Abstract: We present Neural Contact Fields, a method that brings together neural fields and tactile sensing to address the problem of tracking extrinsic contact between object and environment. Knowing where the external contact occurs is a first step towards methods that can actively control it in facilitating downstream manipulation tasks. Prior work for localizing environmental contacts typically assume a contact type (e.g. point or line), does not capture contact/no-contact transitions, and only works with basic geometric-shaped objects. Neural Contact Fields are the first method that can track arbitrary multi-modal extrinsic contacts without making any assumptions about the contact type. Our key insight is to estimate the probability of contact for any 3D point in the latent space of object's shapes, given vision-based tactile inputs that sense the local motion resulting from the external contact. In experiments, we find that Neural Contact Fields are able to localize multiple contact patches without making any assumptions about the geometry of the contact, and capture contact/no-contact transitions for known categories of objects with unseen shapes in unseen environment configurations. In addition to Neural Contact Fields, we also release our YCB-Extrinsic-Contact dataset of simulated extrinsic contact interactions to enable further research in this area. Project page: https://github.com/carolinahiguera/NCF keywords: {Geometry;Three-dimensional displays;Automation;Shape;Tracking;Robot sensing systems;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160526&isnumber=10160212

S. Yao and K. Hauser, "Estimating Tactile Models of Heterogeneous Deformable Objects in Real Time," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12583-12589, doi: 10.1109/ICRA48891.2023.10160731.Abstract: This paper introduces a method for learning the force response of heterogeneous, deformable objects directly from robot sensor data without prior knowledge. The method estimates an object's force response given robot force or torque measurements using a novel volumetric stiffness field representation and point-based contact simulator. The stiffness of each point colliding with the robot is estimated independently and is updated upon each observed measurement using a projected diagonal Kalman filter. Experiments show that this method can update a stiffness field over 105 points at 23 Hz or higher, and is more accurate than learning-based methods in predicting torque response while touching artificial plants. The method can also be augmented with visual information to help extrapolate stiffness fields to distant parts of the touched object using only a small number of touches. keywords: {Deformable models;Visualization;Torque;Deformation;Force;Tactile sensors;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160731&isnumber=10160212

X. Zhou and A. J. Spiers, "Tactile Identification of Object Shapes via In-Hand Manipulation with A Minimalistic Barometric Tactile Sensor Array," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12590-12596, doi: 10.1109/ICRA48891.2023.10160975.Abstract: With the goal of providing an alternative to optical and other tactile sensors, we set out to stress test the object shape identification capabilities of barometric tactile arrays in robotic manipulation tasks. These sensors are superior to optical devices in terms of form factor, ease of fabrication, and data reading/processing speeds, but lack the necessary spatial resolution to identify surface shapes via a single contact. To compensate, we utilize in-hand-manipulation, specifically in- hand-rolling to identify object shapes via a spatiotemporal approach. To increase task difficulty, we only use three neighboring barometric sensors and designed strict experiment requirements with the purpose of creating a set of extremely confusable test objects. The E- TRoll robotic hand, equipped with a barometric tactile array on one finger, was used to roll test objects within its grasp, taking just under 3.4 seconds for data collection under the fastest tested speed setting, compared to 33 seconds in our previous work. We also designed and implemented a feature extraction algorithm, based and improved upon our recently published algorithm. This captures enough information from the collected spatiotemporal data samples for successful classification with only 13 features. Finally, a bagged tree classification algorithm was trained and optimized with data from 1,164 trials of rolling 9 prismatic test objects, leading to a five-fold cross validation accuracy of 90.5% for identifying the 9 object classes. keywords: {Surface reconstruction;Shape;Tactile sensors;Classification algorithms;Spatiotemporal phenomena;Object recognition;Optical sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160975&isnumber=10160212

Y. Shirai, D. K. Jha, A. U. Raghunathan and D. Hong, "Tactile Tool Manipulation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12597-12603, doi: 10.1109/ICRA48891.2023.10160480.Abstract: Humans can effortlessly perform very complex, dexterous manipulation tasks by reacting to sensor observations. In contrast, robots can not perform reactive manipulation and they mostly operate in open-loop while interacting with their environment. Consequently, the current manipulation algorithms either are inefficient in performance or can only work in highly structured environments. In this paper, we present closed-loop control of a complex manipulation task where a robot uses a tool to interact with objects. Manipulation using a tool leads to complex kinematics and contact constraints that need to be satisfied for generating feasible manipulation trajectories. We first present an open-loop controller design using Non-Linear Programming (NLP) that satisfies these constraints. In order to design a closed-loop controller, we present a pose estimator of objects and tools using tactile sensors. Using our tactile estimator, we design a closed-loop controller based on Model Predictive Control (MPC). The proposed algorithm is verified using a 6 DoF manipulator on tasks using a variety of objects and tools. We verify that our closed-loop controller can successfully perform tool manipulation under several unexpected contacts. keywords: {Automation;Tactile sensors;Kinematics;Programming;Prediction algorithms;Manipulators;6-DOF},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160480&isnumber=10160212

M. Finn-Henry, J. L. Brenes, A. Baimyshev and M. Goldfarb, "Preliminary Evaluation of a Wearable Thruster for Arresting Backwards Falls," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12604-12609, doi: 10.1109/ICRA48891.2023.10160518.Abstract: This paper presents preliminary results assessing the efficacy of a backpack-worn cold-gas thruster to potentially arrest impending backwards falls. Specifically, a nitrogen-based cold gas thruster system was integrated into a backpack-worn prototype device, and experiments were conducted to assess the effect of the wearable device on backwards falls. Although the device is eventually intended for individuals at fall risk, these preliminary experiments were conducted on three healthy subjects. The experiments compared each subject's ability to recover from an impending fall with and without assistance from the thruster. Results suggest that the likelihood of a fall was substantially reduced with the thruster assistance. keywords: {Automation;Attitude control;Wearable computers;Prototypes;Nitrogen},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160518&isnumber=10160212

M. Eveld, S. King, K. Zelik and M. Goldfarb, "A method for selecting stumble recovery response in a knee exoskeleton," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12610-12616, doi: 10.1109/ICRA48891.2023.10160789.Abstract: Powered lower-limb exoskeletons have been shown to assist and augment walking, but most such devices do not currently have the ability to explicitly accommodate a stumble perturbation. A major challenge in doing so is identifying a stumble event and selecting in real-time which recovery strategy (elevating or lowering) to employ, particularly since the exoskeleton should ideally select the same strategy selected by the user. In order to do so, the authors conducted experiments involving five young, healthy adults wearing a knee exoskeleton. Each participant underwent a stumble experiment in order to collect an exoskeleton sensor dataset of stumbles throughout swing phase, which was used for stumble detection and recovery strategy identification algorithm development and testing. Overall, the proposed detection and identification algorithms provide improved accuracy with fewer required sensors relative to previous works, and were tested on the largest exoskeleton sensor stumble dataset to date, showing the feasibility of such algorithms for real-time implementation, which is an essential first step in developing lower-limb assistive devices that are robust to stumbles. keywords: {Knee;Legged locomotion;Perturbation methods;Exoskeletons;Thigh;Robot sensing systems;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160789&isnumber=10160212

L. Chen, J. Qiu, X. Zou and H. Cheng, "A Dual-Arm Participated Human-Robot Collaboration Method for Upper Limb Rehabilitation of Hemiplegic Patients," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12617-12623, doi: 10.1109/ICRA48891.2023.10160949.Abstract: Upper limb rehabilitation robots are mainly used as a physical therapy method to passively or actively train the affected side. However, they are rarely implemented in accordance with the occupational therapy theory, which is dedicated to improving the sensorimotor coordination of hemiplegic patients by considering both healthy and affected limbs. To realize the occupational therapy concept in robot-assisted upper limb rehabilitation, we propose a new human-robot collaboration framework for hemiplegic patients that integrates healthy/affected limbs and robot. The strategy aims at achieving patient-specific movement capabilities and improving the participation of the affected limb during rehabilitation. To accomplish this task, we have addressed two essential issues: accurate motion estimation of the healthy limb and the rehabilitation trajectory learning technique. The posture estimation is achieved by introducing the calibration model to reduce static and time dependent errors during the measurement. We also introduce a force term to the conventional imitation learning method to improve the adaptability in integrating the affected side in cooperation with the robot. Various experiments have been conducted to validate the feasibility and effectiveness of our proposed dual-arm collaboration strategy. keywords: {Learning systems;Robot kinematics;Force;Collaboration;Estimation;Clinical trials;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160949&isnumber=10160212

A. Toedtheide, X. Chen, H. Sadeghian, A. Naceri and S. Haddadin, "A Force-Sensitive Exoskeleton for Teleoperation: An Application in Elderly Care Robotics," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12624-12630, doi: 10.1109/ICRA48891.2023.10161175.Abstract: With the increasing demand for new healthcare solutions and technologies, such as those resulting from the COVID-19 crisis, and the growing elderly population, exoskeletons for teleoperation are a promising solution for many future medical applications. In this context, we propose two force- sensitive upper-limb exoskeletons for teleoperation, that are characterized by: i) torque-controlled robotic actuators, ii) rigid-body model compensations, and iii) a lightweight design achieved through the use of Bowden cable transmissions and remotely placed actuators. Specifically, we present a semi-active upper-limb exoskeleton for which we demonstrate human- device interaction control and bilateral teleoperation with force- feedback, evaluated via simulation, in the lab and over the Internet. We also introduce a design for a future fully-active upper-limb exoskeleton with two contact force/torque sensors, for a dual-arm device, which features a novel 3-degrees-of- freedom exoskeleton shoulder design and a contact wrench mitigation controller, as demonstrated through simulation. With this work, we propose the essential technical steps towards a novel teleoperation system for elderly care. keywords: {Actuators;Exoskeletons;Sociology;Shoulder;Medical services;Sensor phenomena and characterization;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161175&isnumber=10160212

V. Chambers and P. Artemiadis, "A Model-Based Analysis of The Effect of Repeated Unilateral Low Stiffness Perturbations on Human Gait: Toward Robot-Assisted Rehabilitation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12631-12637, doi: 10.1109/ICRA48891.2023.10160224.Abstract: Human gait is quite complex, especially when considering the irregular and uncertain environments that humans are able to walk in. While unperturbed gait in a controlled environment is understood to a large degree, gait in more unique environments, such as asymmetric compliant terrain, is not understood to the same degree. In this study, we build upon a neuromuscular gait model and extend it to allow for walking on unilaterally compliant (soft) surfaces. This model is then compared to and verified by experimental human data. The model can successfully walk with step length trends similar to human data. Additionally, the model shows similar behaviors with respect to kinematics and muscle activity. We believe this work contributes significantly to a better understanding of the control of human gait and could lead to model-informed, patient-specific rehabilitation strategies that can advance the field of rehabilitation robotics, as well as the development of bio-inspired controllers for bipedal robots that would be able to traverse through dynamic and complaint terrains. keywords: {Legged locomotion;Adaptation models;Analytical models;Neuromuscular;Biological system modeling;Perturbation methods;Kinematics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160224&isnumber=10160212

A. Menon et al., "Shared Control of Assistive Robots through User-intent Prediction and Hyperdimensional Recall of Reactive Behavior," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12638-12644, doi: 10.1109/ICRA48891.2023.10161509.Abstract: There is increasing interest in shared control for assistive robotics with adaptable levels of supervised autonomy. In this work, we present a user-adaptive multi-layer shared control scheme for control of assistive devices. The system leverages the advantages of brain-inspired hyperdimensional computing (HDC) for classification & recall of reactive robotic behavior including high performance, computational efficiency and intelligent sensor fusion, to execute actuation based on the user's goal while alleviating the burden of fine control. Using a multi-modal dataset of activities of daily living, we first recognize the user's most recent behaviors, then predict the user's next action based on their habitual action sequences, and finally, determine actuation through HDC recall-based shared control which intelligently deliberates between the predicted action and sensor feedback-based autonomy. In this work, we independently implement each layer to achieve >92% accuracy and then integrate the layers and discuss the combined performance and methods to reduce accumulated error. keywords: {Performance evaluation;Automation;Robot sensing systems;Assistive robots;Behavioral sciences;Computational efficiency;Assistive devices},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161509&isnumber=10160212

D. Zadok, O. Salzman, A. Wolf and A. M. Bronstein, "Towards Predicting Fine Finger Motions from Ultrasound Images via Kinematic Representation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12645-12651, doi: 10.1109/ICRA48891.2023.10160601.Abstract: A central challenge in building robotic prostheses is the creation of a sensor-based system able to read physiological signals from the lower limb and instruct a robotic hand to perform various tasks. Existing systems typically perform discrete gestures such as pointing or grasping, by employing electromyography (EMG) or ultrasound (US) technologies to analyze muscle states. While estimating finger gestures has been done in the past by detecting prominent gestures, we are interested in detection, or inference, done in the context of fine motions that evolve over time. Examples include motions occurring when performing fine and dexterous tasks such as keyboard typing or piano playing. We consider this task as an important step towards higher adoption rates of robotic prostheses among arm amputees, as it has the potential to dramatically increase functionality in performing daily tasks. To this end, we present an end-to-end robotic system, which can successfully infer fine finger motions. This is achieved by modeling the hand as a robotic manipulator and using it as an intermediate representation to encode muscles' dynamics from a sequence of US images. We evaluated our method by collecting data from a group of subjects and demonstrating how it can be used to replay music played or text typed. To the best of our knowledge, this is the first study demonstrating these downstream tasks within an end-to-end system. keywords: {Ultrasonic imaging;Keyboards;Kinematics;Grasping;Muscles;Robot sensing systems;Electromyography},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160601&isnumber=10160212

M. Brunet, M. Pétriaux, F. Di Meglio and N. Petit, "Enabling safe walking rehabilitation on the exoskeleton Atalante: experimental results," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12652-12658, doi: 10.1109/ICRA48891.2023.10161235.Abstract: This paper exposes a control architecture enabling rehabilitation of walking impaired patients with the lower-limb exoskeleton Atalante. Atalante's control system is modified to allow the patient to contribute to the walking motion through their efforts. Only the swing leg degree of freedom along the nominal path is relaxed. An online trajectory optimization checks that the muscle forces do not jeopardize stability. The optimization generates reference trajectories that satisfy several key constraints from the current point to the end of the step. One of the constraints requires that the center or pressure remains inside the support polygon, which ensures that the support leg subsystem successfully tracks the reference trajectory. As a result of the presented works, the robot provides a non-zero force in the direction of motion only when required, helping the patient go fast enough to maintain balance (or preventing him from going too fast). Experimental results are reported. They illustrate that variations of ±50% of the duration of the step can be achieved in response to the patient's efforts and that many steps are achieved without falling. keywords: {Legged locomotion;Tracking;Lips;Exoskeletons;Muscles;Stability analysis;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161235&isnumber=10160212

T. Shen, I. Di Giulio and M. Howard, "A Probabilistic Model of Activity Recognition with Loose Clothing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12659-12664, doi: 10.1109/ICRA48891.2023.10161236.Abstract: Human activity recognition has become an attractive research area with the development of on-body wearable sensing technology. With comfortable electronic-textiles, sensors can be embedded into clothing so that it is possible to record human movement outside the laboratory for long periods. However, a long-standing issue is how to deal with motion artifact introduced by movement of clothing with respect to the body. Surprisingly, recent empirical findings suggest that cloth-attached sensor can actually achieve higher accuracy of activity recognition than rigid-attached sensor, particularly when predicting from short time-windows. In this work, a probabilistic model is introduced in which this improved accuracy and resposiveness is explained by the increased statistical distance between movements recorded via fabric sensing. The predictions of the model are verified in simulated and real human motion capture experiments, where it is evident that this counterintuitive effect is closely captured. keywords: {Automation;Clothing;Predictive models;Robot sensing systems;Probabilistic logic;Motion capture;Fabrics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161236&isnumber=10160212

K. Seo, "Real-Time Estimation of Walking Speed and Stride Length Using an IMU Embedded in a Robotic Hip Exoskeleton," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12665-12671, doi: 10.1109/ICRA48891.2023.10160770.Abstract: Gait parameters, including walking speed and stride length, are crucial indicators of health status and rehabilitation progress for individuals using wearable robots for exercise or rehabilitation. These metrics play a crucial role in monitoring progress and adjusting training programs, thereby fostering greater engagement in the training. In this paper, we present methods for estimating walking speed and stride length using sensors in wearable hip exoskeleton GEMS-H. Our study collected data from 79 middle-aged healthy individuals walking on a treadmill while wearing GEMS-H under various assistance conditions. To estimate walking speed, we evaluated linear regression models, deep neural networks, and ensemble models using different combinations of joint encoders and an IMU in the GEMS-H hip exoskeleton to form various sets of features. The ensemble of deep neural networks using only 6-DOF IMU signals as features achieved the lowest root-mean-square error (RMSE) for walking speed estimation, which was 0.066 m/s. We also present an algorithm for real-time stride length estimation, building on one of the speed estimation models. The speed and stride length estimation model was tested on 12 middle-aged healthy subjects walking in GEMS-H overground, yielding an RMSE of 0.060 m/s for speed and 7.1 cm for stride length. keywords: {Legged locomotion;Training;Deep learning;Exoskeletons;Neural networks;Estimation;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160770&isnumber=10160212

R. Jradi, H. Rifaï, Y. Amirat and S. Mohammed, "Adaptive based Assist-as-needed control strategy for Ankle movement assistance," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12672-12678, doi: 10.1109/ICRA48891.2023.10161008.Abstract: Stroke affects a large number of people every year. One consequence is the weakness of ambulatory muscles resulting in a paretic gait. Actuated ankle foot orthoses can be a solution to assist paretic patients to dorsiflex and/or plantar flex their ankle joint during the gait phases. To assist the wearer following a predefined ankle joint desired trajectory, an adaptive active disturbance rejection controller is proposed in this study. The human muscular torque and estimation errors are estimated through a nonlinear disturbance observer based on the estimated model. This estimated torque is compensated within the proposed projection based adaptive controller combined to a saturated proportional derivative term. The purposes of using this controller are: i) the no need of prior system's parameter identification due to the adaptive structure, ii) the assistance-as-needed of the wearer through the rejection term and iii) the avoidance of the actuator saturation by including projection and saturation functions. This controller is tested in real time using an actuated ankle-foot-orthosis (AAFO) in lab environment with three healthy subjects to show its effectiveness. keywords: {Estimation error;Torque;Parameter estimation;Flexible printed circuits;Automation;Muscles;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161008&isnumber=10160212

D. D. Molinaro, E. O. Park and A. J. Young, "Anticipation and Delayed Estimation of Sagittal Plane Human Hip Moments using Deep Learning and a Robotic Hip Exoskeleton," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12679-12685, doi: 10.1109/ICRA48891.2023.10161286.Abstract: Estimating human joint moments using wearable sensors has utility for personalized health monitoring and generalized exoskeleton control. Data-driven models have potential to map wearable sensor data to human joint moments, even with a reduced sensor suite and without subject-specific calibration. In this study, we quantified the RMSE and R2 of a temporal convolutional network (TCN), trained to estimate human hip moments in the sagittal plane using exoskeleton sensor data (i.e., a hip encoder and thigh- and pelvis-mounted inertial measurement units). We conducted three analyses in which we iteratively retrained the network while: 1) varying the input sequence length of the model, 2) incorporating noncausal data into the input sequence, thus delaying the network estimates, and 3) time shifting the labels to train the model to anticipate (i.e., predict) human hip moments. We found that 930 ms of causal input data maintained model performance while minimizing input sequence length (validation RMSE and R2 of 0.141±0.014 Nm/kg and 0.883±0.025, respectively). Further, delaying the model estimate by up to 200 ms significantly improved model performance compared to the best causal estimators (p<0.05), improving estimator fidelity in use cases where delayed estimates are acceptable (e.g., in personalized health monitoring or diagnoses). Finally, we found that anticipating hip moments further in time linearly increased model RMSE and decreased R2 (p<0.05); however, performance remained strong (R2>0.85) when predicting up to 200 ms ahead. keywords: {Analytical models;Exoskeletons;Estimation;Predictive models;Robot sensing systems;Data models;Convolutional neural networks},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161286&isnumber=10160212

M. Black, G. Fainekos, B. Hoxha, D. Prokhorov and D. Panagou, "Safety Under Uncertainty: Tight Bounds with Risk-Aware Control Barrier Functions," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12686-12692, doi: 10.1109/ICRA48891.2023.10161379.Abstract: We propose a novel class of risk-aware control barrier functions (RA-CBFs) for the control of stochastic safety-critical systems. Leveraging a result from the stochastic level-crossing literature, we deviate from the martingale theory that is currently used in stochastic CBF techniques and prove that a RA-CBF based control synthesis confers a tighter upper bound on the probability of the system becoming unsafe within a finite time interval than existing approaches. We highlight the advantages of our proposed approach over the state-of-the-art via a comparative study on an mobile-robot example, and further demonstrate its viability on an autonomous vehicle highway merging problem in dense traffic. keywords: {Road transportation;Upper bound;Uncertainty;Merging;Control systems;Safety;Noise measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161379&isnumber=10160212

K. Ekenberg, V. Renganathan and B. Olofsson, "Distributionally Robust RRT with Risk Allocation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12693-12699, doi: 10.1109/ICRA48891.2023.10161303.Abstract: An integration of distributionally robust risk allocation into sampling-based motion planning algorithms for robots operating in uncertain environments is proposed. We perform non-uniform risk allocation by decomposing the distributionally robust joint risk constraints defined over the entire planning horizon into individual risk constraints given the total risk budget. Specifically, the deterministic tightening defined using the individual risk constraints is leveraged to define our proposed exact risk allocation procedure. Embedding the risk allocation technique into sampling-based motion planning algorithms realises guaranteed conservative, yet increasingly more risk-feasible trajectories for efficient state-space exploration. keywords: {Automation;Probabilistic logic;Planning;Trajectory;Resource management;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161303&isnumber=10160212

C. Knuth, G. Chou, J. Reese and J. Moore, "Statistical Safety and Robustness Guarantees for Feedback Motion Planning of Unknown Underactuated Stochastic Systems," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12700-12706, doi: 10.1109/ICRA48891.2023.10161001.Abstract: We present a method for providing statistical guarantees on runtime safety and goal reachability for integrated planning and control of a class of systems with unknown nonlinear stochastic underactuated dynamics. Specifically, given a dynamics dataset, our method jointly learns a mean dynamics model, a spatially-varying disturbance bound that captures the effect of noise and model mismatch, and a feedback controller based on contraction theory that stabilizes the learned dynamics. We propose a sampling-based planner that uses the mean dynamics model and simultaneously bounds the closed-loop tracking error via a learned disturbance bound. We employ techniques from Extreme Value Theory (EVT) to estimate, to a specified level of confidence, several constants which characterize the learned components and govern the size of the tracking error bound. This ensures plans are guaranteed to be safely tracked at runtime. We validate that our guarantees translate to empirical safety in simulation on a 10D quadrotor, and in the real world on a physical CrazyFlie quadrotor and Clearpath Jackal robot, whereas baselines that ignore the model error and stochasticity are unsafe. keywords: {Runtime;Tracking;Stochastic systems;Stochastic processes;Robustness;Planning;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161001&isnumber=10160212

S. Wasiela, P. R. Giordano, J. Cortés and T. Siméon, "A Sensitivity-Aware Motion Planner (SAMP) to Generate Intrinsically-Robust Trajectories," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12707-12713, doi: 10.1109/ICRA48891.2023.10160576.Abstract: Closed-loop state sensitivity [1], [2] is a recently introduced notion that can be used to quantify deviations of the closed-loop trajectory of a robot/controller pair against variations of uncertain parameters in the robot model. While local optimization techniques are used in [1], [2] to generate reference trajectories minimizing a sensitivity-based cost, no global planning algorithm considering this metric to compute collision-free motions robust to parametric uncertainties has yet been proposed. The contribution of this paper is to propose a global control-aware motion planner for optimizing a state sensitivity metric and producing collision-free reference motions that are robust against parametric uncertainties for a large class of complex dynamical systems. Given the prohibitively high computational cost of directly minimizing the state sensitivity using asymptotically optimal sampling-based tree planners, the proposed RRT*-based SAMP planner uses an appropriate steering method to first compute a (near) time-optimal and kinodynamically feasible trajectory that is then locally deformed to improve robustness and decrease its sensitivity to uncertainties. The evaluation performed on planar/full-3D quadrotor UAV models shows that the SAMP method produces low sensitivity robust solutions with a much higher performance than a planner directly optimizing the sensitivity. keywords: {Sensitivity;Uncertainty;Costs;Computational modeling;Robot sensing systems;Robustness;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160576&isnumber=10160212

X. Cao, J. W. Crandall, E. Pedersen, A. Gautam and M. A. Goodrich, "Proficiency Self-Assessment without Breaking the Robot: Anomaly Detection using Assumption-Alignment Tracking from Safe Experiments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12714-12720, doi: 10.1109/ICRA48891.2023.10160916.Abstract: Proficiency self-assessment (PSA), the ability to assess how well one can carry out a task, is a desirable capability of autonomous robot systems. Prior work has proposed assumption-alignment tracking (AAT) for performing PSA, and has shown that it can accurately predict robot performance in real-time given a dataset obtained from both normal and abnormal training runs. Obtaining data in abnormal conditions (i.e., conditions in which the robot is not prepared to operate) is difficult and is often not possible. As a result, many realistic datasets contain very few data points for abnormal conditions, making it difficult to apply AAT. This paper hypothesizes that a one-class classifier can be built to detect anomalies using only data collected under normal conditions. Two metrics, difference and separation, are proposed and used to demonstrate that AAT feature vectors from different running conditions tend to form distinct clusters that are identifiable by mainstream one-class classification algorithms. Thus, one-class classifiers trained on AAT feature vectors from normal data can detect anomalous conditions. Furthermore, preliminary results suggest that a few abnormal data points, if available, can be used to classify the abnormality type and, in turn, the degree to which the anomalies will likely impact robot performance. Empirical results from both a simulated navigation robot and a Sawyer robot manipulating blocks show the efficacy of the approach. keywords: {Training;Measurement;Automation;Navigation;Feature extraction;Real-time systems;Classification algorithms},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160916&isnumber=10160212

W. Shao, Y. Xu, L. Peng, J. Li and H. Wang, "Failure Detection for Motion Prediction of Autonomous Driving: An Uncertainty Perspective," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12721-12728, doi: 10.1109/ICRA48891.2023.10160596.Abstract: Motion prediction is essential for safe and efficient autonomous driving. However, the inexplicability and uncertainty of complex artificial intelligence models may lead to unpredictable failures of the motion prediction module, which may mislead the system to make unsafe decisions. Therefore, it is necessary to develop methods to guarantee reliable autonomous driving, where failure detection is a potential direction. Uncertainty estimates can be used to quantify the degree of confidence a model has in its predictions and may be valuable for failure detection. We propose a framework of failure detection for motion prediction from the uncertainty perspective, considering both motion uncertainty and model uncertainty, and formulate various uncertainty scores according to different prediction stages. The proposed approach is evaluated based on different motion prediction algorithms, uncertainty estimation methods, uncertainty scores, etc., and the results show that uncertainty is promising for failure detection for motion prediction but should be used with caution. keywords: {Uncertainty;Decision making;Estimation;Predictive models;Prediction algorithms;Trajectory;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160596&isnumber=10160212

D. Nurchalifah, S. Blumenthal, L. Lo Iacono and N. Hochgeschwender, "Analysing the Safety and Security of a UV-C Disinfection Robot," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12729-12736, doi: 10.1109/ICRA48891.2023.10160527.Abstract: Safety is paramount for robots used in environments they share with humans. In such scenarios, security is also growing in importance. However, conventional approaches to analysing safety requirements are aimed at identifying hazards only. Security-related aspects such as cyber threats, cyber attacks and vulnerabilities have hardly been integrated into analysis and design methods to date. The methods available so far for the joint analysis of safety and security are based on established methods of safety engineering, where the amount of information is very large and usually stored in text- and table-based documents. This makes it challenging for engineers to systematically assess and maintain safety and security information. Thus, adequate tool support for robot engineers is required to cope with the increased complexity and to manage the safety and security risks. In this paper, we demonstrate that robot's safety and security information can be expressed, stored, analysed and queried in a knowledge graph representation paving the way to automated analysis. More specifically, we apply an integrated, systems-oriented safety and security co-analysis approach, namely STPA-Safesec, to a robot performing disinfection tasks in domestic environments. By querying the resulting graph of safety and security artefacts, we automatically retrieve hazardous scenarios, identify gaps in the analysis and increase our understanding of the overall risks of the robot. keywords: {Terminology;Knowledge graphs;Ontologies;Software;Hazards;Hardware;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160527&isnumber=10160212

G. Nava and D. Pucci, "Failure Detection and Fault Tolerant Control of a Jet-Powered Flying Humanoid Robot," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12737-12743, doi: 10.1109/ICRA48891.2023.10160615.Abstract: Failure detection and fault tolerant control are fundamental safety features of any aerial vehicle. With the emer-gence of complex, multi-body flying systems such as jet-powered humanoid robots, it becomes of crucial importance to design fault detection and control strategies for these systems, too. In this paper we propose a fault detection and control framework for the flying humanoid robot iRonCub in case of loss of one turbine. The framework is composed of a failure detector based on turbines rotational speed, a momentum-based flight control for fault response, and an offline reference generator that produces far-from-singularities configurations and accounts for self and jet exhausts collision avoidance. Simulation results with Gazebo and MATLAB prove the effectiveness of the proposed control strategy. keywords: {Fault detection;Simulation;Velocity control;Humanoid robots;Fault tolerant control;Generators;Stability analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160615&isnumber=10160212

C. Innes and S. Ramamoorthy, "Testing Rare Downstream Safety Violations via Upstream Adaptive Sampling of Perception Error Models," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12744-12750, doi: 10.1109/ICRA48891.2023.10161501.Abstract: Testing black-box perceptual-control systems in simulation faces two difficulties. Firstly, perceptual inputs in simulation lack the fidelity of real-world sensor inputs. Secondly, for a reasonably accurate perception system, encountering a rare failure trajectory may require running infeasibly many simulations. This paper combines perception error models-surrogates for a sensor-based detection system-with state-dependent adaptive importance sampling. This allows us to efficiently assess the rare failure probabilities for real-world perceptual control systems within simulation. Our experiments with an autonomous braking system equipped with an RGB obstacle-detector show that our method can calculate accurate failure probabilities with an inexpensive number of simulations. Further, we show how choice of safety metric can influence the process of learning proposal distributions capable of reliably sampling high-probability failures. keywords: {Measurement;Adaptation models;Adaptive systems;Probability;Robot sensing systems;Robustness;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161501&isnumber=10160212

A. Acharya, R. Russell and N. R. Ahmed, "Learning to Forecast Aleatoric and Epistemic Uncertainties over Long Horizon Trajectories," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12751-12757, doi: 10.1109/ICRA48891.2023.10160766.Abstract: Giving autonomous agents the ability to forecast their own outcomes and uncertainty will allow them to communicate their competencies and be used more safely. We accomplish this by using a learned world model of the agent system to forecast full agent trajectories over long time horizons. Real world systems involve significant sources of both aleatoric and epistemic uncertainty that compound and interact over time in the trajectory forecasts. We develop a deep generative world model that quantifies aleatoric uncertainty while incorporating the effects of epistemic uncertainty during the learning process. We show on two reinforcement learning problems that our uncertainty model produces calibrated outcome uncertainty estimates over the full trajectory horizon. keywords: {Uncertainty;Automation;Reinforcement learning;Predictive models;Autonomous agents;Trajectory;Compounds},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160766&isnumber=10160212

R. Laha, W. Wu, R. Sun, N. Mansfeld, L. F. C. Figueredo and S. Haddadin, "S*: On Safe and Time Efficient Robot Motion Planning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12758-12764, doi: 10.1109/ICRA48891.2023.10161248.Abstract: As robots and humans increasingly share the same workspace, the development of safe motion plans becomes paramount. For real-world applications, nonetheless, it is critical that safety solutions are achieved without compromising performance. The computation of safe, time-efficient trajectories, however, usually requires rather complex often decoupled planning and optimization methods which degrades the nominal performance. In this work, instead, we cast the problem as a graph search-based scheme that enables us to solve the problem efficiently. The graph search is guided by an informed cost balance criterion. In this context we present the S* algorithm which minimizes the total planning time by equilibrising shortest time-efficient paths and paths with higher safe velocities. The approach is compatible with standards and validated both in rigorous simulation trials on a 6 DoF UR5 robot as well as real world experiments on a Franka Emika 7 DoF research robot. keywords: {Costs;Optimization methods;Human-robot interaction;Search problems;Safety;Planning;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161248&isnumber=10160212

K. Nakamura and S. Bansal, "Online Update of Safety Assurances Using Confidence-Based Predictions," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 12765-12771, doi: 10.1109/ICRA48891.2023.10160828.Abstract: Robots such as autonomous vehicles and assistive manipulators are increasingly operating in dynamic environ-ments and close physical proximity to people. In such scenarios, the robot can leverage a human motion predictor to predict their future states and plan safe and efficient trajectories. However, no model is ever perfect - when the observed human behavior deviates from the model predictions, the robot might plan unsafe maneuvers. Recent works have explored maintaining a confidence parameter in the human model to overcome this challenge, wherein the predicted human actions are tempered online based on the likelihood of the observed human action under the prediction model. This has opened up a new research challenge, i.e., how to compute the future human states online as the confidence parameter changes? In this work, we propose a Hamilton-Jacobi (HJ) reachability-based approach to overcome this challenge. Treating the confidence parameter as a virtual state in the system, we compute a parameter-conditioned forward reachable tube (FRT) that provides the future human states as a function of the confidence parameter. Online, as the confidence parameter changes, we can simply query the corresponding FRT, and use it to update the robot plan. Computing parameter-conditioned FRT corre-sponds to an (offline) high-dimensional reachability problem, which we solve by leveraging recent advances in data-driven reachability analysis. Overall, our framework enables online maintenance and updates of safety assurances in human-robot interaction scenarios, even when the human prediction model is incorrect. We demonstrate our approach in several safety-critical autonomous driving scenarios, involving a state-of-the-art deep learning-based prediction model. keywords: {Computational modeling;Human-robot interaction;Predictive models;Maintenance engineering;Safety;Trajectory;Vehicle dynamics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160828&isnumber=10160212

