R. Caballero, A. Coronado and E. Feron, "Computational Modeling in System with Non-Circular Timing Pulleys," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9714-9720, doi: 10.1109/ICRA48891.2023.10160802.Abstract: We analyze and model a belt transmission system with non-circular timing pulleys. Using a 3D printer as a proof-of-concept device, experiments consisting of tracking the pose data of a printer nozzle and its pulleys are conducted. A computational model from our previous work is validated with the experimental data and expanded to model more complex systems with multiple non-circular timing pulleys as well as slippage and non-ideal tensions. Finally, an example with two non-circular timing pulleys is presented and simulated utilizing the proposed method. keywords: {Printing;Solid modeling;Three-dimensional displays;Shape;Pulleys;Computational modeling;Belts},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160802&isnumber=10160212

J. -P. Merlet and Y. Papegay, "The new exhibition Blind machines, a large 3D printing machine," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9721-9727, doi: 10.1109/ICRA48891.2023.10160478.Abstract: This paper presents the further developments and preliminary results of a large 3D printing machine based on a 3 d.o.f cable-driven parallel robot (CDPR) that is used for an artistic exhibition. The printing material is a powder constituted of glass micro-beads that is deposited on a fixed trajectory so that the resulting structure collapses with time. A first exhibition has been held during the summer of 2019 and another one was scheduled to take place during ICRA 2020, that was canceled because of the Covid. The current exhibition has started on 07/09/2022 and will end on 10/14/2019. We describe in this paper the improvements of the current prototype, both on hardware and software, compared to the 2019 and 2020 versions. Between 7/9/2022 and 16/10/2022 the CDPR has run for 126 hours and has traveled on a total distance of 9km. During the period 142 layers have been deposited, representing a mass of 2.56 tons of glass powder. keywords: {COVID-19;Parallel robots;Powders;Automation;Prototypes;Glass;Three-dimensional printing;cable-driven parallel robot;kinematics;art;AI},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160478&isnumber=10160212

F. Thomas, "New Bracket Polynomials Associated with the General Gough-Stewart Parallel Robot Singularities," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9728-9734, doi: 10.1109/ICRA48891.2023.10161484.Abstract: It is well known that the singularities of a Gough-Stewart platform arise when the determinant of the Plücker coordinates of the robot leg lines vanish. The direct expansion of this determinant in terms of the configuration of the moving platform leads to an intimidating algebraic expression which is difficult to organize in a manner that facilitates extracting geometric conditions for singularities to occur. The use of Grassmann-Cayley algebra has permitted expressing this determinant as a bracket polynomial which is easier to manipulate symbolically. Each monomial in this polynomial is the product of three brackets, 4×4 determinants involving the homogeneous coordinates of four leg attachments. In this paper, we show how to derive, using elementary linear algebra arguments, bracket polynomials where all brackets can be interpreted as reciprocal products between lines. Contrarily to what one might expect, these new bracket polynomials are simpler in general than those previously obtained using Grassmann-Cayley algebra. keywords: {Legged locomotion;Parallel robots;Automation;Robot kinematics;Linear algebra},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161484&isnumber=10160212

P. B. Edwards, A. Baskar, C. Hills, M. Plecnik and J. D. Hauenstein, "Output Mode Switching for Parallel Five-bar Manipulators Using a Graph-based Path Planner," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9735-9741, doi: 10.1109/ICRA48891.2023.10160891.Abstract: The configuration spaces of parallel manipulators exhibit more nonlinearity than serial manipulators. Qualitatively, they can be seen to possess extra folds. Projection onto smaller spaces of engineering relevance, such as an output workspace or an input actuator space, these folds cast edges that exhibit boundary behavior. For example, inside the global workspace bounds of a five-bar linkage appear several local workspace bounds that only constrain certain output modes of the mechanism. The presence of such boundaries, which manifest in both input and output projections, serve as a source of confusion when these projections are studied exclusively instead of the configuration space itself. Particularly, the design of nonsymmetric parallel manipulators has been confounded by the presence of exotic projections in their input and output spaces. In this paper, we represent the configuration space with a radius graph, then weight each edge by solving an optimization problem using homotopy continuation to quantify transmission quality. We then employ a graph path planner to approximate geodesics between configuration points that avoid regions of low transmission quality. Our methodology automatically generates paths capable of transitioning between non-neighboring output modes, a motion which involves osculating multiple workspace boundaries (local, global, or both). We apply our technique to two nonsymmetric five-bar examples that demonstrate how transmission properties and other characteristics of the workspace can be selected by switching output modes. keywords: {Couplings;Switches;Color;Manipulators;Planning;Partitioning algorithms;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160891&isnumber=10160212

X. Wang et al., "Dimensional Optimization and Anti-Disturbance Analysis of an Upgraded Feed Mechanism in FAST," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9742-9748, doi: 10.1109/ICRA48891.2023.10160750.Abstract: Five-hundred-meter aperture spherical radio telescope (FAST) is a very famous large-scale scientific facility with excellent performance for astronomical observation in the world, but it currently fails to observe the center of the Milky Way Galaxy due to the limited observation angle that is affected by the heavy weight of the feed cabin. To improve this problem, an upgraded feed mechanism (UFM) with a lighter cable structure is designed and employed to replace the existing heavy rigid A-B rotator and Stewart platform in the feed cabin of FAST. The structural dimension of the UFM is analyzed and optimized under cable tension constraints to meet the requirements of the observation angle. Then, a novel disturbance increment method is proposed to analyze the anti-disturbance ability of the UFM, where a gradually increased disturbance wrench is applied to the UFM with the stiffness matrix iteratively updated. Through the dimensional optimization and further anti-disturbance analysis, the newly-designed UFM can indeed meet the higher demand for astronomical observation with the larger observation angle, which benefits from the lightweight cable structure. Besides, the UFM also has the appreciable anti-disturbance ability for long-term stable operation of FAST. keywords: {Automation;Radio astronomy;Simulation;Prototypes;Apertures;Structural engineering;Feeds},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160750&isnumber=10160212

S. Silva, N. Verdezoto, D. Paillacho, S. Millan-Norman and J. D. Hernández, "Online Social Robot Navigation in Indoor, Large and Crowded Environments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9749-9756, doi: 10.1109/ICRA48891.2023.10160603.Abstract: New robotics applications require robots to complete tasks in social spaces (i.e. environments shared with people), thus arising the necessity of enabling robots to operate in a socially acceptable manner. Some social spaces tend to be large and crowded (e.g. museums, shopping malls), which require robots to move around while showing appropriate social behaviors (e.g. not interfering with human's comfortable areas). Moving under such conditions is generally called social robot navigation, and there are different approaches to do so. Nonetheless, current approaches are mostly limited to navigate large and outdoor spaces, where both robots and people can easily avoid each other. Other approaches have been tested in indoor environments, however, the test environments tend to be small and largely empty. In this paper, we present an online social robot navigation framework, which allow robots to navigate indoor, large and crowded environments, while showing social behaviors. Our framework consists of 3 modules: 1) world modeling that incorporates a novel Social Heatmap (SH) to represent crowded areas, 2) multilayered path planning that uses sampling-based approaches, and 3) path following control. We extensively benchmark our approach against state-of-the-art approaches in challenging simulated scenarios, and $w$ e also demonstrate its feasibility with the Pepper robot in real-world trials. keywords: {Heating systems;Automation;Navigation;Social robots;Benchmark testing;Path planning;Museums},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160603&isnumber=10160212

R. K. Cosner, Y. Chen, K. Leung and M. Pavone, "Learning Responsibility Allocations for Safe Human-Robot Interaction with Applications to Autonomous Driving," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9757-9763, doi: 10.1109/ICRA48891.2023.10161112.Abstract: Drivers have a responsibility to exercise reasonable care to avoid collision with other road users. This assumed responsibility allows interacting agents to maintain safety without explicit coordination. Thus to enable safe autonomous vehicle (AV) interactions, AVs must understand what their responsibilities are to maintain safety and how they affect the safety of nearby agents. In this work we seek to understand how responsibility is shared in multi-agent settings where an autonomous agent is interacting with human counterparts. We introduce Responsibility-Aware Control Barrier Functions (RA-CBFs) and present a method to learn responsibility allocations from data. By combining safety-critical control and learning- based techniques, RA-CBFs allow us to account for scene- dependent responsibility allocations and synthesize safe and efficient driving behaviors without making worst-case assumptions that typically result in overly-conservative behaviors. We test our framework using real-world driving data and demonstrate its efficacy as a tool for both safe control and forensic analysis of unsafe driving. keywords: {Navigation;Roads;Forensics;Human-robot interaction;Autonomous agents;Safety;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161112&isnumber=10160212

S. Sobti, R. Shome and L. E. Kavraki, "Efficient Inference of Temporal Task Specifications from Human Demonstrations using Experiment Design," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9764-9770, doi: 10.1109/ICRA48891.2023.10160692.Abstract: Robotic deployments in human environments have motivated the need for autonomous systems to be able to interact with humans and solve tasks effectively. Human demonstrations of tasks can be used to infer underlying task specifications, commonly modeled with temporal logic. State-of-the-art methods have developed Bayesian inference tools to estimate a temporal logic formula from a sequence of demon-strations. The current work proposes the use of experiment design to choose environments for humans to perform these demonstrations. This reduces the number of demonstrations needed to estimate the unknown ground truth formula with low error. A novel computationally efficient strategy is proposed to generate informative environments by using an optimal planner as the model for the demonstrator. Instead of evaluating all possible environments, the search space reduces to the placement of informative orderings of likely eventual goals along an optimal planner's solution. A human study with 600 demonstrations from 20 participants for 4 tasks on a 2D interface validates the proposed hypothesis and empirical performance benefit in terms of convergence and error over baselines. The human study dataset is also publicly shared. keywords: {Automation;Autonomous systems;Computational modeling;Computational efficiency;Bayes methods;Task analysis;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160692&isnumber=10160212

A. Dahiya, Y. Cai, O. Schneider and S. L. Smith, "On the Impact of Interruptions During Multi-Robot Supervision Tasks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9771-9777, doi: 10.1109/ICRA48891.2023.10160323.Abstract: Human supervisors in multi-robot systems are primarily responsible for monitoring robots, but can also be assigned with secondary tasks. These tasks can act as interruptions and can be categorized as either intrinsic, i.e., being directly related to the monitoring task, or extrinsic, i.e., being unrelated. In this paper, we investigate the impact of these two types of interruptions through a user study (N = 39), where participants monitor a number of remote mobile robots while intermittently being interrupted by either a robot fault correction task (intrinsic) or a messaging task (extrinsic). We find that task performance of participants does not change significantly with the interruptions but depends greatly on the number of robots. However, interruptions result in an increase in perceived workload, and extrinsic interruptions have a more negative effect on workload across all NASA-TLX scales. Participants also reported switching between extrinsic interruptions and the primary task to be more difficult compared to the intrinsic interruption case. Statistical significance of these results is confirmed using ANOVA and one-sample t-test. These findings suggest that when deciding task assignment in such supervision systems, one should limit interruptions from secondary tasks, especially extrinsic ones, in order to limit user workload. keywords: {Automation;Switches;Multi-robot systems;Mobile robots;Task analysis;Monitoring;Analysis of variance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160323&isnumber=10160212

H. Hwang et al., "System Configuration and Navigation of a Guide Dog Robot: Toward Animal Guide Dog-Level Guiding Work," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9778-9784, doi: 10.1109/ICRA48891.2023.10160573.Abstract: A robot guide dog has compelling advantages over animal guide dogs for its cost-effectiveness, the potential for mass production, and low maintenance burden. However, despite the long history of guide dog robot research, previous studies were conducted with little or no consideration of how the guide dog handler and the guide dog work as a team for navigation. To develop a robotic guiding system that genuinely benefits blind or visually impaired individuals, we performed qualitative research, including interviews with guide dog handlers, trainers, and first-hand blindfold walking experiences with various guide dogs. We build a collaborative indoor navigation scheme for a guide dog robot that includes preferred features such as speed and directional control. For collaborative navigation, we propose a semantic-aware local path planner that enables safe and efficient guiding work by utilizing semantic information about the environment and considering the handler's position and directional cues to determine the collision-free path. We evaluate our integrated robotic system by testing blindfolded walking in indoor settings and demonstrate guide dog-like navigation behavior by avoiding obstacles at typical gait speed (0.7m/s). The following demonstration video link includes an audio description: https://youtu.be/YxlcMeaL7GA keywords: {Legged locomotion;Mass production;Semantics;Collaboration;Dogs;Maintenance engineering;Collision avoidance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160573&isnumber=10160212

C. T. Chang, M. B. Luebbers, M. Hebert and B. Hayes, "Human Non-Compliance with Robot Spatial Ownership Communicated via Augmented Reality: Implications for Human-Robot Teaming Safety," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9785-9792, doi: 10.1109/ICRA48891.2023.10161277.Abstract: Ensuring the safety and efficiency of human workers in environments shared with autonomous robots is of paramount importance. In this work we examine the behavior and attitudes of participants performing tasks in a noisy environment collocated with an autonomous quadcopter robot. Visual communication of spatial ownership and nonverbal (deictic gesture) requests for changes in spatial ownership are facilitated using an augmented reality (AR) head-mounted device that renders a color-keyed grid on the floor. After a request, the robot can alter floor ownership to provide participants with a safe path to complete their work. Participants ($n=20$) in a between-subjects study took part in either a shared space condition (concurrently occupying the work floor with the robot, with obvious rationale for floor ownership) or a turn-taking condition (alternating excursions onto the grid with the robot, without apparent rationale for the floor grid colors). We find consistent evidence of potentially dangerous over-trust in the system that led to non-compliance; notably, 25% of participants intentionally walked across forbidden floor regions during the experiment. We identify design considerations and a variety of user-borne rationale for committing safety violations that designers will need to explicitly take measures to remedy in production AR safety systems. keywords: {Performance evaluation;Visual communication;Production;Particle measurements;Safety;Noise measurement;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161277&isnumber=10160212

Y. You, V. Thomas, F. Colas, R. Alami and O. Buffet, "Robust Robot Planning for Human-Robot Collaboration," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9793-9799, doi: 10.1109/ICRA48891.2023.10161406.Abstract: In human-robot collaboration, the objectives of the human are often unknown to the robot. Moreover, even assuming a known objective, the human behavior is also uncertain. In order to plan a robust robot behavior, a key preliminary question is then: How to derive realistic human behaviors given a known objective? A major issue is that such a human behavior should itself account for the robot behavior, otherwise collaboration cannot happen. In this paper, we rely on Markov decision models, representing the uncertainty over the human objective as a probability distribution over a finite set of objective functions (inducing a distribution over human behaviors). Based on this, we propose two contributions: 1) an approach to automatically generate an uncertain human behavior (a policy) for each given objective function while accounting for possible robot behaviors; and 2) a robot planning algorithm that is robust to the above-mentioned uncertainties and relies on solving a partially observable Markov decision process (POMDP) obtained by reasoning on a distribution over human behaviors. A co-working scenario allows conducting experiments and presenting qualitative and quantitative results to evaluate our approach. keywords: {Uncertainty;Collaboration;Markov processes;Linear programming;Behavioral sciences;Planning;Power capacitors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161406&isnumber=10160212

W. Wang, X. Li, Y. Dong, J. Xie, D. Guo and H. Liu, "Natural Language Instruction Understanding for Robotic Manipulation: a Multisensory Perception Approach," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9800-9806, doi: 10.1109/ICRA48891.2023.10160906.Abstract: It has always been expected that the robot can understand the natural language instruction and thus a more natural human-robot interaction is achieved. Currently, the robot usually interprets the instruction by visually grounding the textual information to its surroundings, while it may be not enough for some complex situations with only visual perception. So it is reasonable for the robot to leverage its multisensory perception ability to better understand the instruction. In this paper, we propose a multisensory perception approach to tackle the task of natural language instruction understanding for robotic manipulation, in which the robot coordinates its visual, tactile and auditory perception to fully understand the instruction and then executes the manipulation task. Extensive experiments have been conducted demonstrating the superiority of the multisensory perception compared with single sensory perception for instruction understanding. Moreover, we establish a user-friendly human-robot interaction interface where the human sends instruction to the robot via a mobile APP. keywords: {Visualization;Automation;Grounding;Robot kinematics;Natural languages;Human-robot interaction;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160906&isnumber=10160212

Y. Liu, J. Yang, X. Gu, Y. Guo and G. -Z. Yang, "EgoHMR: Egocentric Human Mesh Recovery via Hierarchical Latent Diffusion Model," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9807-9813, doi: 10.1109/ICRA48891.2023.10161247.Abstract: Egocentric vision has gained increasing popularity in social robotics, demonstrating great potentials for personal assistance and human-centric behavior analysis. Holistic per-ception of human body itself is a prerequisite for downstream applications, including action recognition and anticipation. Extensive research has been performed for human mesh recovery from the exocentric images captured from a third-person view, but limited studies are conducted for heavily distorted yet occluded egocentric images. In this paper, we propose Egocentric Human Mesh Recovery (EgoHMR), a novel hierarchical network based on latent diffusion models. Our method takes a single egocentric frame as the input and it can be trained in an end-to-end manner without supervision of 2D pose. The network is built upon the latent diffusion model by incorporating both global and local features in a hierarchical structure. To train the proposed network, we generate weak labels from synchronized exocentric images. The proposed method can perform human mesh recovery directly from egocentric images and detailed quantitative and qualitative experiments have been conducted to demonstrate the effectiveness of the proposed EgoHMR method. keywords: {Solid modeling;Three-dimensional displays;Automation;Focusing;Behavioral sciences;Synchronization;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161247&isnumber=10160212

M. Singhala and J. D. Brown, "Telerobot operators can account for varying transmission dynamics in a visuo-haptic object tracking task," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9814-9820, doi: 10.1109/ICRA48891.2023.10160509.Abstract: Humans possess an innate ability to incorporate tools into our body schema to perform a myriad of tasks not possible with our natural limbs. Human-in-the-loop telerobotic systems (HiLTS) are tools that extend human manipulation capabilities to remote and virtual environments. Unlike most hand-held tools, however, HiLTS often possess complex electromechanical architectures that introduce non-trivial transmission dynamics between the robot's leader and follower, which alter or obfuscate the environment's dynamics. While considerable research has focused on negating or circumventing these dynamics, it is not well understood how capable human operators are at incorporating these transmission dynamics into their sensorimotor control scheme. To begin answering this question, we recruited $\mathrm{N}=12$ participants to use a novel reconfigurable teleoperator with varying transmission dynamics to perform a visuo-haptic tracking task. Contrary to our original hypothesis, our findings demonstrate that humans can account for substantial differences in teleoperator transmission dynamics and produce the compensatory strategies necessary to adequately control the teleoperator. These findings suggest that advances in transparency algorithms and haptic feedback approaches must be coupled with control designs that leverage the unique capabilities of the human operator in the loop. keywords: {Teleoperators;Automation;Control design;Heuristic algorithms;Virtual environments;Robot sensing systems;Human in the loop},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160509&isnumber=10160212

Z. Huang et al., "Hierarchical Intention Tracking for Robust Human-Robot Collaboration in Industrial Assembly Tasks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9821-9828, doi: 10.1109/ICRA48891.2023.10160515.Abstract: Collaborative robots require effective human intention estimation to safely and smoothly work with humans in less structured tasks such as industrial assembly, where human intention continuously changes. We propose the concept of intention tracking and introduce a collaborative robot system that concurrently tracks intentions at hierarchical levels. The high-level intention is tracked to estimate human's interaction pattern and enable robot to (1) avoid collision with human to minimize interruption and (2) assist human to correct failure. The low-level intention estimate provides robot with task-related information. We implement the system on a UR5e robot and demonstrate robust, seamless and ergonomic human-robot collaboration in an ablative pilot study of an assembly use case. keywords: {Learning systems;Automation;Service robots;Ergonomics;Collaboration;Estimation;Recording},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160515&isnumber=10160212

A. K. Keshari, H. Ren and A. H. Qureshi, "CoGrasp: 6-DoF Grasp Generation for Human-Robot Collaboration," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9829-9836, doi: 10.1109/ICRA48891.2023.10160623.Abstract: Robot grasping is an actively studied area in robotics, mainly focusing on the quality of generated grasps for object manipulation. However, despite advancements, these methods do not consider the human-robot collaboration settings where robots and humans will have to grasp the same objects concurrently. Therefore, generating robot grasps compatible with human preferences of simultaneously holding an object becomes necessary to ensure a safe and natural collaboration experience. In this paper, we propose a novel, deep neural network-based method called CoGrasp that generates human-aware robot grasps by contextualizing human preference mod-els of object grasping into the robot grasp selection pro-cess. We validate our approach against existing state-of-the-art robot grasping methods through simulated and real-robot experiments and user studies. In real robot experiments, our method achieves about 88% success rate in producing stable grasps that also allow humans to interact and grasp objects simultaneously in a socially compliant manner. Furthermore, our user study with 10 independent participants indicated our approach enables a safe, natural, and socially-aware human-robot objects' co-grasping experience compared to a standard robot grasping technique. keywords: {Measurement;Automation;Collaboration;Focusing;Grasping;6-DOF;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160623&isnumber=10160212

H. Ahn, E. V. Mascaro and D. Lee, "Can We Use Diffusion Probabilistic Models for 3D Motion Prediction?," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9837-9843, doi: 10.1109/ICRA48891.2023.10160722.Abstract: After many researchers observed fruitfulness from the recent diffusion probabilistic model, its effectiveness in image generation is actively studied these days. In this paper, our objective is to evaluate the potential of diffusion probabilistic models for 3D human motion-related tasks. To this end, this pa-per presents a study of employing diffusion probabilistic models to predict future 3D human motion(s) from the previously observed motion. Based on the Human 3.6M and HumanEva-I datasets, our results show that diffusion probabilistic models are competitive for both single (deterministic) and multiple (stochastic) 3D motion prediction tasks, after finishing a single training process. In addition, we find out that diffusion probabilistic models can offer an attractive compromise, since they can strike the right balance between the likelihood and diversity of the predicted future motions. Our code is publicly available on the project website: https://sites.google.com/view/diffusion-motion-prediction. keywords: {Solid modeling;Three-dimensional displays;Noise reduction;Stochastic processes;Predictive models;Probabilistic logic;Transformers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160722&isnumber=10160212

A. Rasouli and I. Kotseruba, "PedFormer: Pedestrian Behavior Prediction via Cross-Modal Attention Modulation and Gated Multitask Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9844-9851, doi: 10.1109/ICRA48891.2023.10161318.Abstract: Predicting pedestrian behavior is a crucial task for intelligent driving systems. Accurate predictions require a deep understanding of various contextual elements that could impact the way pedestrians behave. To address this challenge, we propose a novel framework that relies on different data modalities to predict future trajectories and crossing actions of pedestrians from an egocentric perspective. Specifically, our model utilizes a cross-modal Transformer architecture to capture dependencies between different data types. The output of the Transformer is augmented with representations of interactions between pedestrians and other traffic agents conditioned on the pedestrian and ego-vehicle dynamics that are generated via a semantic attentive interaction module. Lastly, the context encodings are fed into a multi-stream decoder framework using a gated-shared network. We evaluate our algorithm on public pedestrian behavior benchmarks, PIE and JAAD, and show that our model improves state-of-the-art in trajectory and action prediction by up to 22% and 13% respectively on various metrics. The advantages of the proposed components are investigated via extensive ablation studies. keywords: {Pedestrians;Semantics;Modulation;Logic gates;Benchmark testing;Transformers;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161318&isnumber=10160212

X. Li, H. Zeng, C. Yang and A. Song, "Robot-Assisted Eye-Hand Coordination Training System by Estimating Motion Direction Using Smooth-Pursuit Eye Movements," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9852-9857, doi: 10.1109/ICRA48891.2023.10160956.Abstract: Robot-assisted eye-hand coordination rehabilitation training system is extremely urgent to study since recent evidence suggests that eye-hand coordination can be brutally disturbed by stroke with critical consequences on motor behavior. In this paper, we develop a robot-assisted eye-hand coordination training system by estimating motion direction using smooth-pursuit eye movements. Firstly, we design a Pong Game, which requires users to extrapolate the direction of a linearly moving ball and to predict whether this ball would be hit. Secondly, the motion direction of the ball is estimated via smooth-pursuit eye movements, allowing the robot quickly establish an assistive force field to hit the ball. Thirdly, adding haptic feedback technology into this training system to make users more immersive. Finally, we conduct a feasibility study with eight healthy subjects to verify the effectiveness of the proposed system. The experimental results show that the mean success rate for hitting the pong ball of the experiment group (assistance turn-on) is 28.33% higher than that of the control group (assistance turn-off), and the mean interception time of the experiment group is 0.35s shorter than that of the control group. Therefore, the developed system may be promising for transferring to the robot-assisted eye-hand coordination rehabilitation training for post-stroke patients. keywords: {Training;Automation;Robot kinematics;Force;Games;Stroke (medical condition);Haptic interfaces},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160956&isnumber=10160212

X. Gu, J. Han, G. -Z. Yang and B. Lo, "Generalizable Movement Intention Recognition with Multiple Heterogeneous EEG Datasets," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9858-9864, doi: 10.1109/ICRA48891.2023.10160462.Abstract: Human movement intention recognition is important for human-robot interaction. Existing work based on motor imagery electroencephalogram (EEG) provides a non-invasive and portable solution for intention detection. However, the data-driven methods may suffer from the limited scale and diversity of the training datasets, which result in poor generalization performance on new test subjects. It is practically difficult to directly aggregate data from multiple datasets for training, since they often employ different channels and collected data suffers from significant domain shifts caused by different devices, experiment setup, etc. On the other hand, the inter-subject heterogeneity is also substantial due to individual differences in EEG representations. In this work, we developed two networks to learn from both the shared and the complete channels across datasets, handling inter-subject and inter-dataset heterogeneity respectively. Based on both networks, we further developed an online knowledge co-distillation framework to collaboratively learn from both networks, achieving coherent performance boosts. Experimental results have shown that our proposed method can effectively aggregate knowledge from multiple datasets, demonstrating better generalization in the context of cross-subject validation. keywords: {Training;Knowledge engineering;Performance evaluation;Ethics;Heuristic algorithms;Human-robot interaction;Training data},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160462&isnumber=10160212

S. Kotsovolis and Y. Demiris, "Bi-Manual Manipulation of Multi-Component Garments towards Robot-Assisted Dressing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9865-9871, doi: 10.1109/ICRA48891.2023.10161335.Abstract: In this paper, we propose a strategy for robot-assisted dressing with multi-component garments, such as gloves. Most studies in robot-assisted dressing usually experiment with single-component garments, such as sleeves, while multi-component tasks are often approached as sequential single-component problems. In dressing scenarios with more complex garments, robots should estimate the alignment of the human body to the manipulated garments, and revise their dressing strategy. In this paper, we focus on a glove dressing scenario and propose a decision process for selecting dressing action primitives on the different components of the garment, based on a hierarchical representation of the task and a set of environmental conditions. To complement this process, we propose a set of bi-manual control strategies, based on hybrid position, visual, and force feedback, in order to execute the dressing action primitives with the deformable object. The experimental results validate our method, enabling the Baxter robot to dress a mannequin's hand with a gardening glove. keywords: {Visualization;Automation;Clothing;Force feedback;Process control;Task analysis;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161335&isnumber=10160212

M. Edraki, P. Maurice and D. Sternad, "Humans Need Augmented Feedback to Physically Track Non-Biological Robot Movements," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9872-9878, doi: 10.1109/ICRA48891.2023.10161075.Abstract: An important component for the effective collaboration of humans with robots is the compatibility of their movements, especially when humans physically collaborate with a robot partner. Following previous findings that humans interact more seamlessly with a robot that moves with human-like or biological velocity profiles, this study examined whether humans can adapt to a robot that violates human signatures. The specific focus was on the role of extensive practice and real-time augmented feedback. Six groups of participants physically tracked a robot tracing an ellipse with profiles where velocity scaled with the curvature of the path in biological and non-biological ways, while instructed to minimize the interaction force with the robot. Three of the 6 groups received real-time visual feedback about their force error. Results showed that with 3 daily practice sessions, when given feedback about their force errors, humans could decrease their interaction forces when the robot's trajectory violated human-like velocity patterns. Conversely, when augmented feedback was not provided, there were no improvements despite this extensive practice. The biological profile showed no improvements, even with feedback, indicating that the (non-zero) force had already reached a floor level. These findings highlight the importance of biological robot trajectories and augmented feedback to guide humans to adapt to non-biological movements in physical human-robot interaction. These results have implications on various fields of robotics, such as surgical applications and collaborative robots for industry. keywords: {Training;Robot motion;Visualization;Service robots;Tracking;Force;Collaboration;Physical Human-Robot Interaction;Human Factors and Human-in-the-Loop;Human-Centered Robotics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161075&isnumber=10160212

R. Yu, B. Kizilkaya, Z. Meng, E. Li, G. Zhao and M. Imran, "Robot Mimicry Attack on Keystroke-Dynamics User Identification and Authentication System," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9879-9884, doi: 10.1109/ICRA48891.2023.10161423.Abstract: Future robots will be very advanced with high flexibility and accurate control performance. They will have the ability to mimic human behaviours or even perform better, which raises the significant risk of robot attack. In this work, we study the robot mimic attack on the current keystroke-dynamic user authentication system. Specifically, we proposed a robot mimicry attack framework for keystroke-dynamics systems. We collected keyboard logging data and acoustical signal data from real users and extracted the timing pattern of keystrokes to understand victim's behaviour for robot imitation attacks. Furthermore, we develop a deep Q-Network (DQN) algorithm to control the velocity of robot which is one of the key challenges of forging the human typing timing features. We tested and evaluated our approach on the real-life robotic testbed. We presented our results considering user identification and user authentication performance. We achieved a 90.3% user identification accuracy with genuine keyboard logging data samples and 89.6% accuracy with robot-forged data samples. Furthermore, we achieved 11.1%, and 36.6% EER for user authentication performance with zero-effort attack, and robot mimicry attack, respectively. keywords: {Automation;Authentication;Keyboards;Pressing;Feature extraction;Timing;Data mining},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161423&isnumber=10160212

L. Shaikewitz, Y. Wu, S. Belkhale, J. Grannen, P. Sundaresan and D. Sadigh, "In-Mouth Robotic Bite Transfer with Visual and Haptic Sensing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9885-9895, doi: 10.1109/ICRA48891.2023.10160467.Abstract: Assistance during eating is essential for those with severe mobility issues or eating risks. However, dependence on traditional human caregivers is linked to malnutrition, weight loss, and low self-esteem. For those who require eating assistance, a semi-autonomous robotic platform can provide independence and a healthier lifestyle. We demonstrate an essential capability of this platform: safe, comfortable, and effective transfer of a bite-sized food item from a utensil directly to the inside of a person's mouth. Our system uses a force-reactive controller to safely accommodate the user's motions throughout the transfer, allowing full reactivity until bite detection then reducing reactivity in the direction of exit. Additionally, we introduce a novel dexterous wrist-like end effector capable of small, unimposing movements to reduce user discomfort. We conduct a user study with 11 participants covering 8 diverse food categories to evaluate our system end-to-end, and we find that users strongly prefer our method to a wide range of baselines. Appendices and videos are available at our website: https://tinyurl.com/btICRA. keywords: {Wrist;Visualization;Mouth;Robot sensing systems;End effectors;Haptic interfaces;Trajectory;Physical Human Robot Interaction;Physically Assistive Devices;Human Robot Collaboration},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160467&isnumber=10160212

Q. Wang, D. Liu, M. G. Carmichael and C. -T. Lin, "Robot Trust and Self-Confidence Based Role Arbitration Method for Physical Human-Robot Collaboration," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9896-9902, doi: 10.1109/ICRA48891.2023.10160711.Abstract: Role arbitration in human-robot collaboration (HRC) is a dynamically changing process that is affected by many factors such as physical workload, environmental changes and trust. In order to address this dynamic process, a trust-based role arbitration method is studied in this research. A computational model of robot trust and self-confidence (TSC) in physical human-robot collaboration (pHRC) is proposed. The TSC model is defined as a function of objective robot and human co-worker performance. A role arbitration method is then proposed based on the TSC model presented. The human-in-the-loop experiments with a collaborative robot are conducted to verify the TSC-based role arbitration method. The results show that the proposed method could achieve superior human-robot combined performance, reduce human co-workers' workload, and improve subjective preference. keywords: {Automation;Computational modeling;Collaboration;Human in the loop;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160711&isnumber=10160212

N. Feizi, Z. Bahrami, S. F. Atashzar, M. R. Kermani and R. V. Patel, "Design Optimization and Data-driven Shallow Learning for Dynamic Modeling of a Smart Segmented Electroadhesive Clutch," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9903-9909, doi: 10.1109/ICRA48891.2023.10161225.Abstract: Electroadhesive clutches have attracted a great deal of interest in the last decade as semi-active actuators for human-robot interaction due to their lightweight, low power consumption, and tunable high-torque output capability. However, because of the complexity of their dynamics, in most cases, they are utilized in an ON/OFF -control strategy. In this regard, the non-autonomous (time-dependent) degradation of electroadhesive behavior is an inherent challenge that injects unpredictability and uncertainty into the behavior of this family of semi-active clutches. We propose a novel approach to preventing degradation of electroadhesion using a segmented electrode design that modulates the electrical field on the dielectric surface while using a direct current signal and securing low power consumption. This paper, for the first time, presents an optimization process based on a novel analytic model of the proposed actuator. It also develops a data-driven model augmentation using a hybrid shallow learning approach composed of a long short-term memory (LSTM) architecture which is combined with the analytical model. The performance of the proposed semi-active clutch and the data-driven hybrid model is experimentally validated in this paper. keywords: {Degradation;Electrodes;Analytical models;Adaptation models;Actuators;Torque;Power demand},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161225&isnumber=10160212

A. Shek, B. Y. Su, R. Chen and C. Liu, "Learning from Physical Human Feedback: An Object-Centric One-Shot Adaptation Method," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9910-9916, doi: 10.1109/ICRA48891.2023.10161416.Abstract: For robots to be effectively deployed in novel environments and tasks, they must be able to understand the feedback expressed by humans during intervention. This can either correct undesirable behavior or indicate additional preferences. Existing methods either require repeated episodes of interactions or assume prior known reward features, which is data-inefficient and can hardly transfer to new tasks. We relax these assumptions by describing human tasks in terms of object-centric sub-tasks and interpreting physical interventions in relation to specific objects. Our method, Object Preference Adaptation (OPA), is composed of two key stages: 1) pre-training a base policy to produce a wide variety of behaviors, and 2) online-updating according to human feedback. The key to our fast, yet simple adaptation is that general interaction dynamics between agents and objects are fixed, and only object-specific preferences are updated. Our adaptation occurs online, requires only one human intervention (one-shot), and produces new behaviors never seen during training. Trained on cheap synthetic data instead of expensive human demonstrations, our policy correctly adapts to human perturbations on realistic tasks on a physical 7DOF robot. Videos, code, and supplementary material: https://alvinosaur.github.io/AboutMe/projects/opa. keywords: {Training;Perturbation methods;Inspection;Production facilities;Behavioral sciences;Task analysis;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161416&isnumber=10160212

M. J. Yang, J. Cho, H. Chung, K. Park and J. Kim, "Touch Classification on Robotic Skin using Multimodal Tactile Sensing Modules," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9917-9923, doi: 10.1109/ICRA48891.2023.10160400.Abstract: Human employs different touch patterns to convey diverse social messages; for example, a stroke is an encouragement, whereas a hit is an offense. Various tactile sensors have been developed to grant an intuitive physical interaction with a robotic system, yet many encountered limitations in achieving broad sensibility or fabricating into a large skin. This paper presents a robotic skin with multimodal tactile sensing modules to achieve broad spatiotemporal sensibility with a few sensing elements. The multimodal module is composed of a microphone and a vented screw installed on a conductive sensory domain. A multilayered fabric with a textured surface covers the sensory domain and forms a piezoresistive structure. High and low temporal components of touch elicit a micro-vibration and a conductivity change on the skin, where both are measured with multimodal modules. The measurements are each processed with short-time Fourier transform (STFT) and electrical resistance tomography (ERT) to encode two spatiotemporal feature maps, which are classified into ten touch classes using a convolutional neural network. Due to a sensibility to both high and low temporal components of touch, the skin classifies touches with an accuracy of 97.0 %, whereas only 84.7 % and 90.6 % are achieved when one type of feature map is used. Also, the skin is robust and beneficial in power consumption and fabrication since the multimodal modules are not exposed to an external stimulus and are sparsely distributed. keywords: {Ventilators;Tactile sensors;Tomography;Robot sensing systems;Skin;Sensors;Spatiotemporal phenomena},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160400&isnumber=10160212

R. T. Fawcett, L. Amanzadeh, J. Kim, A. D. Ames and K. A. Hamed, "Distributed Data-Driven Predictive Control for Multi-Agent Collaborative Legged Locomotion," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9924-9930, doi: 10.1109/ICRA48891.2023.10160914.Abstract: The aim of this work is to define a planner that enables robust legged locomotion for complex multi-agent systems consisting of several holonomically constrained quadrupeds. To this end, we employ a methodology based on behavioral systems theory to model the sophisticated and high-dimensional structure induced by the holonomic constraints. The resulting model is then used in tandem with distributed control techniques such that the computational burden is shared across agents while the coupling between agents is preserved. Finally, this distributed model is framed in the context of a predictive controller, resulting in a robustly stable method for trajectory planning. This methodology is tested in simulation with up to five agents and is further experimentally validated on three A1 quadrupedal robots subject to various uncertainties, including payloads, rough terrain, and push disturbances. keywords: {Legged locomotion;Uncertainty;Trajectory planning;Computational modeling;Predictive models;Robustness;Behavioral sciences;Legged Robots;Motion Control;Multi-Contact Whole-Body Motion Planning and Control},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160914&isnumber=10160212

S. Khorshidi et al., "On the Use of Torque Measurement in Centroidal State Estimation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9931-9937, doi: 10.1109/ICRA48891.2023.10160823.Abstract: State-of-the-art legged robots are either capable of measuring torque at the output of their drive systems, or have transparent drive systems which enable the computation of joint torques from motor currents. In either case, this sensor modality is seldom used in state estimation. In this paper, we propose to use joint torque measurements to estimate the centroidal states of legged robots. To do so, we project the whole-body dynamics of a legged robot into the nullspace of the contact constraints, allowing expression of the dynamics independent of the contact forces. Using the constrained dynamics and the centroidal momentum matrix, we are able to directly relate joint torques and centroidal states dynamics. Using the resulting model as the process model of an Extended Kalman Filter (EKF), we fuse the torque measurement in the centroidal state estimation problem. Through real-world experiments on a quadruped robot executing different gaits, we demonstrate that the estimated centroidal states from our torque-based EKF drastically improve the recovery of these quantities compared to direct computation. keywords: {Legged locomotion;Torque;Fuses;Current measurement;Dynamics;Robot sensing systems;Torque measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160823&isnumber=10160212

P. Nikdel, M. Mahdavian and M. Chen, "DMMGAN: Diverse Multi Motion Prediction of 3D Human Joints using Attention-Based Generative Adversarial Network," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9938-9944, doi: 10.1109/ICRA48891.2023.10160401.Abstract: Human body motion prediction is a fundamental part of many human-robot applications. Despite the recent progress in the area, most studies predict human body motion relative to a fixed joint and only limit their model to predict one possible future motion, or both. However, due to the complex nature of human motion, a single prediction cannot adequately reflect the many possible movements one can make. Also, for any robotics application, prediction of the full human body motion including the absolute 3D trajectory - not just a 3D body pose relative to the hip joint - is needed. In this paper, we try to address these two shortcomings by proposing a transformer-based generative model for forecasting multiple diverse human motions. Our model generates $N$ future possible body motions given the human motion history. This is achieved by first predicting the pose of the body relative to the hip joint as was done in prior work. Then, our proposed Hip Prediction Module predicts the trajectory of the hip position relative to a global reference frame for each predicted pose frame, an aspect of human body motion neglected by previous work. To obtain a set of diverse predicted motions, we introduce a similarity loss that penalizes the pairwise sample distance. Our system not only outperforms the state-of-the-art in human motion prediction, but also is able to predict a diverse set of future human body motions, including the hip trajectory. keywords: {Three-dimensional displays;Biological system modeling;Predictive models;Transformers;Generative adversarial networks;Trajectory;History},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160401&isnumber=10160212

A. Rigo, Y. Chen, S. K. Gupta and Q. Nguyen, "Contact Optimization for Non-Prehensile Loco-Manipulation via Hierarchical Model Predictive Control," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9945-9951, doi: 10.1109/ICRA48891.2023.10160507.Abstract: Recent studies on quadruped robots have focused on either locomotion or mobile manipulation using a robotic arm. However, legged robots can manipulate large objects using non-prehensile manipulation primitives, such as planar pushing, to drive the object to the desired location. This paper presents a novel hierarchical model predictive control (MPC) for contact optimization of the manipulation task. Using two cascading MPCs, we split the loco-manipulation problem into two parts: the first to optimize both contact force and contact location between the robot and the object, and the second to regulate the desired interaction force through the robot locomotion. Our method is successfully validated in both simulation and hardware experiments. While the baseline locomotion MPC fails to follow the desired trajectory of the object, our proposed approach can effectively control both object's position and orientation with minimal tracking error. This capability also allows us to perform obstacle avoidance for both the robot and the object during the loco-manipulation task. keywords: {Navigation;Force;Trajectory;Numerical models;Quadrupedal robots;Task analysis;Collision avoidance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160507&isnumber=10160212

C. Khazoom, S. Heim, D. Gonzalez-Diaz and S. Kim, "Optimal Scheduling of Models and Horizons for Model Hierarchy Predictive Control," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9952-9958, doi: 10.1109/ICRA48891.2023.10160528.Abstract: Model predictive control (MPC) is a powerful tool to control systems with non-linear dynamics and constraints, but its computational demands impose limitations on the dynamics model used for planning. Instead of using a single complex model along the MPC horizon, model hierarchy predictive control (MHPC) reduces solve times by planning over a sequence of models of varying complexity within a single horizon. Choosing this model sequence can become intractable when considering all possible combinations of reduced order models and prediction horizons. We propose a framework to systematically optimize a model schedule for MHPC. We leverage trajectory optimization (TO) to approximate the accumulated cost of the closed-loop controller. We trade off performance and solve times by minimizing the number of decision variables of the MHPC problem along the horizon while keeping the approximate closed-loop cost near optimal. The framework is validated in simulation with a planar humanoid robot as a proof of concept. We find that the approximated closed-loop cost matches the simulated one for most of the model schedules, and show that the proposed approach finds optimal model schedules that transfer directly to simulation, and with total horizons that vary between 1.1 and 1.6 walking steps. keywords: {Legged locomotion;Schedules;Costs;Computational modeling;Humanoid robots;Optimal scheduling;Predictive models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160528&isnumber=10160212

M. Mahdavian, P. Nikdel, M. TaherAhmadi and M. Chen, "STPOTR: Simultaneous Human Trajectory and Pose Prediction Using a Non-Autoregressive Transformer for Robot Follow-Ahead," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9959-9965, doi: 10.1109/ICRA48891.2023.10160538.Abstract: In this paper, we greatly expand the capability of robots to perform the follow-ahead task and variations of this task through development of a neural network model to predict future human motion from an observed human motion history. We propose a non-autoregressive transformer architecture to leverage its parallel nature for easier training and fast, accurate predictions at test time. The proposed architecture divides human motion prediction into two parts: 1) the human trajectory, which is the 3D positions of the hip joint over time, and 2) the human pose which is the 3D positions of all other joints over time with respect to a fixed hip joint. We propose to make the two predictions simultaneously, as the shared representation can improve the model performance. Therefore, the model consists of two sets of encoders and decoders. First, a multi-head attention module applied to encoder outputs improves human trajectory. Second, another multi-head self-attention module applied to encoder outputs concatenated with decoder outputs facilitates the learning of temporal dependencies. Our model is well-suited for robotic applications in terms of test accuracy and speed, and compares favorably with respect to state-of-the-art methods. We demonstrate the real-world applicability of our work via the Robot Follow-Ahead task, a challenging yet practical case study for our proposed model. The human motion predicted by our model enables the robot follow-ahead in scenarios that require taking detailed human motion into account such as sit-to-stand, stand-to-sit. It also enables simple control policies to trivially generalize to many different variations of human following, such as follow-beside. Our code and data are available at the following Github page: https://github.com/mmahdavian/STPOTR keywords: {Training;Three-dimensional displays;Predictive models;Transformers;Trajectory;Decoding;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160538&isnumber=10160212

V. Dhédin et al., "Visual-Inertial and Leg Odometry Fusion for Dynamic Locomotion," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9966-9972, doi: 10.1109/ICRA48891.2023.10160898.Abstract: Implementing dynamic locomotion behaviors on legged robots requires a high-quality state estimation module. Especially when the motion includes flight phases, state-of-the-art approaches fail to produce reliable estimation of the robot posture, in particular base height. In this paper, we propose a novel approach for combining visual-inertial odometry (VIO) with leg odometry in an extended Kalman filter (EKF) based state estimator. The VIO module uses a stereo camera and IMU to yield low-drift 3D position and yaw orientation and drift-free pitch and roll orientation of the robot base link in the inertial frame. However, these values have a considerable amount of latency due to image processing and optimization, while the rate of update is quite low which is not suitable for low-level control. To reduce the latency, we predict the VIO state estimate at the rate of the IMU measurements of the VIO sensor. The EKF module uses the base pose and linear velocity predicted by VIO, fuses them further with a second high-rate IMU and leg odometry measurements, and produces robot state estimates with a high frequency and small latency suitable for control. We integrate this lightweight estimation framework with a nonlinear model predictive controller and show successful implementation of a set of agile locomotion behaviors, including trotting and jumping at varying horizontal speeds, on a torque-controlled quadruped robot. keywords: {Legged locomotion;Three-dimensional displays;Fuses;Trajectory planning;Delays;Behavioral sciences;Odometry},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160898&isnumber=10160212

C. Mailer, S. Shield, R. Govender and A. Patel, "Getting Air: Modelling and Control of a Hybrid Pneumatic-Electric Legged Robot," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9973-9979, doi: 10.1109/ICRA48891.2023.10160737.Abstract: With their combination of power and compliance, pneumatic actuators have great potential for enabling dynamic and agile behaviors in legged robots, but their complex dynam-ics impose control challenges that have hindered widespread use. In this paper, we describe the development of a tractable model and characterization procedure of an off-the-shelf double acting pneumatic cylinder controlled by on/off solenoid valves for use in trajectory optimization. With this we are able to generate motions which incorporate both the body and actuator dynamics of our robot Kemba: a novel quadrupedal robot prototype with a combination of electric and pneumatic actu-ators. We demonstrate both a 0.5 m jump and land maneuver, and a maximal 1 m jump, approximately 2.2 times its leg length, on the physical hardware with the proposed model and approach. The hardware matches the desired trajectory with a maximum height error of only 5 cm without any feedback on the pneumatic joints, demonstrating the utility of the model in high-level motion generation, and capability of the physical robot. keywords: {Legged locomotion;Pneumatic actuators;Atmospheric modeling;Prototypes;Pneumatic systems;Valves;Hardware},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160737&isnumber=10160212

C. -Y. Lee, S. Yang, B. Bokser and Z. Manchester, "Enhanced Balance for Legged Robots Using Reaction Wheels," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9980-9987, doi: 10.1109/ICRA48891.2023.10160833.Abstract: We introduce a reaction wheel system that enhances the balancing capabilities and stability of quadrupedal robots during challenging locomotion tasks. Inspired by both the standard centroidal dynamics model common in legged robotics and models of spacecraft commonly used in the aerospace community, we model the coupled quadruped-reaction-wheel system as a gyrostat, and simplify the dynamics to formulate the problem as a linear discrete-time trajectory optimization problem. Modifications are made to a standard centroidal model-predictive control (MPC) algorithm to solve for both stance foot ground reaction forces and reaction wheel torques simultaneously. The MPC problem is posed as a quadratic program and solved online at 1000 Hz. We demonstrate improved attitude stabilization both in simulation and on hardware compared to a quadruped without reaction wheels, and perform a challenging traversal of a narrow balance beam that would be impossible for a standard quadruped. A video of our experiments is available online1. keywords: {Legged locomotion;Space vehicles;Wheels;Aerodynamics;Stability analysis;Quadrupedal robots;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160833&isnumber=10160212

H. Li, T. Zhang, W. Yu and P. M. Wensing, "Versatile Real-Time Motion Synthesis via Kino-Dynamic MPC With Hybrid-Systems DDP," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9988-9994, doi: 10.1109/ICRA48891.2023.10160221.Abstract: Specialized motions such as jumping are often achieved on quadruped robots by solving a trajectory optimization problem once and executing the trajectory using a tracking controller. This approach is in parallel with Model Predictive Control (MPC) strategies that commonly control regular gaits via online re-planning. In this work, we present a nonlinear MPC (NMPC) technique that unlocks on-the-fly replanning of specialized motion skills and regular locomotion within a unified framework. The NMPC reasons about a hybrid kinodynamic model, and is solved using a variant of a constrained Differential Dynamic Programming (DDP) solver. The proposed NMPC enables the robot to perform a variety of agile skills like jumping, bounding, and trotting, and the rapid transition between them. We evaluated the proposed algorithm with three challenging motion sequences that combine multiple agile skills, on two quadruped platforms, Unitree A1, and MIT Mini Cheetah, showing its effectiveness and generality. keywords: {Legged locomotion;Automation;Tracking;Heuristic algorithms;Real-time systems;Dynamic programming;Quadrupedal robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160221&isnumber=10160212

S. Xu, W. Zhang, L. Zhu and C. P. Ho, "Distributed Model Predictive Formation Control with Gait Synchronization for Multiple Quadruped Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 9995-10002, doi: 10.1109/ICRA48891.2023.10161260.Abstract: In this paper, we present a fully distributed framework for multiple quadruped robots in environments with obstacles. Our approach utilizes Model Predictive Control (MPC) and multi-robot consensus protocol to obtain the distributed control law. It ensures that all the robots are able to avoid obstacles, navigate to the desired positions, and meanwhile synchronize the gaits. In particular, via MPC and consensus, the robots compute the optimal trajectory and the contact profile of the legs. Then an MPC-based locomotion controller is implemented to achieve the gait, stabilize the locomotion and track the desired trajectory. We present experiments in simulation and with three real quadruped robots in an environment with a static obstacle. keywords: {Legged locomotion;Simultaneous localization and mapping;Navigation;Robot kinematics;Decentralized control;Formation control;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161260&isnumber=10160212

Q. Wen, Y. Wu and Q. Chen, "Video Waterdrop Removal via Spatio-Temporal Fusion in Driving Scenes," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10003-10009, doi: 10.1109/ICRA48891.2023.10161240.Abstract: The waterdrops on windshields during driving can cause severe visual obstructions, which may lead to car accidents. Meanwhile, the waterdrops can also degrade the performance of a computer vision system in autonomous driving. To address these issues, we propose an attention-based framework that fuses the spatio-temporal representations from multiple frames to restore visual information occluded by waterdrops. Due to the lack of training data for video waterdrop removal, we propose a large-scale synthetic dataset with simulated waterdrops in complex driving scenes on rainy days. To improve the generality of our proposed method, we adopt a cross-modality training strategy that combines synthetic videos and real-world images. Extensive experiments show that our proposed method can generalize well and achieve the best waterdrop removal performance in complex real-world driving scenes. keywords: {Training;Visualization;Computer vision;Fuses;Training data;Image restoration;Automobiles},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161240&isnumber=10160212

Y. Wang, H. Yang, J. Cai, G. Wang, J. Wang and Y. Huang, "Unsupervised Learning of Depth and Pose Based on Monocular Camera and Inertial Measurement Unit (IMU)," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10010-10017, doi: 10.1109/ICRA48891.2023.10160277.Abstract: The main content of the research in this paper is the estimation of depth and pose based on monocular vision and Inertial Measurement Unit (IMU). The usual depth estimation network and pose estimation network require depth ground truth or pose ground truth as a supervised signal for training, while the depth ground truth and pose ground truth are hard to obtain, and monocular vision based depth estimation cannot predict absolute depth. In this paper, with the help of IMU, which is inexpensive and widely used, we can obtain angular velocity and acceleration information. Two new supervision signals are proposed and the calculation expressions are given. Among them, the model trained with acceleration constraint shows a good ability to estimate the absolute depth during the test. It can be considered that the model can estimate the absolute depth. We also derive the method of estimating the scale factor during the test from the acceleration constraint, and also achieve good results as the acceleration constraint does. In addition, this paper also studies the method of using IMU information as pose network input and as selecting conditions. Moreover, it analyzes and discusses the experimental results. At the same time, we also evaluate the effect of the pose estimation of the relevant models. This article starts by reviewing the achievements and deficiencies of the work in this field, combines the use of IMU, puts forward three new methods such as a new loss function, and conducts a test analysis and discussion of relevant indicators on the KITTI data set. keywords: {Training;Measurement units;Automation;Pose estimation;Video sequences;Life estimation;Inertial navigation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160277&isnumber=10160212

W. Wu, G. Wang, J. Zhong, H. Wang and Z. Liu, "Self-supervised Multi-frame Monocular Depth Estimation with Pseudo-LiDAR Pose Enhancement," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10018-10025, doi: 10.1109/ICRA48891.2023.10160391.Abstract: Depth estimation is one of the most important tasks in scene understanding. In the existing joint self-supervised learning approaches of depth-pose estimation, depth estimation and pose estimation networks are independent of each other. They only use the adjacent image frames for pose estimation and lack the use of the estimated geometric information. To enhance the depth-pose association, we propose a monocular multi-frame unsupervised depth estimation framework, named PLPE-Depth. There are a depth estimation network and two pose estimation networks with image input and pseudo-LiDAR input. The main idea of our approach is to use the pseudo-LiDAR reconstructed from the depth map to estimate the pose of adjacent frames. We propose depth re-estimation with a better pose between the image pose and the pseudo-LiDAR pose to improve the accuracy of estimation. Besides, we improve the reconstruction loss and design a pseudo-LiDAR pose enhancement loss to facilitate the joint learning. Our approach enhances the use of the estimated depth information and strengthens the coupling between depth estimation and pose estimation. Experiments on the KITTI dataset show that our depth estimation achieves state-of-the-art performance at low resolution. Our source codes will be released on https://github.com/IRMVLabIPLPE-Depth. keywords: {Couplings;Estimation error;Laser radar;Automation;Source coding;Pose estimation;Estimation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160391&isnumber=10160212

K. Jin, F. Mu, X. Han, G. Wang and Z. Liu, "Anomaly Detection For Robust Autonomous Navigation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10026-10032, doi: 10.1109/ICRA48891.2023.10161507.Abstract: Human drivers are remarkably robust against various unexpected occurring variations and corruptions by understanding temporal changes and traffic scenes. In contrast, the neural network based autonomous navigation system can be easily affected by sensor data anomaly, like occlusion, sensor noise, challenging weather and illumination conditions. Such external disturbances are inevitable in practical driving applications. In this paper, we develop a semi-supervised anomaly detection module to detect the corrupted data while extracting the traffic scenario features. We further introduce an end-to-end robust autonomous navigation framework based on the idea that the consecutive frames of clean data depict a similar traffic scenario and the differences among the sequential data imply the dynamic state changes. By taking into consideration both spatial traffic scenario and temporal environmental variation, the model is able to achieve robust navigation against sensor data corruptions. We conduct experiments in CARLA platform and the evaluation results show the effectiveness of the proposed method. keywords: {Navigation;Neural networks;Lighting;Data visualization;Feature extraction;Robot sensing systems;Data models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161507&isnumber=10160212

J. -S. Park, X. Xiao, G. Warnell, H. Yedidsion and P. Stone, "Learning Perceptual Hallucination for Multi-Robot Navigation in Narrow Hallways," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10033-10039, doi: 10.1109/ICRA48891.2023.10161327.Abstract: While current systems for autonomous robot navigation can produce safe and efficient motion plans in static environments, they usually generate suboptimal behaviors when multiple robots must navigate together in confined spaces. For example, when two robots meet each other in a narrow hallway, they may either turn around to find an alternative route or collide with each other. This paper presents a new approach to navigation that allows two robots to pass each other in a narrow hallway without colliding, stopping, or waiting. Our approach, Perceptual Hallucination for Hallway Passing (PHHP), learns to synthetically generate virtual obstacles (i.e., perceptual hallucination) to facilitate passing in narrow hallways by multiple robots that utilize otherwise standard autonomous navigation systems. Our experiments on physical robots in a variety of hallways show improved performance compared to multiple baselines. keywords: {Automation;Navigation;Behavioral sciences;Standards;Autonomous robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161327&isnumber=10160212

T. Wu, S. Acharya, A. Khalil, A. F. Aljanaideh, M. Al Janaideh and D. Kundur, "Multi-Head Attention Machine Learning for Fault Classification in Mixed Autonomous and Human-Driven Vehicle Platoons," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10040-10046, doi: 10.1109/ICRA48891.2023.10160426.Abstract: Connected Autonomous Vehicle (CAV) platoons have been extensively studied to protect against cyber and physical vulnerabilities. Faults can occur in all layers of the platoon system or could be introduced by impaired human drivers. Since different types of faults may require different fault resolution methods, identifying the fault class facilitates the selection of the best mitigation strategy. This paper introduces a Multi-Head Attention Machine Learning (MHA-ML) approach to classify a set of five different faults and abnormalities in mixed autonomous and human-driven vehicle platoons. Autonomous vehicles can face actuator faults, False Data Injection (FDI) attacks, and Denial-of-Service (DoS) attacks, while abnormalities such as drunk or distracted human drivers could occur. MHA-ML is developed to identify faulty vehicle behavior over long sequences of sensor measurements. MHA-ML is trained on a mixed platoon simulation model and then tested on mobile laboratory robots. The experiment classifies the five fault categories with 90% accuracy and outperforms a baseline recurrent neural network approach. keywords: {Fault diagnosis;Training;Actuators;Recurrent neural networks;Machine learning;Robot sensing systems;Velocity measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160426&isnumber=10160212

M. Ali and L. Liu, "GP-Frontier for Local Mapless Navigation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10047-10053, doi: 10.1109/ICRA48891.2023.10161230.Abstract: We propose a new frontier concept called the Gaussian Process Frontier (GP-Frontier) that can be used to locally navigate a robot towards a goal without building a map. The GP-Frontier is built on the uncertainty assessment of an efficient variant of sparse Gaussian Process. Based only on local ranging sensing measurement, the GP-Frontier can be used for navigation in both known and unknown environments. The proposed method is validated through intensive evaluations, and the results show that the GP-Frontier can navigate the robot in a safe and persistent way, i.e., the robot moves in the most open space (thus reducing the risk of collision) without relying on a map or a path planner. A supplementary video that demonstrates the robot navigation behavior is available at https://youtu.be/ndpqTNYqGfw. keywords: {Uncertainty;Navigation;Buildings;Gaussian processes;Robot sensing systems;Distance measurement;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161230&isnumber=10160212

H. Chawla, K. Jeeveswaran, E. Arani and B. Zonooz, "Image Masking for Robust Self-Supervised Monocular Depth Estimation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10054-10060, doi: 10.1109/ICRA48891.2023.10161373.Abstract: Self-supervised monocular depth estimation is a salient task for 3D scene understanding. Learned jointly with monocular ego-motion estimation, several methods have been proposed to predict accurate pixel-wise depth without using labeled data. Nevertheless, these methods focus on improving performance under ideal conditions without natural or digital corruptions. The general absence of occlusions is assumed even for object-specific depth estimation. These methods are also vulnerable to adversarial attacks, which is a pertinent concern for their reliable deployment in robots and autonomous driving systems. We propose MIMDepth, a method that adapts masked image modeling (MIM) for self-supervised monocular depth estimation. While MIM has been used to learn generalizable features during pre-training, we show how it could be adapted for direct training of monocular depth estimation. Our experiments show that MIMDepth is more robust to noise, blur, weather conditions, digital artifacts, occlusions, as well as untargeted and targeted adversarial attacks. keywords: {Training;Adaptation models;Three-dimensional displays;Estimation;Transformers;Robustness;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161373&isnumber=10160212

H. Lee, J. Kwon and C. Kwon, "Learning-based Uncertainty-aware Navigation in 3D Off-Road Terrains," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10061-10068, doi: 10.1109/ICRA48891.2023.10161543.Abstract: This paper presents a safe, efficient, and agile ground vehicle navigation algorithm for 3D off-road terrain environments. Off-road navigation is subject to uncertain vehicle-terrain interactions caused by different terrain conditions on top of 3D terrain topology. The existing works are limited to adopt overly simplified vehicle-terrain models. The proposed algorithm learns the terrain-induced uncertainties from driving data and encodes the learned uncertainty distribution into the traversability cost for path evaluation. The navigation path is then designed to optimize the uncertainty-aware traversability cost, resulting in a safe and agile vehicle maneuver. Assuring real-time execution, the algorithm is further implemented within parallel computation architecture running on Graphics Processing Units (GPU). keywords: {Solid modeling;Three-dimensional displays;Uncertainty;Costs;Navigation;Graphics processing units;Computer architecture},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161543&isnumber=10160212

S. Pini, C. S. Perone, A. Ahuja, A. S. R. Ferreira, M. Niendorf and S. Zagoruyko, "Safe Real-World Autonomous Driving by Learning to Predict and Plan with a Mixture of Experts," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10069-10075, doi: 10.1109/ICRA48891.2023.10160992.Abstract: The goal of autonomous vehicles is to navigate public roads safely and comfortably. To enforce safety, traditional planning approaches rely on handcrafted rules to generate trajectories. Machine learning-based systems, on the other hand, scale with data and are able to learn more complex behaviors. However, they often ignore that agents and self-driving vehicle trajectory distributions can be leveraged to improve safety. In this paper, we propose modeling a distribution over multiple future trajectories for both the self-driving vehicle and other road agents, using a unified neural network architecture for prediction and planning. During inference, we select the planning trajectory that minimizes a cost taking into account safety and the predicted probabilities. Our approach does not depend on any rule-based planners for trajectory generation or optimization, improves with more training data and is simple to implement. We extensively evaluate our method through a realistic simulator and show that the predicted trajectory distribution corresponds to different driving profiles. We also successfully deploy it on a self-driving vehicle on urban public roads, confirming that it drives safely without compromising comfort. The code for training and testing our model on a public prediction dataset and the video of the road test are available at https://woven.mobi/safepathnet. keywords: {Training;Roads;Training data;Predictive models;Trajectory;Safety;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160992&isnumber=10160212

H. Liu, J. Zhao and L. Zhang, "Interpretable and Flexible Target-Conditioned Neural Planners For Autonomous Vehicles," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10076-10082, doi: 10.1109/ICRA48891.2023.10160913.Abstract: Learning-based approaches to autonomous vehicle planners have the potential to scale to many complicated real-world driving scenarios by leveraging huge amounts of driver demonstrations. However, prior work only learns to estimate a single planning trajectory, while there may be multiple acceptable plans in real-world scenarios. To solve the problem, we propose an interpretable neural planner to regress a heatmap, which effectively represents multiple potential goals in the bird's-eye view for an autonomous vehicle. The planner employs an adaptive Gaussian kernel and relaxed hourglass loss to better capture the uncertainty of planning problems. We also use a negative Gaussian kernel to add supervision to the heatmap regression, enabling the model to learn collision avoidance effectively. Our systematic evaluation on the Lyft Open Dataset across a diverse range of real-world driving scenarios shows that our model achieves a safer and more flexible driving performance than prior works. keywords: {Heating systems;Uncertainty;Systematics;Planning;Trajectory;Kernel;Collision avoidance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160913&isnumber=10160212

J. Muguira-Iturralde, A. Curtis, Y. Du, L. P. Kaelbling and T. Lozano-Pérez, "Visibility-Aware Navigation Among Movable Obstacles," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10083-10089, doi: 10.1109/ICRA48891.2023.10160865.Abstract: In this paper, we examine the problem of visibility-aware robot navigation among movable obstacles (VANAMO). A variant of the well-known NAMO robotic planning problem, VANAMO puts additional visibility constraints on robot motion and object movability. This new problem formulation lifts the restrictive assumption that the map is fully visible and the object positions are fully known. We provide a formal definition of the VANAMO problem and propose the Look and Manipulate Backchaining (LAMB) algorithm for solving such problems. Lamb has a simple vision-based interface that makes it more easily transferable to real-world robot applications and scales to the large 3D environments. To evaluate Lamb, we construct a set of tasks that illustrate the complex interplay between visibility and object movability that can arise in mobile base manipulation problems in unknown environments. We show that Lamb outperforms NAMO and visibility-aware motion planning approaches as well as simple combinations of them on complex manipulation problems with partial observability. keywords: {Robot motion;Three-dimensional displays;Navigation;Heuristic algorithms;Prediction algorithms;Robot localization;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160865&isnumber=10160212

D. Gitardi, S. Sabbadini and A. Valente, "Trajectory error compensation for optimal control of UMA-2 – a climbing robot executing maintenance operation in harsh environment," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10090-10096, doi: 10.1109/ICRA48891.2023.10161025.Abstract: UMA-2 is a wheeled mobile platform equipped with a vacuum adhesion system, eight actuated joints and four passive ones, designed to climb vertical and curved surfaces. The platform can perform maintenance tasks such as corrosion removal and cleaning with grinding while climbing. The quality of the repairing process is largely affected by grinding process parameters including tool forces, toolpath and the robot trajectory accuracy. The current work introduces a trajectory analysis and adaptation model to control the UMA-2 platform to ensure specific surface quality KPIs and incorporating the effects of robot compliancy. The proposed trajectory analysis has been extensively validated through experimental campaigns representative of maintenance in wind power industry. keywords: {Industries;Vacuum systems;Service robots;Optimal control;Error compensation;Maintenance engineering;Wind power generation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161025&isnumber=10160212

J. Gao, F. He, W. Zhang and Y. Yao, "Obstacle-Aware Topological Planning over Polyhedral Representation for Quadrotors," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10097-10103, doi: 10.1109/ICRA48891.2023.10161295.Abstract: In this paper, we propose a novel mapping-planning framework for autonomous quadrotor navigation. First, a polyhedron-based mapping algorithm is presented to fully exploit the information of the onboard sensor data. Polyhedra are generated to approximate the segmented clusters of occupied voxels. Then, customized data structures are designed to extract information for motion planning in real time. With complete knowledge of the shape, position, and number of the observed obstacles, we can conveniently generate smooth trajectories with sufficient obstacle clearance along the most desired direction. Before searching for the initial path, a local topological graph is constructed to keep the path expanding in the most favorable topology class. The following path search is segmented based on the graph vertices, which allows fast convergence. The refined trajectory is obtained after smoothing, and large deviations are penalized in the formulated optimization problem to preserve the original clearance. Finally, we analyze and validate the proposed framework through extensive simulations and real-world quadrotor flights. keywords: {Smoothing methods;Shape;Data structures;Robustness;Real-time systems;Trajectory;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161295&isnumber=10160212

M. Zhang, C. Xu, F. Gao and Y. Cao, "Trajectory Optimization for 3D Shape-Changing Robots with Differential Mobile Base," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10104-10110, doi: 10.1109/ICRA48891.2023.10160911.Abstract: Service robots have attracted extensive attention due to specially designed functions, such as mobile manipulators or robots with extra structures. For robots that have changing shapes, autonomous navigation in the real world presents new challenges. In this paper, we propose a trajectory optimization method for differential-drive mobile robots with controllable changing shapes in dense 3D environments. We model the whole-body trajectory as a polynomial trajectory that satisfies the nonholonomic dynamics of the base and dynamics of the extra joints. These constraints are converted into soft constraints, and an activation function for dense sampling is applied to avoid nonlinear mutations. In addition, we guarantee the safety of full shape by limiting the system's distance from obstacles. To comprehensively simulate a large extent of height and width changes, we designed a novel Shape-Changing Robot with a Differential Base (SCR-DB). Our global trajectory optimization gives a smooth and collision-free trajectory for SCR-DB at a low computational cost. We present vast simulations and real-world experiments to validate our performance, including coupled whole-body and independent differential-driven vehicle motion planning. keywords: {Solid modeling;Three-dimensional displays;Shape;Computational modeling;Manipulators;Planning;Collision avoidance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160911&isnumber=10160212

A. Uchytil and J. Zemánek, "Trajectory Optimization for Distributed Manipulation by Shaping a Physical Field," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10111-10117, doi: 10.1109/ICRA48891.2023.10160720.Abstract: Trajectory optimization is used to solve various planning tasks. In this paper we present a optimization-based method that solves a planning problem for multiple independent objects manipulated by a spatially continuous physical field. The field is generated and controlled (shaped) in real time by an array of actuators. In the paper we first formulate a trajectory optimization problem and a related initialization scheme, and then we demonstrate the proposed method using an experimental platform for distributed magnetic manipulation. The demonstrated task is that of planar reconfiguration of an ensemble of multiple objects, which significantly benefits from the inherent parallelism of the manipulation enabled by the array of actuators shaping the physical field. We show that the system can rearrange up to eight objects simultaneously while avoiding collisions. keywords: {Actuators;Automation;Parallel processing;Real-time systems;Planning;Steel;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160720&isnumber=10160212

O. de Groot, L. Ferranti, D. Gavrila and J. Alonso–Mora, "Globally Guided Trajectory Planning in Dynamic Environments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10118-10124, doi: 10.1109/ICRA48891.2023.10160379.Abstract: Navigating mobile robots through environments shared with humans is challenging. From the perspective of the robot, humans are dynamic obstacles that must be avoided. These obstacles make the collision-free space nonconvex, which leads to two distinct passing behaviors per obstacle (passing left or right). For local planners, such as receding-horizon trajectory optimization, each behavior presents a local optimum in which the planner can get stuck. This may result in slow or unsafe motion even when a better plan exists. In this work, we identify trajectories for multiple locally optimal driving behaviors, by considering their topology. This identification is made consistent over successive iterations by propagating the topology information. The most suitable high-level trajectory guides a local optimization-based planner, resulting in fast and safe motion plans. We validate the proposed planner on a mobile robot in simulation and real-world experiments. keywords: {Trajectory planning;Tracking;Navigation;Computational modeling;Dynamics;Behavioral sciences;Topology},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160379&isnumber=10160212

J. Jankowski, L. Brudermüller, N. Hawes and S. Calinon, "VP-STO: Via-point-based Stochastic Trajectory Optimization for Reactive Robot Behavior," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10125-10131, doi: 10.1109/ICRA48891.2023.10160214.Abstract: Achieving reactive robot behavior in complex dynamic environments is still challenging as it relies on being able to solve trajectory optimization problems quickly enough, such that we can replan the future motion at frequencies which are sufficiently high for the task at hand. We argue that current limitations in Model Predictive Control (MPC) for robot manipulators arise from inefficient, high-dimensional trajectory representations and the negligence of time-optimality in the trajectory optimization process. Therefore, we propose a motion optimization framework that optimizes jointly over space and time, generating smooth and timing-optimal robot trajectories in joint-space. While being task-agnostic, our formulation can incorporate additional task-specific requirements, such as collision avoidance, and yet maintain real-time control rates, demonstrated in simulation and real-world robot experiments on closed-loop manipulation. For additional material, please visit https://sites.google.com/oxfordrobotics.institute/vp-sto. keywords: {Costs;Uncertainty;Stochastic processes;Robustness;Behavioral sciences;Task analysis;Collision avoidance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160214&isnumber=10160212

J. Lee, M. Lee and D. Lee, "Modular and Parallelizable Multibody Physics Simulation via Subsystem-Based ADMM," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10132-10138, doi: 10.1109/ICRA48891.2023.10161052.Abstract: In this paper, we present a new multibody physics simulation framework that utilizes the subsystem-based struc-ture and the Alternating Direction Method of Multiplier (ADMM). The major challenge in simulating complex high degree of freedom systems is a large number of coupled con-straints and large-sized matrices. To address this challenge, we first split the multibody into several subsystems and reformulate the dynamics equation into a subsystem perspective based on the structure of their interconnection. Then we utilize ADMM with our novel subsystem-based variable splitting scheme to solve the equation, which allows parallelizable and modular architecture. The resulting algorithm is fast, scalable, versatile, and converges well while maintaining solution consistency. Sev-eral illustrative examples are implemented with performance evaluation results showing advantages over other state-of-the-art algorithms. keywords: {Performance evaluation;Automation;Heuristic algorithms;Mathematical models;Convex functions;Physics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161052&isnumber=10160212

R. Dempster, M. Al-Sharman, D. Rayside and W. Melek, "Real-Time Unified Trajectory Planning and Optimal Control for Urban Autonomous Driving Under Static and Dynamic Obstacle Constraints," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10139-10145, doi: 10.1109/ICRA48891.2023.10160577.Abstract: Trajectory planning and control have historically been separated into two modules in automated driving stacks. Trajectory planning focuses on higher-level tasks like avoiding obstacles and staying on the road surface, whereas the controller tries its best to follow an ever changing reference trajectory. We argue that this separation is (1) flawed due to the mismatch between planned trajectories and what the controller can feasibly execute, and (2) unnecessary due to the flexibility of the model predictive control (MPC) paradigm. Instead, in this paper, we present a unified MPC-based trajectory planning and control scheme that guarantees feasibility with respect to road boundaries, the static and dynamic environment, and enforces passenger comfort constraints. The scheme is evaluated rigorously in a variety of scenarios focused on proving the effectiveness of the optimal control problem (OCP) design and real-time solution methods. The prototype code will be released at github.com/WATonomous/control. keywords: {Trajectory planning;Roads;Optimal control;Prototypes;Turning;Real-time systems;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160577&isnumber=10160212

D. Yang, Y. Liu and Y. Yu, "A General Locomotion Approach for a Novel Multi-legged Spherical Robot," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10146-10152, doi: 10.1109/ICRA48891.2023.10160881.Abstract: As a kind of ground mobile robot, deformable robots have many advantages, such as solid terrain adaptability, lightweight, and portability. Among these robots, the radial skeleton robot has better stability and controllability. However, because the friction of foot and ground is hard to be predicted, the accuracy of its gait generation algorithms that have been studied is very low. Furthermore, there is currently no closed-loop control scheme for this kind of robot. We designed a 12-legged radial skeleton robot with high extension ratio legs, proposed a high-precision gait generation algorithm for any multi-legged radial skeleton robot, and first proposed a closed-loop control scheme for this kind of robot. A dynamic model considering contact friction is established. And the robot has the advantages of omnidirectional motion, high-precision trajectory tracking, and motion robustness. By conducting prototype experiments, it is verified that our method achieves the highest accuracy when tracking trajectory and holds robustness in the unknown environment. keywords: {Legged locomotion;Trajectory tracking;Friction;Prototypes;Prediction algorithms;Skeleton;Robustness},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160881&isnumber=10160212

M. Yu, K. Lv, C. Wang, M. Tomizuka and X. Li, "A Coarse-to-Fine Framework for Dual-Arm Manipulation of Deformable Linear Objects with Whole-Body Obstacle Avoidance," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10153-10159, doi: 10.1109/ICRA48891.2023.10160264.Abstract: Manipulating deformable linear objects (DLOs) to achieve desired shapes in constrained environments with obstacles is a meaningful but challenging task. Global planning is necessary for such a highly-constrained task; however, accurate models of DLOs required by planners are difficult to obtain owing to their deformable nature, and the inevitable modeling errors significantly affect the planning results, probably resulting in task failure if the robot simply executes the planned path in an open-loop manner. In this paper, we propose a coarse-to-fine framework to combine global planning and local control for dual-arm manipulation of DLOs, capable of precisely achieving desired configurations and avoiding potential collisions between the DLO, robot, and obstacles. Specifically, the global planner refers to a simple yet effective DLO energy model and computes a coarse path to find a feasible solution efficiently; then the local controller follows that path as guidance and further shapes it with closed-loop feedback to compensate for the planning errors and improve the task accuracy. Both simulations and real-world experiments demonstrate that our framework can robustly achieve desired DLO configurations in constrained environments with imprecise DLO models, which may not be reliably achieved by only planning or control. keywords: {Deformable models;Shape;Computational modeling;Reliability engineering;Real-time systems;Planning;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160264&isnumber=10160212

D. Russell, R. Papallas and M. Dogar, "Adaptive approximation of dynamics gradients via interpolation to speed up trajectory optimisation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10160-10166, doi: 10.1109/ICRA48891.2023.10161090.Abstract: Trajectory optimisation methods for robotic motion planning often require the use of first order derivatives of the dynamics of the system with respect to the states and controls of the system. Particularly when multi-contact dynamics are present, these derivatives are often numerically approximated by a method such as finite-differencing. Finite-differencing whilst using an expensive physics simulator is usually the bottleneck in these trajectory optimisation algorithms. Since these dynamics derivatives do not change substantially over certain time inter-vals, we propose that trajectory optimisers can compute the dy-namics derivatives less often and then interpolate approximations to the derivatives in between calculated derivatives, gaining a sig-nificant speed up for overall optimisation time with no observable degradation in the generated behaviour. We investigate different methods of interpolating approximations as well as propose an adaptive method to detect when to compute the derivatives with finite-differencing. We find a speed-up of planning times on average by 60% in a contact-based manipulation task. keywords: {Robot motion;Interpolation;Heuristic algorithms;Dynamics;Optimization methods;Trajectory;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161090&isnumber=10160212

A. Khanal and G. J. Stein, "Learning Augmented, Multi-Robot Long-Horizon Navigation in Partially Mapped Environments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10167-10173, doi: 10.1109/ICRA48891.2023.10161476.Abstract: We present a novel approach for efficient and reliable goal-directed long-horizon navigation for a multi-robot team in a structured, unknown environment by predicting statistics of unknown space. Building on recent work in learning-augmented model based planning under uncertainty, we introduce a high-level state and action abstraction that lets us approximate the challenging Dec-POMDP into a tractable stochastic MDP. Our Multi-Robot Learning over Subgoals Planner (MR-LSP) guides agents towards coordinated exploration of regions more likely to reach the unseen goal. We demonstrate improvement in cost against other multi-robot strategies; in simulated office-like environments, we show that our approach saves 13.29% (2 robot) and 4.6% (3 robot) average cost versus standard non-learned optimistic planning and a learning-informed baseline. keywords: {Costs;Uncertainty;Navigation;Robot kinematics;Buildings;Stochastic processes;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161476&isnumber=10160212

M. Booker and A. Majumdar, "Switching Attention in Time-Varying Environments via Bayesian Inference of Abstractions," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10174-10180, doi: 10.1109/ICRA48891.2023.10161533.Abstract: Motivated by the goal of endowing robots with a means for focusing attention in order to operate reliably in complex, uncertain, and time-varying environments, we consider how a robot can (i) determine which portions of its environment to pay attention to at any given point in time, (ii) infer changes in context (e.g., task or environment dynamics), and (iii) switch its attention accordingly. In this work, we tackle these questions by modeling context switches in a time-varying Markov decision process (MDP) framework. We utilize the theory of bisimulation-based state abstractions in order to synthesize mechanisms for paying attention to context-relevant information. We then present an algorithm based on Bayesian inference for detecting changes in the robot's context (task or environment dynamics) as it operates online, and use this to trigger switches between different abstraction-based attention mechanisms. Our approach is demonstrated on two examples: (i) an illustrative discrete-state tracking problem, and (ii) a continuous-state tracking problem implemented on a quadrupedal hardware platform. These examples demonstrate the ability of our approach to detect context switches online and robustly ignore task-irrelevant distractors by paying attention to context-relevant information. keywords: {Heuristic algorithms;Focusing;Switches;Markov processes;Inference algorithms;Hardware;Bayes methods},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161533&isnumber=10160212

K. Hansel, J. Urain, J. Peters and G. Chalvatzaki, "Hierarchical Policy Blending as Inference for Reactive Robot Control," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10181-10188, doi: 10.1109/ICRA48891.2023.10161374.Abstract: Motion generation in cluttered, dense, and dynamic environments is a central topic in robotics, rendered as a multi-objective decision-making problem. Current approaches trade-off between safety and performance. On the one hand, reactive policies guarantee a fast response to environmental changes at the risk of suboptimal behavior. On the other hand, planning-based motion generation provides feasible trajectories, but the high computational cost may limit the control frequency and, thus, safety. To combine the benefits of reactive policies and planning, we propose a hierarchical motion generation method. Moreover, we employ probabilistic inference methods to formalize the hierarchical model and stochastic optimization. We realize this approach as a weighted product of stochastic, reactive expert policies, where planning is used to adaptively compute the optimal weights over the task horizon. This stochastic optimization avoids local optima and proposes feasible reactive plans that find paths in cluttered and dense environments. Our extensive experimental study in planar navigation and 7DoF manipulation shows that our proposed hierarchical motion generation method outperforms both myopic reactive controllers and online re-planning methods. Additional material available at https://sites.google.com/view/hipbi. keywords: {Adaptation models;Robot control;Stochastic processes;Probabilistic logic;Safety;Planning;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161374&isnumber=10160212

N. A. Urpí, M. Bagatella, O. Hilliges, G. Martius and S. Coros, "Efficient Learning of High Level Plans from Play," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10189-10196, doi: 10.1109/ICRA48891.2023.10161415.Abstract: Real-world robotic manipulation tasks remain an elusive challenge, since they involve both fine-grained environment interaction, as well as the ability to plan for long-horizon goals. Although deep reinforcement learning (RL) methods have shown encouraging results when planning end-to-end in high-dimensional environments, they remain fundamentally limited by poor sample efficiency due to inefficient exploration, and by the complexity of credit assignment over long horizons. In this work, we present Efficient Learning of High-Level Plans from Play (ELF-P), a framework for robotic learning that bridges motion planning and deep RL to achieve long-horizon complex manipulation tasks. We leverage task-agnostic play data to learn a discrete behavioral prior over object-centric primitives, modeling their feasibility given the current context. We then design a high-level goal-conditioned policy which (1) uses primitives as building blocks to scaffold complex long-horizon tasks and (2) leverages the behavioral prior to accelerate learning. We demonstrate that ELF-P has significantly better sample efficiency than relevant baselines over multiple realistic manipulation tasks and learns policies that can be easily transferred to physical hardware. keywords: {Deep learning;Reinforcement learning;Hardware;Data models;Planning;Behavioral sciences;Complexity theory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161415&isnumber=10160212

A. Rao, A. Breitfeld, A. Candela, B. Jensen, D. Wettergreen and H. Choset, "Multi-Objective Ergodic Search for Dynamic Information Maps," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10197-10204, doi: 10.1109/ICRA48891.2023.10160642.Abstract: Robotic explorers are essential tools for gathering information about regions that are inaccessible to humans. For applications like planetary exploration or search and rescue, robots use prior knowledge about the area to guide their search. Ergodic search methods find trajectories that effectively balance exploring unknown regions and exploiting prior information. In many search based problems, the robot must take into account multiple factors such as scientific information gain, risk, and energy, and update its belief about these dynamic objectives as they evolve over time. However, existing ergodic search methods either consider multiple static objectives or consider a single dynamic objective, but not multiple dynamic objectives. We address this gap in existing methods by presenting an algorithm called Dynamic Multi-Objective Ergodic Search (D-MO-ES) that efficiently plans an ergodic trajectory on multiple changing objectives. Our experiments show that our method requires up to nine times less compute time than a naïve approach with comparable coverage of each objective. keywords: {Space vehicles;Heuristic algorithms;Computational modeling;Pareto optimization;Search problems;Data models;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160642&isnumber=10160212

C. Lerch, D. Dong and I. Abraham, "Safety-Critical Ergodic Exploration in Cluttered Environments via Control Barrier Functions," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10205-10211, doi: 10.1109/ICRA48891.2023.10161032.Abstract: In this paper, we address the problem of safe trajectory planning for autonomous search and exploration in constrained, cluttered environments. Guaranteeing safe (collision-free) trajectories is a challenging problem that has garnered significant due to its importance in the successful utilization of robots in search and exploration tasks. This work contributes a method that generates guaranteed safety-critical search trajectories in a cluttered environment. Our approach integrates safety-critical constraints using discrete control barrier functions (DCBFs) with ergodic trajectory optimization to enable safe exploration. Ergodic trajectory optimization plans continuous exploratory trajectories that guarantee complete coverage of a space. We demonstrate through simulated and experimental results on a drone that our approach is able to generate trajectories that enable safe and effective exploration. Furthermore, we show the efficacy of our approach for safe exploration using real-world single- and multi- drone platforms. keywords: {Automation;Trajectory planning;Aerospace electronics;Search problems;Task analysis;Collision avoidance;Trajectory optimization},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161032&isnumber=10160212

R. Scalise, A. Mandalika, B. Hou, S. Choudhury and S. S. Srinivasa, "GuILD: Guided Incremental Local Densification for Accelerated Sampling-based Motion Planning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10212-10218, doi: 10.1109/ICRA48891.2023.10161028.Abstract: Sampling-based motion planners rely on incre-mental densification to discover progressively shorter paths. After computing feasible path $\xi$ between start $x_{s}$ and goal $x_{t}$, the Informed Set (IS) prunes the configuration space $\mathcal{X}$ by conservatively eliminating points that cannot yield shorter paths. Densification via sampling from this Informed Set retains asymptotic optimality of sampling from the entire configuration space. For path length $c(\xi)$ and Euclidean heuristic $h, IS= \{x\vert x\in \mathcal{X},\ h(x_{s},\ x)+h(x,\ x_{t})\leq c(\xi)\}$. Relying on the heuristic can render the IS especially conservative in high dimensions or complex environments. Furthermore, the IS only shrinks when shorter paths are discovered. Thus, the computational effort from each iteration of densification and planning is wasted if it fails to yield a shorter path, despite improving the cost-to-come for vertices in the search tree. Our key insight is that even in such a failure, shorter paths to vertices in the search tree (rather than just the goal) can immediately improve the planner's sampling strategy. Guided Incremental Local Densification (GuILD) leverages this information to sample from Local Subsets of the IS. We show that GuILD significantly outperforms uniform sampling of the Informed Set in simulated $\mathbb{R}^{2}, SE(2)$ environments and manipulation tasks in $\mathbb{R}^{7}$. keywords: {Automation;Search problems;Planning;Task analysis;Convergence},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161028&isnumber=10160212

Y. Cao, T. Hou, Y. Wang, X. Yi and G. Sartoretti, "ARiADNE: A Reinforcement learning approach using Attention-based Deep Networks for Exploration," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10219-10225, doi: 10.1109/ICRA48891.2023.10160565.Abstract: In autonomous robot exploration tasks, a mobile robot needs to actively explore and map an unknown environment as fast as possible. Since the environment is being revealed during exploration, the robot needs to frequently re-plan its path online, as new information is acquired by onboard sensors and used to update its partial map. While state-of-the-art exploration planners are frontier- and sampling-based, encouraged by the recent development in deep reinforcement learning (DRL), we propose ARiADNE, an attention-based neural approach to obtain real-time, non-myopic path planning for autonomous exploration. ARiADNE is able to learn dependencies at multiple spatial scales between areas of the agent's partial map, and implicitly predict potential gains associated with exploring those areas. This allows the agent to sequence movement actions that balance the natural trade-off between exploitation/refinement of the map in known areas and exploration of new areas. We experimentally demonstrate that our method outperforms both learning and non-learning state-of-the-art baselines in terms of average trajectory length to complete exploration in hundreds of simplified 2D indoor scenarios. We further validate our approach in high-fidelity Robot Operating System (ROS) simulations, where we consider a real sensor model and a realistic low-level motion controller, toward deployment on real robots. keywords: {Deep learning;Solid modeling;Three-dimensional displays;Reinforcement learning;Robot sensing systems;Sensor systems;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160565&isnumber=10160212

S. G. Manyam and D. W. Casbeer, "On Shortest Arc-To-Arc Dubins Path," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10226-10232, doi: 10.1109/ICRA48891.2023.10161550.Abstract: For a given set of orbits, the Orbiting Dubins Traveling Salesman Problem (ODTSP) involves finding Dubins tour that is tangential to each orbit at some point. We consider a shortest Arc-to-Arc Dubins (ATAD) path problem that arrives in solving lower bound to the ODTSP. Given an initial and a final arc, the objective of ATAD is to find the shortest Dubins path such that the initial and final point lie on the given two arcs, and the path is tangential to the arcs. We analyze the six Dubins modes and the degenerate cases to find local minima. We present the optimal solution for the ATAD, along with an algorithm that uses this solution to compute tight lower bounds for the ODTSP. We test the lower bounding algorithm on several random instances and report the results. Using this algorithm, we show that the percent gap between upper and lower bounds is less than 10% for most instances. keywords: {Automation;Traveling salesman problems;Orbits},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161550&isnumber=10160212

W. Cai, G. Cheng, L. Kong, L. Dong and C. Sun, "Robust Navigation with Cross-Modal Fusion and Knowledge Transfer," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10233-10239, doi: 10.1109/ICRA48891.2023.10161405.Abstract: Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying working conditions. keywords: {Employee welfare;Training;Navigation;Laser noise;Pose estimation;Real-time systems;Noise measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161405&isnumber=10160212

A. Nickelson, K. Tumer and W. D. Smart, "Contextual Multi-Objective Path Planning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10240-10246, doi: 10.1109/ICRA48891.2023.10160781.Abstract: Many critical robot environments, such as healthcare and security, require robots to account for contextdependent criteria when performing their functions (e.g., navigation). Such domains require decisions that balance multiple factors, making it difficult for robots to make contextually appropriate decisions. Multi-Objective Optimization (MOO) methods offer a potential solution by trading off between objectives; however concepts like Pareto fronts are not only expensive to compute but struggle with differentiating among solutions on the Pareto front. This work introduces the Contextual Multi-Objective Path Planning (CMOPP) algorithm, which enables the robot to trade off different complex costs dependent on context. The key insight of this work is to separate the path planning and path cost estimation into two independent steps, thus significantly reducing computation cost without impacting the quality of the resulting path. As a result, CMOPP is able to accurately model path costs, which provide meaningful trade-offs when choosing a path that best fits the context. We show the benefits of CMOPP on case studies that demonstrate its contextual path planning capabilities. CMOPP finds contextually appropriate paths by first reducing the search space up to 99.9% to a near-optimal set of paths. This reduction enables the generation of accurate path cost models, using up to 90% less computation than similar methods. keywords: {Costs;Navigation;Computational modeling;Estimation;Medical services;Path planning;Security},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160781&isnumber=10160212

P. Rousseas, C. P. Bechlioulis and K. J. Kyriakopoulos, "A Continuous Off-Policy Reinforcement Learning Scheme for Optimal Motion Planning in Simply-Connected Workspaces," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10247-10253, doi: 10.1109/ICRA48891.2023.10161189.Abstract: In this work, an Integral Reinforcement Learning (RL) framework is employed to provide provably safe, convergent and almost globally optimal policies in a novel Off-Policy Iterative method for simply-connected workspaces. This restriction stems from the impossibility of strictly global navigation in multiply connected manifolds, and is necessary for formulating continuous solutions. The current method generalizes and improves upon previous results, where parametrized controllers hindered the method in scope and results. Through enhancing the traditional reactive paradigm with RL, the proposed scheme is demonstrated to outperform both previous reactive methods as well as an RRT* method in path length, cost function values and execution times, indicating almost global optimality. keywords: {Manifolds;Automation;Navigation;Reinforcement learning;Cost function;Planning;Iterative methods},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161189&isnumber=10160212

A. SaLoutos, H. Kim, E. Stanger-Jones, M. Guo and S. Kim, "Towards Robust Autonomous Grasping with Reflexes Using High-Bandwidth Sensing and Actuation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10254-10260, doi: 10.1109/ICRA48891.2023.10160930.Abstract: Modern robotic manipulation systems fall short of human manipulation skills partly because they rely on closing feedback loops exclusively around vision data, which reduces system bandwidth and speed. By developing autonomous grasping reflexes that rely on high-bandwidth force, contact, and proximity data, the overall system speed and robustness can be increased while reducing reliance on vision data. We are developing a new system built around a low-inertia, high-speed arm with nimble fingers that combines a high-level trajectory planner operating at less than 1 Hz with low-level autonomous reflex controllers running upwards of 300 Hz. We characterize the reflex system by comparing the volume of the set of successful grasps for a naive baseline controller and variations of our reflexive grasping controller, finding that our controller expands the set of successful grasps by 55% relative to the baseline. We also deploy our reflexive grasping controller with a simple vision-based planner in an autonomous clutter clearing task, achieving a grasp success rate above 90% while clearing over 100 items. keywords: {Feedback loop;Force;Fingers;Grasping;Robot sensing systems;Robustness;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160930&isnumber=10160212

K. H. Mak, P. Xu and J. Seo, "High-Speed Scooping: An Implementation through Stiffness Control and Direct-Drive Actuation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10261-10267, doi: 10.1109/ICRA48891.2023.10160263.Abstract: This study presents the technique of robotic high-speed scooping: rapidly picking an object lying on a support surface by making contact with the object's open top face and the bottom face that is hidden in contact with the support surface. Essential to high-speed scooping is thus to make suitable dynamic, impactful interaction happen among the robot, object, and environment under errors and uncertainties. We propose a solution to this challenge based on stiffness control, an approach for indirect force control using the robot that is arranged to behave like a desired mechanical system. An implementation of the solution is then presented using a custom-built two-fingered direct-drive gripper. Our experiments verify that high-speed scooping operation is achievable, with the duration of dynamic interaction less than 0.3 s, and effective to various scooping situations featuring objects durable and fragile. keywords: {Uncertainty;Automation;Dynamics;Mechanical systems;Grippers;Force control;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160263&isnumber=10160212

Y. Chen, J. Jiang, R. Lei, Y. Bekiroglu, F. Chen and M. Li, "GraspAda: Deep Grasp Adaptation through Domain Transfer," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10268-10274, doi: 10.1109/ICRA48891.2023.10160213.Abstract: Learning-based methods for robotic grasping have been shown to yield high performance. However, they rely on expensive-to-acquire and well-labeled datasets. In addition, how to generalize the learned grasping ability across different scenarios is still unsolved. In this paper, we present a novel grasp adaptation strategy to transfer the learned grasping ability to new domains based on visual data using a new grasp feature representation. We present a conditional generative model for visual data transformation. By leveraging the deep feature representational capacity from the well-trained grasp synthesis model, our approach utilizes feature-level contrastive representation learning and adopts adversarial learning on output space. This way we bridge the domain gap between the new domain and the training domain while keeping consistency during the adaptation process. Based on transformed input grasp data via the generator, our trained model can generalize to new domains without any fine-tuning. The proposed method is evaluated on benchmark datasets and based on real robot experiments. The results show that our approach leads to high performance in new scenarios. keywords: {Training;Representation learning;Learning systems;Bridges;Adaptation models;Visualization;Grasping},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160213&isnumber=10160212

A. E. H. Martin, A. M. Sundaram, W. Friedl, V. R. Garate and M. A. Roa, "Task-Oriented Stiffness Setting for a Variable Stiffness Hand," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10275-10281, doi: 10.1109/ICRA48891.2023.10161053.Abstract: The integration of variable stiffness actuators (VSA) in robotic systems endows them with intrinsic flexibility and therefore robustness to unknown disturbances. However, this characteristic presents a challenge: choosing the best intrinsic stiffness setting guaranteeing the required force ap-plication capability while keeping the system as adaptable to uncertainties as possible. This paper proposes a method to set the optimal stiffness for a multi-finger VSA hand to perform a desired manipulation task. The task is generically represented as a force (with unknown magnitude) applied along a reference direction. According to the force application's direction and the hand's kinematic state, the fingers assume a certain role to split the collective force application. We employ the endpoint stiffness ellipsoid to analyze the required finger stiffness to fulfill the task. We evaluate the optimized stiffness settings in a door opening application with an iterative adaption of the stiffness behavior to handle the unknown force requirement. The results show a successful collective behavior of the fingers, where the stiffness setting considers a task-oriented force-adaptability trade-off and effective use of independent VSA fingers. keywords: {Uncertainty;Force;Thumb;Kinematics;Robustness;Behavioral sciences;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161053&isnumber=10160212

C. Zhao, C. Jiang, J. Cai, M. Y. Wang, H. Yu and Q. Chen, "Flipbot: Learning Continuous Paper Flipping via Coarse-to-Fine Exteroceptive-Proprioceptive Exploration," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10282-10288, doi: 10.1109/ICRA48891.2023.10160774.Abstract: This paper tackles the task of singulating and grasping paper-like deformable objects. We refer to such tasks as paper-flipping. In contrast to manipulating deformable objects that lack compression strength (such as shirts and ropes), minor variations in the physical properties of the paper-like deformable objects significantly impact the results, making manipulation highly challenging. Here, we present Flipbot, a novel solution for flipping paper-like deformable objects. Flipbot allows the robot to capture object physical properties by integrating exteroceptive and proprioceptive perceptions that are indispensable for manipulating deformable objects. Furthermore, by incorporating a proposed coarse-to-fine exploration process, the system is capable of learning the optimal control parameters for effective paper-flipping through proprioceptive and exteroceptive inputs. We deploy our method on a real-world robot with a soft gripper and learn in a self-supervised manner. The resulting policy demonstrates the effectiveness of Flipbot on paper-flipping tasks with various settings beyond the reach of prior studies, including but not limited to flipping pages throughout a book and emptying paper sheets in a box. The code is available here: https://robotll.github.io/Flipbot/. keywords: {Pneumatic actuators;Propioception;Process control;Optimal control;Grasping;Robustness;Encoding},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160774&isnumber=10160212

D. Kim, J. Yang and D. Yun, "Anthropomorphic robot hand using the principle of sweat and fingerprints of human hands," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10289-10295, doi: 10.1109/ICRA48891.2023.10161390.Abstract: In our daily life, when a small amount of sweat or water forms on a person's hand, we can empirically feel that the friction force of the hand increases, and the objects are gripped well. However, if sweat or water forms heavily, we can feel the friction decrease when holding an object. In this study, we analyzed the degree to which fingerprints and sweat present on a person's hand can affect the friction force between the hand and the gripping object. We fabricated an anthropomorphic robot hand with a fingerprint structure to set up an environment similar to that of the human hand, and performed object-holding and friction-change experiments by changing the amount of sweat to verify that this phenomenon can be applied to a robot hand. Furthermore, we for the first time proposed and developed a variable friction system using fluids and microstructures to solve the difficulty of anthropomorphic robot hand force control. By applying the manufactured variable friction system and performing an active friction control performance test and an object grip test of the robot hand, we validated that the fingerprint and sweat of a human hand can affect the grip of an actual object. keywords: {Fluids;Shape;Friction;Force;Fingerprint recognition;Control systems;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161390&isnumber=10160212

Y. Cai and S. Yuan, "In-Hand Manipulation in Power Grasp: Design of an Adaptive Robot Hand with Active Surfaces," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10296-10302, doi: 10.1109/ICRA48891.2023.10161516.Abstract: This paper describes the development of BACH (Belt-Augmented Compliant Hand), a compliant robotic hand equipped with active surfaces. The hand can securely grasp an object using power grasp and simultaneously manipulate the grasped object. The hand consists of three identical fingers, each with an actuated timing belt wrapped around a Fin Ray based compliant finger backbone. Each finger is mounted on a compliant pivot joint allowing for further adaptability. The combination of compliant mechanisms and active surfaces allows the hand to perform dexterous in-hand manipulation with great robustness. Multiple analyses were conducted to optimize and validate the design of BACH. The hand was experimentally tested for grasping and manipulating objects of various geometries and sizes, and it demonstrated highly robust and efficient in-hand manipulation capabilities. keywords: {Geometry;Manufacturing processes;Automation;Grasping;Belts;Robustness;Timing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161516&isnumber=10160212

I. Nate, Z. Wang and S. Hirai, "Passive robotic gripper using a contact-based locking mechanism," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10303-10309, doi: 10.1109/ICRA48891.2023.10160922.Abstract: Robotic end-effectors have been developed for various applications. Most of them are driven by electric or pneumatic actuator/actuators, which usually make the end-effector bulky and vulnerable due to the external cables and air tubes. In this study, we propose a novel passive robotic gripper with a locking mechanism that does not require any actuators. Locking and unlocking of the gripper fingers are performed through contact with external environment, such as ground, table, and conveyor. To facilitate gripper design, modeling of the deformed finger shape was conducted, and experimental validation was performed. A robotic gripper with eight such passive fingers were fabricated using 3D printer. Experiments were conducted to investigate the grasping capacities in terms of object size and weight. We found that the larger the object, the greater the weight capacity of the gripper, which increased significantly when the object exceeded a certain size. In addition, experiments on grasping various food products were carried out and results suggested that the proposed gripper could grasp objects with complex shapes and soft fragile properties, but damages were caused on very fragile objects due to the rigid structure of the gripper. keywords: {Deformable models;Actuators;Three-dimensional displays;Shape;Computational modeling;Fingers;Grasping},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160922&isnumber=10160212

G. Gao, A. Dwivedi and M. Liarokapis, "The New Dexterity Adaptive Humanlike Robot Hand: Employing a Reconfigurable Palm for Robust Grasping and Dexterous Manipulation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10310-10316, doi: 10.1109/ICRA48891.2023.10161369.Abstract: Robots have predominantly been used in automating tasks in structured industrial environments, however, with the advances in technology they are starting to take part in roles in dynamic everyday life scenarios. As a result, the tasks executed by robotic systems will also grow in sophistication. Grasping and dexterous manipulation are critical aspects that allow humans to execute these sophisticated tasks, enabling them to interact with their environment. As such, emulating the human hand can be advantageous for interacting with a world designed for humans. However, directly replicating the anatomical structure of the hand produces designs that are fully actuated, expensive, and which require sophisticated controls and sensing to operate efficiently. In this paper, we present two different versions of the New Dexterity adaptive, humanlike robot hand that is capable of executing robust caging grasps under a wide range of environmental uncertainties (e.g., object pose uncertainties). One of the versions has a classic, fixed thumb base while the second one incorporates an additional degree of freedom at the thumb base, which enables a translational motion for repositioning the thumb and adjusting the aperture. This design choice enhances the inhand manipulation capabilities of the robot hand, improving also the power grasping capabilities for larger objects. The performances of the proposed robot hand designs are experimentally validated and compared through three different tests: i) grasping experiments involving everyday-life objects, ii) force experiments that evaluate their force exertion capabilities, and iii) in-hand manipulation experiments that demonstrate and compare their dexterity. keywords: {Uncertainty;Service robots;Force;Thumb;Grasping;Apertures;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161369&isnumber=10160212

Y. Song, A. Nazir, D. Lau and Y. Liu, "Picking by Tilting: In-Hand Manipulation for Object Picking using Effector with Curved Form," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10317-10323, doi: 10.1109/ICRA48891.2023.10160404.Abstract: This paper presents a robotic in-hand manipulation technique that can be applied to pick an object too large to grasp in a prehensile manner, by taking advantage of its contact interactions with a curved, passive end-effector, and two flat support surfaces. First, the object is tilted up while being held between the end-effector and the supports. Then, the end-effector is tucked into the gap underneath the object, which is formed by tilting, in order to obtain a grasp against gravity. In this paper, we first examine the mechanics of tilting to understand the different ways in which the object can be initially tilted. We then present a strategy to tilt up the object in a secure manner. Finally, we demonstrate successful picking of objects of various size and geometry using our technique through a set of experiments performed with a custom-made robotic device and a conventional robot arm. Our experiment results show that object picking can be performed reliably with our method using simple hardware and control, and when possible, with appropriate fixture design. keywords: {Performance evaluation;Geometry;Fixtures;Tactile sensors;Reliability engineering;End effectors;Hardware},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160404&isnumber=10160212

S. Patil, T. Tao, T. Hellebrekers, O. Kroemer and F. Z. Temel, "Linear Delta Arrays for Compliant Dexterous Distributed Manipulation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10324-10330, doi: 10.1109/ICRA48891.2023.10160578.Abstract: This paper presents a new type of distributed dexterous manipulator: delta arrays. Our delta array setup consists of 64 linearly-actuated delta robots with 3D-printed compliant linkages. Through the design of the individual delta robots, the modular array structure, and distributed communication and control, we study a wide range of in-plane and out-of-plane manipulations, as well as prehensile manipulations among subsets of neighboring delta robots. We also demonstrate dexterous manipulation capabilities of the delta array using reinforcement learning while leveraging compliance. Our evaluations show that the resulting 192 DoF compliant robot is capable of performing various coordinated distributed manipulations of a variety of objects, including translation, alignment, prehensile squeezing, lifting, and grasping. keywords: {Visualization;Shape;Robot kinematics;Redundancy;Grasping;Reinforcement learning;Manipulators;Multi-Robot Systems;Soft Robot Applications;Dexterous Manipulation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160578&isnumber=10160212

I. H. Taylor, M. Bawa and A. Rodriguez, "A Tactile-enabled Hybrid Rigid-Soft Continuum Manipulator for Forceful Enveloping Grasps via Scale Invariant Design," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10331-10337, doi: 10.1109/ICRA48891.2023.10161121.Abstract: This work presents a novel hybrid rigid-soft continuum manipulator, which integrates high-resolution tactile sensing in a form factor that is forceful, compliant, inherently safe, and easily controllable. We utilize a hybrid approach motivated by scale-invariant principles to fuse the rigid and soft design domains while addressing their respective challenges. We use Euler-Bernoulli beam theory and geometric inference to design and develop a novel variant of folded flexure hinge (FFH) compliant mechanism, the variable area moment of inertia folded flexure hinge (VAFFH), which deforms logarithmically along its length and thus yields first-order scale-invariant grasp behavior. Finally, we characterize the forcefulness of the manipulator and demonstrate its compliance, adaptability, and tactile sensing capabilities in selected tasks. keywords: {Manufacturing processes;Fuses;Grasping;Fasteners;Soft robotics;Manipulators;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161121&isnumber=10160212

W. Zheng, H. Liu, D. Guo and W. Yang, "Adaptive Optimal Electrical Resistance Tomography for Large-Area Tactile Sensing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10338-10344, doi: 10.1109/ICRA48891.2023.10161048.Abstract: It is critical to perceive physical contact for intelligent robots to safely interact in dynamic, unstructured environments. As physical contacts can occur at any location, a well-performing tactile sensing system should be able to deploy a large area on robotic surface. Some researchers have implemented large-area tactile sensors by using sensing arrays, but it is challenging to deploy many sensing elements. Electrical resistance tomography (ERT) has recently been introduced into tactile sensing to overcome some of the limitations with conventional tactile sensing arrays, and good results have been achieved for some robotic applications. However, a particular challenge is that spatial resolution is low. Although various attempts have been made to improve the performance of ERT-based tactile sensors, the intrinsic resolution issue remains unsolved. In this paper, we propose a novel adaptive optimal drive strategy for efficient ERT-based large-area tactile sensing for robotic applications, which can adaptively select the current injection and voltage measurement pattern for optimal tactile stimulus. In particular, regions of tactile contacts are preliminarily detected and localized by a base scanning pattern with only a few measurement data. According to this detected region, the adaptive strategy can select the optimal current injection and voltage measurement pattern to improve the sensing performance by maximizing the current density. To verify the effectiveness of the proposed strategy, the proposed method is comprehensively evaluated by simulation and experiments. The results revealed that the optimal strategy can effectively improve both spatial and temporal resolution. keywords: {Adaptation models;Voltage measurement;Surface resistance;Tactile sensors;Tomography;Robot sensing systems;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161048&isnumber=10160212

K. Liu, Q. Yang, Y. Xie and X. Huang, "Towards Open-Set Material Recognition using Robot Tactile Sensing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10345-10351, doi: 10.1109/ICRA48891.2023.10161108.Abstract: The texture recognition can provide clues for robots to interact with the external environment. The traditional tactile material recognition task is studied under the close-set assumption, which means that all types of materials are included in the training set. However, the open-set materials recognition for robots is of much greater significance because in the real-world applications, there is usually something that doesn't belong to any known class. Up to now, there is no researcher to further the discussion of this problem. To cope with unknown classes, this study proposes the Open set Material Recognition (OpenMR) based on General Convolutional Prototype Learning (GCPL). To handle the open space risk for GCPL caused by the lack of unknown samples in the training stage, we use Generative Adversarial Networks (GAN) to synthesize open-set samples as unknowns. The proposed framework is implemented and tested on two batches of tactile data collected in different exploratory motions on 8 material textures using the electronic skin. Compared with other open-set classifiers, experiments reveal that the proposed framework achieves competitive performance in both known classification and unknown detection. keywords: {Training;Automation;Prototypes;Robot sensing systems;Generative adversarial networks;Skin;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161108&isnumber=10160212

Z. Si, T. C. Yu, K. Morozov, J. McCann and W. Yuan, "RobotSweater: Scalable, Generalizable, and Customizable Machine-Knitted Tactile Skins for Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10352-10358, doi: 10.1109/ICRA48891.2023.10161321.Abstract: Tactile sensing is essential for robots to perceive and react to the environment. However, it remains a challenge to make large-scale and flexible tactile skins on robots. Industrial machine knitting provides solutions to manufacture customiz-able fabrics. Along with functional yarns, it can produce highly customizable circuits that can be made into tactile skins for robots. In this work, we present RobotSweater, a machine-knitted pressure-sensitive tactile skin that can be easily applied on robots. We design and fabricate a parameterized multi-layer tactile skin using off-the-shelf yarns, and characterize our sensor on both a flat testbed and a curved surface to show its robust contact detection, multi-contact localization, and pressure sensing capabilities. The sensor is fabricated using a well-established textile manufacturing process with a programmable industrial knitting machine, which makes it highly customizable and low-cost. The textile nature of the sensor also makes it easily fit curved surfaces of different robots and have a friendly appearance. Using our tactile skins, we conduct closed-loop control with tactile feedback for two applications: (1) human lead-through control of a robot arm, and (2) human-robot interaction with a mobile robot. keywords: {Location awareness;Service robots;Robot sensing systems;Manipulators;Skin;Surface fitting;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161321&isnumber=10160212

C. Lin, Z. Lin, S. Wang and H. Xu, "DTact: A Vision-Based Tactile Sensor that Measures High-Resolution 3D Geometry Directly from Darkness," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10359-10366, doi: 10.1109/ICRA48891.2023.10160796.Abstract: Vision-based tactile sensors that can measure 3D geometry of the contacting objects are crucial for robots to perform dexterous manipulation tasks. However, the existing sensors are usually complicated to fabricate and delicate to extend. In this work, we novelly take advantage of the reflection property of semitransparent elastomer to design a robust, low-cost, and easy-to-fabricate tactile sensor named DTact. DTact measures high-resolution 3D geometry accurately from the darkness shown in the captured tactile images with only a single image for calibration. In contrast to previous sensors, DTact is robust under various illumination conditions. Then, we build prototypes of DTact that have non-planar contact surfaces with minimal extra efforts and costs. Finally, we perform two intelligent robotic tasks including pose estimation and object recognition using DTact, in which DTact shows large potential in applications. keywords: {Geometry;Surface reconstruction;Three-dimensional displays;Pose estimation;Tactile sensors;Lighting;Prototypes},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160796&isnumber=10160212

S. Park, S. -R. Oh and D. Hwang, "MagTac: Magnetic Six-Axis Force/Torque Fingertip Tactile Sensor for Robotic Hand Applications," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10367-10372, doi: 10.1109/ICRA48891.2023.10161042.Abstract: We develop a novel hall-effect-based six-axis force/torque (F/T) tactile sensor integrated into the fingertip of robotic hands. When the robotic hands performs the grasping tasks in an unstructured environment, the visual information plays a main role in sensing the external properties of the objects. However, the various intrinsic properties of the objects such as softness, roughness, mass distribution, and weight cannot be measured properly only with the visual information. To detect the various force information in performing diverse tasks, we aim to implement the six-axis F/T fingertip tactile sensor with hall-effect-based principle. The experimental results demonstrate that the proposed sensor can measure the six-axis F/T with average errors of about 3.3%. In addition, it is observed that the effect of stray field can be shielded by applying a soft magnetic shielding film to the sensor. keywords: {Visualization;Magnetic field measurement;Force measurement;Force;Tactile sensors;Magnetic hysteresis;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161042&isnumber=10160212

W. Fan, M. Yang, Y. Xing, N. F. Lepora and D. Zhang, "Tac-VGNN: A Voronoi Graph Neural Network for Pose-Based Tactile Servoing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10373-10379, doi: 10.1109/ICRA48891.2023.10160288.Abstract: Tactile pose estimation and tactile servoing are fundamental capabilities of robot touch. Reliable and precise pose estimation can be provided by applying deep learning models to high-resolution optical tactile sensors. Given the recent successes of Graph Neural Network (GNN) and the effectiveness of Voronoi features, we developed a Tactile Voronoi Graph Neural Network (Tac-VGNN) to achieve reliable pose-based tactile servoing relying on a biomimetic optical tactile sensor (TacTip). The GNN is well suited to modeling the distribution relationship between shear motions of the tactile markers, while the Voronoi diagram supplements this with area-based tactile features related to contact depth. The experiment results showed that the Tac-VGNN model can help enhance data interpretability during graph generation and model training efficiency significantly than CNN-based methods. It also improved pose estimation accuracy along vertical depth by 28.57% over vanilla GNN without Voronoi features and achieved better performance on the real surface following tasks with smoother robot control trajectories. For more project details, please view our website: https://sites.google.com/view/tac-vgnn/home keywords: {Integrated optics;Biomedical optical imaging;Biological system modeling;Pose estimation;Tactile sensors;Optical computing;Graph neural networks},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160288&isnumber=10160212

L. Fu, H. Huang, L. Berscheid, H. Li, K. Goldberg and S. Chitta, "Safe Self-Supervised Learning in Real of Visuo-Tactile Feedback Policies for Industrial Insertion," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10380-10386, doi: 10.1109/ICRA48891.2023.10160763.Abstract: Industrial insertion tasks are often performed repetitively with parts that are subject to tight tolerances and prone to breakage. Learning an industrial insertion policy in real is challenging as the collision between the parts and the environment can cause slippage or breakage of the part. In this paper, we present a safe self-supervised method to learn a visuo-tactile insertion policy that is robust to grasp pose variations. The method reduces human input and collisions between the part and the receptacle. The method divides the insertion task into two phases. In the first align phase, a tactile-based grasp pose estimation model is learned to align the insertion part with the receptacle. In the second insert phase, a vision-based policy is learned to guide the part into the receptacle. The robot uses force-torque sensing to achieve a safe self-supervised data collection pipeline. Physical experiments on the USB insertion task from the NIST Assembly Taskboard suggest that the resulting policies can achieve 45/45 insertion successes on 45 different initial grasp poses, improving on two baselines: (1) a behavior cloning agent trained on 50 human insertion demonstrations (1/45) and (2) an online RL policy (TD3) trained in real (0/45). keywords: {Pose estimation;Pipelines;Cloning;Self-supervised learning;NIST;Data collection;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160763&isnumber=10160212

C. Zhao, J. Ren, H. Yu and D. Ma, "In-situ Mechanical Calibration for Vision-based Tactile Sensors," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10387-10393, doi: 10.1109/ICRA48891.2023.10161153.Abstract: This paper proposes a novel approach to conduct routine calibration for the changing mechanical parameters over time of a vision-based tactile sensor, without disassembling its overall structure, i.e., in-situ mechanical calibration. Calibration for mechanical parameters, Young's modulus and Poisson's ratio, of a tactile sensor's sensing elastomer, is crucial for its force perception capabilities. However, there are few methods that can retrieve values of these parameters both accurately and conveniently. To address this problem, we propose an in-situ approach to calibrate mechanical parameters other than the verbose traditional evaluation process. This method incorporates the deformation sensing capability of the sensor, the accurate force sensing capability of a force/torque sensor, and most importantly, the deformation-force relation-ship for an indentation with embedded mechanical parameters of the elastomers. We also present the indentation test setup and the complete pipeline to extract Young's modulus and Poisson's ratio from experimental results. We validate the method by comparing the indentation depths simulated through finite element analysis (FEA) using the cali-brated parameters with the indentation depths measured in real experiments. Furthermore, superior contact force distribution can be achieved with the accurate mechanical parameters. The proposed method provides the theoretical basis for accurate, lifelong routine calibration, whether weekly or even daily, which can enhance the applications of tactile sensors in real manipulation scenarios. keywords: {Young's modulus;Force measurement;Deformation;Simulation;Force;Pipelines;Tactile sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161153&isnumber=10160212

C. J. Ford et al., "Tactile-Driven Gentle Grasping for Human-Robot Collaborative Tasks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10394-10400, doi: 10.1109/ICRA48891.2023.10161036.Abstract: This paper presents a control scheme for force sensitive, gentle grasping with a Pisa/IIT anthropomorphic SoftHand equipped with a miniaturised version of the TacTip optical tactile sensor on all five fingertips. The tactile sensors provide high-resolution information about a grasp and how the fingers interact with held objects. We first describe a series of hardware developments for performing asynchronous sensor data acquisition and processing, resulting in a fast control loop sufficient for real-time grasp control. We then develop a novel grasp controller that uses tactile feedback from all five fingertip sensors simultaneously to gently and stably grasp 43 objects of varying geometry and stiffness, which is then applied to a human-to-robot handover task. These developments open the door to more advanced manipulation with underactuated hands via fast reflexive control using high-resolution tactile sensing. keywords: {Integrated optics;Optical feedback;Tactile sensors;Process control;Grasping;Handover;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161036&isnumber=10160212

J. Xu, H. Lin, S. Song and M. Ciocarlie, "TANDEM3D: Active Tactile Exploration for 3D Object Recognition," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10401-10407, doi: 10.1109/ICRA48891.2023.10161091.Abstract: Tactile recognition of 3D objects remains a challenging task. Compared to 2D shapes, the complex geometry of 3D surfaces requires richer tactile signals, more dexterous actions, and more advanced encoding techniques. In this work, we propose TANDEM3D, a method that applies a co-training framework for exploration and decision making to 3D object recognition with tactile signals. Starting with our previous work, which introduced a co-training paradigm for 2D recognition problems, we introduce a number of advances that enable us to scale up to 3D. TANDEM3D is based on a novel encoder that builds 3D object representation from contact positions and normals using PointNet++. Furthermore, by enabling 6DOF movement, TANDEM3D explores and collects discriminative touch information with high efficiency. Our method is trained entirely in simulation and validated with real-world experiments. Compared to state-of-the-art baselines, TANDEM3D achieves higher accuracy and a lower number of actions in recognizing 3D objects and is also shown to be more robust to different types and amounts of sensor noise. keywords: {Geometry;Three-dimensional displays;Shape;Decision making;Fingers;Tactile sensors;Encoding},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161091&isnumber=10160212

A. Wilson, H. Jiang, W. Lian and W. Yuan, "Cable Routing and Assembly using Tactile-driven Motion Primitives," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10408-10414, doi: 10.1109/ICRA48891.2023.10161069.Abstract: Manipulating cables is challenging for robots because of the infinite degrees of freedom of the cables and frequent occlusion by the gripper and the environment. These challenges are further complicated by the dexterous nature of the operations required for cable routing and assembly, such as weaving and inserting, hampering common solutions with vision-only sensing. In this paper, we propose to integrate tactile-guided low-level motion control with high-level vision- based task parsing for a challenging task: cable routing and assembly on a reconfigurable task board. Specifically, we build a library of tactile-guided motion primitives using a fingertip GelSight sensor, where each primitive reliably accomplishes an operation such as cable following and weaving. The overall task is inferred via visual perception given a goal configuration image, and then used to generate the primitive sequence. Experiments demonstrate the effectiveness of individual tactile- guided primitives and the integrated end-to-end solution, sig- nificantly outperforming the method without tactile sensing. Our reconfigurable task setup and proposed baselines provide a benchmark for future research in cable manipulation. keywords: {Robot sensing systems;Routing;Weaving;Libraries;Sensors;Reliability;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161069&isnumber=10160212

O. Gibbons, A. Albini and P. Maiolino, "A Tactile Feedback Insertion Strategy for Peg-in-Hole Tasks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10415-10421, doi: 10.1109/ICRA48891.2023.10160879.Abstract: The Peg-In-Hole (PiH) task performed under un-certain conditions still represents a challenge for autonomous robots. When the peg is not rigidly connected to the robot end-effector, the external forces generated by peg-environment interactions can change the in-hand pose of the peg. This aspect must be taken into account when performing the insertion. This paper deals with this problem and proposes an insertion strategy driven by tactile feedback. In particular, we consider holding the peg using a parallel gripper equipped with tactile sensors, whose measurements are processed to capture in-hand rotations of the peg pose. This information is fed back to the robot controller and used to compensate for changes in the peg orientation and end-point position occurring during the task execution. The approach is validated on a real robot using a two-finger gripper equipped with two capacitive-based tactile sensor arrays hosting 20 tactile elements each. We show that the proposed method achieves an insertion success rate of 38/40 with a 0.1 mm clearance between the peg and hole. keywords: {Atmospheric measurements;Tactile sensors;Particle measurements;End effectors;Sensors;Frequency measurement;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160879&isnumber=10160212

J. Greig, M. E. Giannaccini and E. Chadwick, "Coupled, closed-system fluidic actuators for use in wearable rehabilitation devices," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 10422-10428, doi: 10.1109/ICRA48891.2023.10160422.Abstract: This paper presents a novel closed-system, coupled soft actuator that aims to increase the applied bending moment that can be powered by a single pneumatic pump. The actuator incorporates both positive pressure and vacuum actuators of established design. The purpose of this development is to enable the design of an effective soft robotic wearable device for the re-habilitation of the revolute joints in post-stroke individuals. The design of a test rig to provide consistent, quantitative data on the output of the soft actuators is presented, allowing a comparison of the positive pressure, vacuum and combined (positive and vacuum) actuators. This combination demonstrates the ability to significantly increase the torque output when compared to a single actuator using the same pump for input, potentially reducing the weight of a wearable device. The closed-system, coupled soft actuator system shows opportunity for use in a wide range of applications due to this reduction in pump weight and isolation from environmental conditions. keywords: {Actuators;Torque;Automation;Wearable computers;Pumps;Soft robotics;Bending},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160422&isnumber=10160212

