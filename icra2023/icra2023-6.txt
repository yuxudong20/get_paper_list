L. Zhang, S. Zhang, X. Yang, H. Qiao and Z. Liu, "Unseen Object Instance Segmentation with Fully Test-time RGB-D Embeddings Adaptation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 4945-4952, doi: 10.1109/ICRA48891.2023.10160742.Abstract: Segmenting unseen objects is a crucial ability for the robot since it may encounter new environments during the operation. Recently, a popular solution is leveraging RGB-D features of large-scale synthetic data and directly applying the model to unseen real-world scenarios. However, the domain shift caused by the sim2real gap is inevitable, posing a crucial challenge to the segmentation model. In this paper, we em-phasize the adaptation process across sim2real domains and model it as a learning problem on the BatchNorm param-eters of a simulation-trained model. Specifically, we propose a novel non-parametric entropy objective, which formulates the learning objective for the test-time adaptation in an open-world manner. Then, a cross-modality knowledge distillation objective is further designed to encourage the test-time knowledge transfer for feature enhancement. Our approach can be efficiently implemented with only test images, without requiring annotations or revisiting the large-scale synthetic training data. Besides significant time savings, the proposed method consistently improves segmentation results on the overlap and boundary metrics, achieving state-of-the-art performance on unseen object instance segmentation. keywords: {Training;Adaptation models;Image segmentation;Training data;Entropy;Chronic kidney disease;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160742&isnumber=10160212

M. Sodano, F. Magistri, T. Guadagnino, J. Behley and C. Stachniss, "Robust Double-Encoder Network for RGB-D Panoptic Segmentation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 4953-4959, doi: 10.1109/ICRA48891.2023.10160315.Abstract: Perception is crucial for robots that act in real-world environments, as autonomous systems need to see and understand the world around them to act properly. Panoptic segmentation provides an interpretation of the scene by computing a pixelwise semantic label together with instance IDs. In this paper, we address panoptic segmentation using RGB-D data of indoor scenes. We propose a novel encoder-decoder neural network that processes RGB and depth separately through two encoders. The features of the individual encoders are progressively merged at different resolutions, such that the RGB features are enhanced using complementary depth information. We propose a novel merging approach called ResidualExcite, which reweighs each entry of the feature map according to its importance. With our double-encoder architecture, we are robust to missing cues. In particular, the same model can train and infer on RGB-D, RGB-only, and depth-only input data, without the need to train specialized models. We evaluate our method on publicly available datasets and show that our approach achieves superior results compared to other common approaches for panoptic segmentation. keywords: {Training;Image segmentation;Automation;Autonomous systems;Neural networks;Merging;Semantics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160315&isnumber=10160212

H. Ayoobi, H. Kasaei, M. Cao, R. Verbrugge and B. Verheij, "Explain What You See: Open-Ended Segmentation and Recognition of Occluded 3D Objects," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 4960-4966, doi: 10.1109/ICRA48891.2023.10160927.Abstract: Local-HDP (Local Hierarchical Dirichlet Process) is a hierarchical Bayesian method recently used for open-ended 3D object category recognition. It has been proven to be efficient in real-time robotic applications. However, the method is not robust to a high degree of occlusion. We address this limitation in two steps. First, we propose a novel semantic 3D object-parts segmentation method that has the flexibility of Local-HDP. This method is shown to be suitable for open-ended scenarios where the number of 3D objects or object parts are not fixed and can grow over time. We show that the proposed method has a higher percentage of mean intersection over union, using a smaller number of learning instances. Second, we integrate this technique with a recently introduced argumentation-based online incremental learning method, enabling the model to handle a high degree of occlusion. We show that the resulting model produces explicit explanations for the 3D object category recognition task. keywords: {Training;Learning systems;Solid modeling;Three-dimensional displays;Semantics;Neural networks;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160927&isnumber=10160212

M. Gentner, P. Kumar Murali and M. Kaboli, "GMCR: Graph-based Maximum Consensus Estimation for Point Cloud Registration," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 4967-4974, doi: 10.1109/ICRA48891.2023.10161215.Abstract: Point cloud registration is a fundamental and challenging problem for autonomous robots interacting in unstructured environments for applications such as object pose estimation, simultaneous localization and mapping, robot-sensor calibration, and so on. In global correspondence-based point cloud registration, data association is a highly brittle task and commonly produces high amounts of outliers. Failure to reject outliers can lead to errors propagating to downstream perception tasks. Maximum Consensus (MC) is a widely used technique for robust estimation, which is however known to be NP-hard. Exact methods struggle to scale to realistic problem instances, whereas high outlier rates are challenging for approximate methods. To this end, we propose Graph-based Maximum Consensus Registration (GMCR), which is highly robust to outliers and scales to realistic problem instances. We propose novel consensus functions to map the decoupled MC-objective to the graph domain, wherein we find a tight approximation to the maximum consensus set as the maximum clique. The final pose estimate is given in closed-form. We extensively evaluated our proposed GMCR on a synthetic registration benchmark, robotic object localization task, and additionally on a scan matching benchmark. Our proposed method shows high accuracy and time efficiency compared to other state-of-the-art MC methods and compares favorably to other robust registration methods. keywords: {Point cloud compression;Location awareness;Simultaneous localization and mapping;Pose estimation;Benchmark testing;Robustness;Timing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161215&isnumber=10160212

X. Li et al., "Toward Cooperative 3D Object Reconstruction with Multi-agent," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 4975-4982, doi: 10.1109/ICRA48891.2023.10160714.Abstract: We study the problem of object reconstruction in a multi-agent collaboration scenario. Specifically, we focus on the reconstruction of specific goals through several cooperative agents equipped with vision sensors to achieve higher efficiency than single agents. Our main insight is that a complete 3D object can be split into several local 3D models and assigned to different agents. In addition, we can use the salient characteristics of the collaboration agent itself to help realize the integration of local models. We develop a novel pipeline that first restores local 3D models from the images obtained from different agents, then the relative poses between collaborative agents are estimated by aligning intrinsic features. After that, all local models are integrated using the estimated parameters. Extensive experiments show that our proposed method is capable of accurately reconstructing 3D objects in the real world in a multi-agent collaborative manner. The full reconstruction pipeline is released to the public as an open-source project. keywords: {Point cloud compression;Solid modeling;Image segmentation;Three-dimensional displays;Pipelines;Collaboration;Vision sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160714&isnumber=10160212

D. Shim and H. J. Kim, "SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via Swin Transformer and Densely Cascaded Network," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 4983-4990, doi: 10.1109/ICRA48891.2023.10160657.Abstract: Monocular depth estimation plays a critical role in various computer vision and robotics applications such as localization, mapping, and 3D object detection. Recently, learning-based algorithms achieve huge success in depth estimation by training models with a large amount of data in a supervised manner. However, it is challenging to acquire dense ground truth depth labels for supervised training, and the unsupervised depth estimation using monocular sequences emerges as a promising alternative. Unfortunately, most studies on unsupervised depth estimation explore loss functions or occlusion masks, and there is little change in model architecture in that ConvNet-based encoder-decoder structure becomes a de-facto standard for depth estimation. In this paper, we employ a convolution-free Swin Transformer as an image feature extractor so that the network can capture both local geometric features and global semantic features for depth estimation. Also, we propose a Densely Cascaded Multi-scale Network (DCMNet) that connects every feature map directly with another from different scales via a top-down cascade pathway. This densely cascaded connectivity reinforces the interconnection between decoding layers and produces high-quality multi-scale depth outputs. The experiments on two different datasets, KITTI and Make3D, demonstrate that our proposed method outperforms existing state-of-the-art unsupervised algorithms. keywords: {Training;Location awareness;Three-dimensional displays;Semantics;Estimation;Object detection;Feature extraction},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160657&isnumber=10160212

J. Huang, J. Hao, R. Juan, R. Gomez, K. Nakamura and G. Li, "GAN-Based Interactive Reinforcement Learning from Demonstration and Human Evaluative Feedback," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 4991-4998, doi: 10.1109/ICRA48891.2023.10160939.Abstract: Generative adversarial imitation learning (GAIL) — a general model-free imitation learning method, allows robots to directly learn policies from expert trajectories in large environments. However, GAIL shares the limitation of other imitation learning methods that they can seldom surpass the performance of demonstrations. In this paper, to address the limit of GAIL, we propose GAN-based interactive reinforcement learning (GAIRL) from demonstrations and human evaluative feedback, by combining the advantages of GAIL and interactive reinforcement learning. We test GAIRL in six physics-based control tasks, ranging from simple low-dimensional control tasks — Cart Pole, Mountain Car and Lunar Lander, to difficult high-dimensional tasks — Inverted Double Pendulum, Hopper and HalfCheetah. Our results suggest that, the GAIRL agent can generally surpass the performance of demonstrations in both low-dimensional and high-dimensional tasks and get an optimal or close to optimal policy. keywords: {Learning systems;Space vehicles;Automation;Moon;Reinforcement learning;Distance measurement;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160939&isnumber=10160212

T. Xue, H. Girgin, T. S. Lembono and S. Calinon, "Demonstration-guided Optimal Control for Long-term Non-prehensile Planar Manipulation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 4999-5005, doi: 10.1109/ICRA48891.2023.10161496.Abstract: Long-term non-prehensile planar manipulation is a challenging task for robot planning and feedback control. It is characterized by underactuation, hybrid control, and contact uncertainty. One main difficulty is to determine both the continuous and discrete contact configurations, e.g., contact points and modes, which requires joint logical and geometrical reasoning. To tackle this issue, we propose a demonstration-guided hierarchical optimization framework to achieve offline task and motion planning (TAMP). Our work extends the formulation of the dynamics model of the pusher-slider system to include separation mode with face switching mechanism, and solves a warm-started TAMP problem by exploiting human demonstrations. We show that our approach can cope well with the local minima problems currently present in the state-of-the-art solvers and determine a valid solution to the task. We validate our results in simulation and demonstrate its applicability on a pusher-slider system with a real Franka Emika robot in the presence of external disturbances. Project webpage: https://sites.google.com/view/dg-oc/. keywords: {Uncertainty;Dynamics;Optimal control;Switches;Planning;Feedback control;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161496&isnumber=10160212

M. Alakuijala, G. Dulac-Arnold, J. Mairal, J. Ponce and C. Schmid, "Learning Reward Functions for Robotic Manipulation by Observing Humans," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5006-5012, doi: 10.1109/ICRA48891.2023.10161178.Abstract: Observing a human demonstrator manipulate objects provides a rich, scalable and inexpensive source of data for learning robotic policies. However, transferring skills from human videos to a robotic manipulator poses several challenges, not least a difference in action and observation spaces. In this work, we use unlabeled videos of humans solving a wide range of manipulation tasks to learn a task-agnostic reward function for robotic manipulation policies. Thanks to the diversity of this training data, the learned reward function sufficiently generalizes to image observations from a previously unseen robot embodiment and environment to provide a meaningful prior for directed exploration in reinforcement learning. We propose two methods for scoring states relative to a goal image: through direct temporal regression, and through distances in an embedding space obtained with time-contrastive learning. By conditioning the function on a goal image, we are able to reuse one model across a variety of tasks. Unlike prior work on leveraging human videos to teach robots, our method, Human Offline Learned Distances (HOLD) requires neither a priori data from the robot environment, nor a set of task-specific human demonstrations, nor a predefined notion of correspondence across morphologies, yet it is able to accelerate training of several manipulation tasks on a simulated robot arm compared to using only a sparse reward obtained from task completion. keywords: {Training;Automation;Training data;Morphology;Reinforcement learning;Manipulators;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161178&isnumber=10160212

T. Oba and N. Ukita, "Data-Driven Stochastic Motion Evaluation and Optimization with Image by Spatially-Aligned Temporal Encoding," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5013-5019, doi: 10.1109/ICRA48891.2023.10161262.Abstract: This paper proposes a probabilistic motion prediction method for long motions. The motion is predicted so that it accomplishes a task from the initial state observed in the given image. While our method evaluates the task achievability by the Energy-Based Model (EBM), previous EBMs are not designed for evaluating the consistency between different domains (i.e., image and motion in our method). Our method seamlessly integrates the image and motion data into the image feature domain by spatially-aligned temporal encoding so that features are extracted along the motion trajectory projected onto the image. Furthermore, this paper also proposes a data-driven motion optimization method, Deep Motion Optimizer (DMO), that works with EBM for motion prediction. Different from previous gradient-based optimizers, our self-supervised DMO alleviates the difficulty of hyper-parameter tuning to avoid local minima. The effectiveness of the proposed method is demonstrated with a variety of experiments with similar SOTA methods. keywords: {Image coding;Stochastic processes;Optimization methods;Prediction methods;Feature extraction;Probabilistic logic;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161262&isnumber=10160212

A. Gupta, C. Lynch, B. Kinman, G. Peake, S. Levine and K. Hausman, "Demonstration-Bootstrapped Autonomous Practicing via Multi-Task Reinforcement Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5020-5026, doi: 10.1109/ICRA48891.2023.10161447.Abstract: Reinforcement learning systems have the potential to enable continuous improvement in unstructured environments, leveraging data collected autonomously. However, in practice these systems require significant amounts of instrumentation or human intervention to learn in the real world. In this work, we propose a system for reinforcement learning that leverages multi-task reinforcement learning bootstrapped with prior data to enable continuous autonomous practicing, minimizing the number of resets needed while being able to learn temporally extended behaviors. We show how appropriately provided prior data can help bootstrap both low-level multi-task policies and strategies for sequencing these tasks one after another to enable learning with minimal resets. This mechanism enables our robotic system to practice with minimal human intervention at training time, while being able to solve long horizon tasks at test time. We show the efficacy of the proposed system on a challenging kitchen manipulation task both in simulation and the real world, demonstrating the ability to practice autonomously in order to solve temporally extended problems. keywords: {Training;Sequential analysis;Automation;Instruments;Reinforcement learning;Multitasking;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161447&isnumber=10160212

A. George, A. Bartsch and A. B. Farimani, "Minimizing Human Assistance: Augmenting a Single Demonstration for Deep Reinforcement Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5027-5033, doi: 10.1109/ICRA48891.2023.10161119.Abstract: The use of human demonstrations in reinforcement learning has proven to significantly improve agent performance. However, any requirement for a human to manually ‘teach’ the model is somewhat antithetical to the goals of reinforcement learning. This paper attempts to minimize human involvement in the learning process while retaining the performance advantages by using a single human example collected through a simple-to-use virtual reality simulation to assist with RL training. Our method augments a single demonstration to generate numerous human-like demonstrations that, when combined with Deep Deterministic Policy Gradients and Hindsight Experience Replay (DDPG + HER) significantly improve training time on simple tasks and allows the agent to solve a complex task (block stacking) that DDPG + HER alone cannot solve. The model achieves this significant training advantage using a single human example, requiring less than a minute of human input. Moreover, despite learning from a human example, the agent is not constrained to human-level performance, often learning a policy that is significantly different from the human demonstration. keywords: {Training;Deep learning;Solid modeling;Automation;Stacking;Reinforcement learning;Virtual reality},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161119&isnumber=10160212

A. Straižys, M. Burke and S. Ramamoorthy, "Learning Robotic Cutting from Demonstration: Non-Holonomic DMPs using the Udwadia-Kalaba Method," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5034-5040, doi: 10.1109/ICRA48891.2023.10160917.Abstract: Dynamic Movement Primitives (DMPs) offer great versatility for encoding, generating and adapting complex end-effector trajectories. DMPs are also very well suited to learning manipulation skills from human demonstration. However, the reactive nature of DMPs restricts their applicability for tool use and object manipulation tasks involving non-holonomic constraints, such as scalpel cutting or catheter steering. In this work, we extend the Cartesian space DMP formulation by adding a coupling term that enforces a pre-defined set of non-holonomic constraints. We obtain the closed-form expression for the constraint forcing term using the Udwadia-Kalaba method. This approach offers a clean and practical solution for guaranteed constraint satisfaction at run-time. Further, the proposed analytical form of the constraint forcing term enables efficient trajectory optimization subject to constraints. We demonstrate the usefulness of this approach by showing how we can learn robotic cutting skills from human demonstration. keywords: {Couplings;Closed-form solutions;Real-time systems;End effectors;Encoding;Computational efficiency;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160917&isnumber=10160212

J. Verheggen and K. Baraka, "KRIS: A Novel Device for Kinesthetic Corrective Feedback during Robot Motion," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5041-5047, doi: 10.1109/ICRA48891.2023.10160504.Abstract: This paper presents a novel device that can be used to perform kinesthetic corrective feedback for robotic systems. KRIS (Kinesthetic Robotic Interaction System) is a device that can be mounted on the end-effector of an articulated robot. From here it can be manipulated by a human to give corrective feedback to the robot system during execution and in an intuitive way. The device can provide feedback in six degrees of freedom while giving passive haptic feedback to the user about both the position, rotation, and movement of the robot. We evaluated KRIS in a user study with respect to a baseline based on keyboard feedback in the areas of usability, intuitiveness, accuracy of corrections, and user task load. KRIS outperformed our baseline on the first three metrics and performed similar on task load. We believe that KRIS can enable a wide variety of robots to be taught interactively by non-expert humans in diverse collaborative settings. keywords: {Robot motion;Performance evaluation;Training;Collaboration;Keyboards;Haptic interfaces;Task analysis;Learning from Demonstrations;Physical Human-Robot Interaction;Corrective Feedback;Robot Training Device;Human-Robot Collaboration},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160504&isnumber=10160212

F. Sukkar, V. H. Moreno, T. Vidal-Calleja and J. Deuse, "Guided Learning from Demonstration for Robust Transferability," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5048-5054, doi: 10.1109/ICRA48891.2023.10160291.Abstract: Learning from demonstration (LfD) has the potential to greatly increase the applicability of robotic manipulators in modern industrial applications. Recent progress in LfD methods have put more emphasis in learning robustness than in guiding the demonstration itself in order to improve robustness. The latter is particularly important to consider when the target system reproducing the motion is structurally different to the demonstration system, as some demonstrated motions may not be reproducible. In light of this, this paper introduces a new guided learning from demonstration paradigm where an interactive graphical user interface (GUI) guides the user during demonstration, preventing them from demonstrating non-reproducible motions. The key aspect of our approach is determining the space of reproducible motions based on a motion planning framework which finds regions in the task space where trajectories are guaranteed to be of bounded length. We evaluate our method on two different setups with a six-degree-of-freedom (DOF) UR5 as the target system. First our method is validated using a seven-DOF Sawyer as the demonstration system. Then an extensive user study is carried out where several participants are asked to demonstrate, with and without guidance, a mock weld task using a hand held tool tracked by a VICON system. With guidance users were able to always carry out the task successfully in comparison to only 44% of the time without guidance. keywords: {Target tracking;Service robots;Welding;Manipulators;Robustness;Space exploration;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160291&isnumber=10160212

M. Chang and S. Gupta, "One-shot Visual Imitation via Attributed Waypoints and Demonstration Augmentation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5055-5062, doi: 10.1109/ICRA48891.2023.10160944.Abstract: In this paper, we analyze the behavior of existing techniques and design new solutions for the problem of one-shot visual imitation. In this setting, an agent must solve a novel instance of a novel task given just a single visual demonstration. Our analysis reveals that current methods fall short because of three errors: the DAgger problem arising from purely offline training, last centimeter errors in interacting with objects, and mis-fitting to the task context rather than to the actual task. This motivates the design of our modular approach where we a) separate out task inference (what to do) from task execution (how to do it), and b) develop data augmentation and generation techniques to mitigate mis-fitting. The former allows us to leverage hand-crafted motor primitives for task execution which side-steps the DAgger problem and last centimeter errors, while the latter gets the model to focus on the task rather than the task context. Our model gets 100% and 48% success rates on two recent benchmarks, improving upon the current state-of-the-art by absolute 90% and 20% respectively. keywords: {Training;Visualization;Automation;Benchmark testing;Data augmentation;Behavioral sciences;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160944&isnumber=10160212

I. Gharbi, J. Kuckling, D. G. Ramos and M. Birattari, "Show me What you want: Inverse Reinforcement Learning to Automatically Design Robot Swarms by Demonstration," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5063-5070, doi: 10.1109/ICRA48891.2023.10160947.Abstract: Automatic design is a promising approach to generating control software for robot swarms. So far, automatic design has relied on mission-specific objective functions to specify the desired collective behavior. In this paper, we explore the possibility to specify the desired collective behavior via demonstrations. We develop Demo-Cho, an automatic design method that combines inverse reinforcement learning with automatic modular design of control software for robot swarms. We show that, only on the basis of demonstrations and without the need to be provided with an explicit objective function, Demo-Cho successfully generated control software to perform four missions. We present results obtained in simulation and with physical robots. keywords: {Measurement;Learning systems;Protocols;Automation;Design methodology;Reinforcement learning;Linear programming},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160947&isnumber=10160212

K. Li, D. Chappell and N. Rojas, "Immersive Demonstrations are the Key to Imitation Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5071-5077, doi: 10.1109/ICRA48891.2023.10160560.Abstract: Achieving successful robotic manipulation is an essential step towards robots being widely used in industry and home settings. Recently, many learning-based methods have been proposed to tackle this challenge, with imitation learning showing great promise. However, imperfect demonstrations and a lack of feedback from teleoperation systems may lead to poor or even unsafe results. In this work we explore the effect of demonstrator force feedback on imitation learning, using a feedback glove and a robot arm to render fingertip-level and palm-level forces, respectively. 10 participants recorded 5 demonstrations of a pick-and-place task with 3 grippers, under conditions with no force feedback, fingertip force feedback, and fingertip and palm force feedback. Results show that force feedback significantly reduces demonstrator fingertip and palm forces, leads to a lower variation in demonstrator forces, and recorded trajectories that are quicker to execute. Using behavioral cloning, we find that agents trained to imitate these trajectories mirror these benefits, even though agents have no force data shown to them during training. We conclude that immersive demonstrations, achieved with force feedback, may be the key to unlocking safer, quicker-to-execute dexterous manipulation policies. keywords: {Training;Learning systems;Industries;Service robots;Force feedback;Manipulators;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160560&isnumber=10160212

I. M. Aswin Nahrendra, B. Yu and H. Myung, "DreamWaQ: Learning Robust Quadrupedal Locomotion With Implicit Terrain Imagination via Deep Reinforcement Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5078-5084, doi: 10.1109/ICRA48891.2023.10161144.Abstract: Quadrupedal robots resemble the physical ability of legged animals to walk through unstructured terrains. However, designing a controller for quadrupedal robots poses a significant challenge due to their functional complexity and requires adaptation to various terrains. Recently, deep reinforcement learning, inspired by how legged animals learn to walk from their experiences, has been utilized to synthesize natural quadrupedal locomotion. However, state-of-the-art methods strongly depend on a complex and reliable sensing framework. Furthermore, prior works that rely only on proprioception have shown a limited demonstration for overcoming challenging terrains, especially for a long distance. This work proposes a novel quadrupedal locomotion learning framework that allows quadrupedal robots to walk through challenging terrains, even with limited sensing modalities. The proposed framework was validated in real-world outdoor environments with varying conditions within a single run for a long distance. keywords: {Legged locomotion;Deep learning;Animals;Reinforcement learning;Stairs;Robot sensing systems;Robustness},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161144&isnumber=10160212

S. Gangapurwala, L. Campanaro and I. Havoutis, "Learning Low-Frequency Motion Control for Robust and Dynamic Robot Locomotion," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5085-5091, doi: 10.1109/ICRA48891.2023.10160357.Abstract: Robotic locomotion is often approached with the goal of maximizing robustness and reactivity by increasing motion control frequency. We challenge this intuitive notion by demonstrating robust and dynamic locomotion with a learned motion controller executing at as low as 8 Hz on a real ANYmal C quadruped. The robot is able to robustly and repeatably achieve a high heading velocity of 1.5 ms-1, traverse uneven terrain, and resist unexpected external perturbations. We further present a comparative analysis of deep reinforcement learning (RL) based motion control policies trained and executed at frequencies ranging from 5 Hz to 200 Hz. We show that low-frequency policies are less sensitive to actuation latencies and variations in system dynamics. This is to the extent that a successful sim- to-real transfer can be performed even without any dynamics randomization or actuation modeling. We support this claim through a set of rigorous empirical evaluations. Moreover, to assist reproducibility, we provide the training and deployment code along with an extended analysis at https://ori-drs.github.io/lfmc/. keywords: {Motion planning;Training;System dynamics;Dynamics;Resists;Reinforcement learning;Robustness},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160357&isnumber=10160212

Y. Fuchioka, Z. Xie and M. Van de Panne, "OPT-Mimic: Imitation of Optimized Trajectories for Dynamic Quadruped Behaviors," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5092-5098, doi: 10.1109/ICRA48891.2023.10160562.Abstract: Reinforcement Learning (RL) has seen many recent successes for quadruped robot control. The imitation of reference motions provides a simple and powerful prior for guiding solutions towards desired solutions without the need for meticulous reward design. While much work uses motion capture data or hand-crafted trajectories as the reference motion, relatively little work has explored the use of reference motions coming from model-based trajectory optimization. In this work, we investigate several design considerations that arise with such a framework, as demonstrated through four dynamic behaviours: trot, front hop, 180 backflip, and biped stepping. These are trained in simulation and transferred to a physical Solo 8 quadruped robot without further adaptation. In particular, we explore the space of feed-forward designs afforded by the trajectory optimizer to understand its impact on RL learning efficiency and sim - to- real transfer. These findings contribute to the long standing goal of producing robot controllers that combine the interpretability and precision of model-based optimization with the robustness that model-free RL- based controllers offer. keywords: {Training;Adaptation models;Analytical models;Tracking;Dynamics;Robot control;Robustness},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160562&isnumber=10160212

M. Seo, R. Gupta, Y. Zhu, A. Skoutnev, L. Sentis and Y. Zhu, "Learning to Walk by Steering: Perceptive Quadrupedal Locomotion in Dynamic Environments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5099-5105, doi: 10.1109/ICRA48891.2023.10161302.Abstract: We tackle the problem of perceptive locomotion in dynamic environments. In this problem, a quadrupedal robot must exhibit robust and agile walking behaviors in response to environmental clutter and moving obstacles. We present a hierarchical learning framework, named PRELUDE, which decomposes the problem of perceptive locomotion into high-level decision-making to predict navigation commands and low-level gait generation to realize the target commands. In this framework, we train the high-level navigation controller with imitation learning on human demonstrations collected on a steerable cart and the low-level gait controller with reinforcement learning (RL). Therefore, our method can acquire complex navigation behaviors from human supervision and discover versatile gaits from trial and error. We demonstrate the effectiveness of our approach in simulation and with hardware experiments. Videos and code can be found at the project page: https://ut-austin-rpl.github.io/PRELUDE. keywords: {Legged locomotion;Deep learning;Navigation;Decision making;Reinforcement learning;Hardware;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161302&isnumber=10160212

X. Cheng, A. Kumar and D. Pathak, "Legs as Manipulator: Pushing Quadrupedal Agility Beyond Locomotion," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5106-5112, doi: 10.1109/ICRA48891.2023.10161470.Abstract: Locomotion has seen dramatic progress for walking or running across challenging terrains. However, robotic quadrupeds are still far behind their biological counterparts, such as dogs, which display a variety of agile skills and can use the legs beyond locomotion to perform several basic manipulation tasks like interacting with objects and climbing. In this paper, we take a step towards bridging this gap by training quadruped robots not only to walk but also to use the front legs to climb walls, press buttons, and perform object interaction in the real world. To handle this challenging optimization, we decouple the skill learning broadly into locomotion, which involves anything that involves movement whether via walking or climbing a wall, and manipulation, which involves using one leg to interact while balancing on the other three legs. These skills are trained in simulation using curriculum and transferred to the real world using our proposed sim2real variant that builds upon recent locomotion success. Finally, we combine these skills into a robust long-term plan by learning a behavior tree that encodes a high-level task hierarchy from one clean expert demonstration. We evaluate our method in both simulation and real-world showing successful executions of both short as well as long-range tasks and how robustness helps confront external perturbations. Videos at https://robot-skills.github.io/. keywords: {Legged locomotion;Training;Presses;Perturbation methods;Pressing;Robustness;Quadrupedal robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161470&isnumber=10160212

A. Shirwatkar et al., "Force control for Robust Quadruped Locomotion: A Linear Policy Approach," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5113-5119, doi: 10.1109/ICRA48891.2023.10161080.Abstract: This work presents a simple linear policy for direct force control for quadrupedal robot locomotion. The motivation is that force control is essential for highly dynamic and agile motions. We learn a linear policy to generate end-foot trajectory parameters and a centroidal wrench, which is then distributed among the legs based on the foot contact information using a quadratic program (QP) to get the desired ground reaction forces. Unlike the majority of the existing works that use complex nonlinear function approximators to represent the RL policy or model predictive control (MPC) methods with many optimization variables in the order of hundred, our controller uses a simple linear function approximator to represent policy along with only a twelve variable QP for the force distribution. A centroidal dynamics-based MPC method is used to generate reference trajectory data, and then the linear policy is trained using imitation learning to minimize the deviations from the reference trajectory. We demonstrate this compute-efficient controller on our robot Stoch3 in simulation and real-world experiments on indoor and outdoor terrains with push recovery. keywords: {Legged locomotion;Training;Force;Hardware;Trajectory;Quadrupedal robots;Force control;Quadruped Robots;Reinforcement Learning;Model Predictive Control (MPC);Linear policy},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161080&isnumber=10160212

E. Vollenweider, M. Bjelonic, V. Klemm, N. Rudin, J. Lee and M. Hutter, "Advanced Skills through Multiple Adversarial Motion Priors in Reinforcement Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5120-5126, doi: 10.1109/ICRA48891.2023.10160751.Abstract: Reinforcement learning (RL) has emerged as a powerful approach for locomotion control of highly articulated robotic systems. However, one major challenge is the tedious process of tuning the reward function to achieve the desired motion style. To address this issue, imitation learning approaches such as adversarial motion priors have been proposed, which encourage a pre-defined motion style. In this work, we present an approach to enhance the concept of adversarial motion prior-based RL, allowing for multiple, discretely switchable motion styles. Our approach demonstrates that multiple styles and skills can be learned simultaneously without significant performance differences, even in combination with motion data-free skills. We conducted several real-world experiments using a wheeled-legged robot to validate our approach. The experiments involved learning skills from existing RL controllers and trajectory optimization, such as ducking and walking, as well as novel skills, such as switching between a quadrupedal and humanoid configuration. For the latter skill, the robot was required to stand up, navigate on two wheels, and sit down. Instead of manually tuning the sit-down motion, we found that a reverse playback of the stand-up movement helped the robot discover feasible sit-down behaviors and avoided the need for tedious reward function tuning. keywords: {Legged locomotion;Training;Navigation;Wheels;Switches;Reinforcement learning;Quadrupedal robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160751&isnumber=10160212

J. K. Mehr, E. Guo, M. Akbari, V. K. Mushahwar and M. Tavakoli, "Deep Reinforcement Learning based Personalized Locomotion Planning for Lower-Limb Exoskeletons," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5127-5133, doi: 10.1109/ICRA48891.2023.10161559.Abstract: This paper introduces intelligent central pattern generators (iCPGs) that can plan personalized walking trajectories for lower-limb exoskeletons. This can make walking more comfortable for the users by resolving one of the significant shortcomings of most commercially available exoskeletons, which is the use of pre-defined fixed trajectories for all users. The proposed method combines reinforcement learning (RL) with previously introduced adaptable central pattern generators (ACPGs) to learn a user's physical interaction behaviour and refine the exoskeleton's walking trajectories. The ACPG method embeds physical human-robot interaction (pHRI) in CPGs to make changing gait trajectories in real-time, possible. However, to effectively refine gait trajectories based on pHRIs, the parameters must be precisely identified and updated as a user interacts with the exoskeleton. Our proposed method uses RL to modify (amplify/attenuate) the pHRI energy based on a user's interaction behaviour, and form an effective energy value which can facilitate reaching desired gait pattern for users via iCPG dynamics. The proposed method can resolve the aforementioned challenges with ACPGs and personalized trajectory generation. The simulation and experimental results provide evidence that the proposed method can effectively adapt to the user's behaviour in different walking scenarios with the Indego lower-limb exoskeleton. keywords: {Legged locomotion;Parameter estimation;Simulation;Exoskeletons;Human-robot interaction;Reinforcement learning;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161559&isnumber=10160212

G. Christmann, Y. -S. Luo, J. H. Soeseno and W. -C. Chen, "Expanding Versatility of Agile Locomotion through Policy Transitions Using Latent State Representation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5134-5140, doi: 10.1109/ICRA48891.2023.10160776.Abstract: This paper proposes the transition-net, a robust transition strategy that expands the versatility of robot locomotion in the real-world setting. To this end, we start by distributing the complexity of different gaits into dedicated locomotion policies applicable to real-world robots. Next, we expand the versatility of the robot by unifying the policies with robust transitions into a single coherent meta-controller by examining the latent state representations. Our approach enables the robot to iteratively expand its skill repertoire and robustly transition between any policy pair in a library. In our framework, adding new skills does not introduce any process that alters the previously learned skills. Moreover, training of a locomotion policy takes less than an hour with a single consumer GPU. Our approach is effective in the real-world and achieves a 19% higher average success rate for the most challenging transition pairs in our experiments compared to existing approaches. keywords: {Training;Legged locomotion;Switches;Libraries;Complexity theory;Trajectory;Iterative methods},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160776&isnumber=10160212

H. Lai et al., "Sim-to-Real Transfer for Quadrupedal Locomotion via Terrain Transformer," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5141-5147, doi: 10.1109/ICRA48891.2023.10160497.Abstract: Deep reinforcement learning has recently emerged as an appealing alternative for legged locomotion over multiple terrains by training a policy in physical simulation and then transferring it to the real world (i.e., sim-to-real transfer). Despite considerable progress, the capacity and scalability of traditional neural networks are still limited, which may hinder their applications in more complex environments. In contrast, the Transformer architecture has shown its superiority in a wide range of large-scale sequence modeling tasks, including natural language processing and decision-making problems. In this paper, we propose Terrain Transformer (TERT), a high-capacity Transformer model for quadrupedal locomotion control on various terrains. Furthermore, to better leverage Transformer in sim-to-real scenarios, we present a novel two-stage training framework consisting of an offline pretraining stage and an online correction stage, which can naturally integrate Transformer with privileged training. Extensive experiments in simulation demonstrate that TERT outperforms state-of-the-art baselines on different terrains in terms of return, energy consumption and control smoothness. In further real-world validation, TERT successfully traverses nine challenging terrains, including sand pit and stair down, which can not be accomplished by strong baselines. keywords: {Training;Scalability;Robot vision systems;Robot control;Neural networks;Reinforcement learning;Stairs},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160497&isnumber=10160212

M. Carroll, Z. Liu, M. Kasaei and Z. Li, "Agile and Versatile Robot Locomotion via Kernel-based Residual Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5148-5154, doi: 10.1109/ICRA48891.2023.10160704.Abstract: This work developed a kernel-based residual learning framework for quadrupedal robotic locomotion. Ini-tially, a kernel neural network is trained with data collected from an MPC controller. Alongside a frozen kernel network, a residual controller network is trained using reinforcement learning to acquire generalized locomotion skills and robust-ness against external perturbations. The proposed framework successfully learns a robust quadrupedal locomotion controller with high sample efficiency and controllability, which can provide omnidirectional locomotion at continuous velocities. We validated its versatility and robustness on unseen terrains that the expert MPC controller failed to traverse. Furthermore, the learned kernel can produce a range of functional locomotion behaviors and can generalize to unseen gaits. keywords: {Legged locomotion;Navigation;Perturbation methods;Reinforcement learning;Controllability;Robustness;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160704&isnumber=10160212

Y. Ji, G. B. Margolis and P. Agrawal, "DribbleBot: Dynamic Legged Manipulation in the Wild," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5155-5162, doi: 10.1109/ICRA48891.2023.10160325.Abstract: DribbleBot (Dexterous Ball Manipulation with a Legged Robot) is a legged robotic system that can dribble a soccer ball under the same real-world conditions as humans. We identify key challenges of in-the-wild soccer ball manipulation, including variable ball motion dynamics and perception using body-mounted cameras. To overcome these challenges, we propose a domain and task specification for learning viable soccer dribbling behaviors in simulation that transfer to real fields. Our system provides promising evidence that current legged robots are physically capable and adequately sensorized for varied and dynamic real-world soccer play. Video is available at https://gmargoll.github.io/dribblebot. keywords: {Legged locomotion;Dynamics;Robot vision systems;Cameras;Trajectory;Behavioral sciences;Quadrupedal robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160325&isnumber=10160212

J. Yang, M. Gong, G. Nair, J. H. Lee, J. Monty and Y. Pu, "Knowledge Distillation for Feature Extraction in Underwater VSLAM," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5163-5169, doi: 10.1109/ICRA48891.2023.10161047.Abstract: In recent years, learning-based feature detection and matching have outperformed manually-designed methods in in-air cases. However, it is challenging to learn the features in the underwater scenario due to the absence of annotated underwater datasets. This paper proposes a cross-modal knowl-edge distillation framework for training an underwater feature detection and matching network (UFEN). In particular, we use in-air RGBD data to generate synthetic underwater images based on a physical underwater imaging formation model and employ these as the medium to distil knowledge from a teacher model SuperPoint pretrained on in-air images. We embed UFEN into the ORB-SLAM3 framework to replace the ORB feature by introducing an additional binarization layer. To test the effectiveness of our method, we built a new underwater dataset with groundtruth measurements named EASI (https://github.com/Jinghe-mel/UFEN-SLAM), recorded in an indoor water tank for different turbidity levels. The experimental results on the existing dataset and our new dataset demonstrate the effectiveness of our method. keywords: {Training;Automation;Feature detection;Imaging;Manuals;Feature extraction;Data models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161047&isnumber=10160212

X. Lin, N. J. Sanket, N. Karapetyan and Y. Aloimonos, "OysterNet: Enhanced Oyster Detection Using Simulation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5170-5176, doi: 10.1109/ICRA48891.2023.10160830.Abstract: Oysters play a pivotal role in the bay living ecosystem and are considered the living filters for the ocean. In recent years, oyster reefs have undergone major devastation caused by commercial over-harvesting, requiring preservation to maintain ecological balance. The foundation of this preservation is to estimate the oyster density which requires accurate oyster detection. However, systems for accurate oyster detection require large datasets obtaining which is an expensive and labor-intensive task in underwater environments. To this end, we present a novel method to mathematically model oysters and render images of oysters in simulation to boost the detection performance with minimal real data. Utilizing our synthetic data along with real data for oyster detection, we obtain up to 35.1 % boost in performance as compared to using only real data with our OysterNet network. We also improve the state-of-the-art by 12.7%. This shows that using underlying geometrical properties of objects can help to enhance recognition task accuracy on limited datasets successfully and we hope more researchers adopt such a strategy for hard-to-obtain datasets. keywords: {Automation;Biological system modeling;Oceans;Ecosystems;Mathematical models;Data models;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160830&isnumber=10160212

J. Wen et al., "SyreaNet: A Physically Guided Underwater Image Enhancement Framework Integrating Synthetic and Real Images," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5177-5183, doi: 10.1109/ICRA48891.2023.10161531.Abstract: Underwater image enhancement (UIE) is vital for high-level vision-related underwater tasks. Although learning-based UIE methods have made remarkable achievements in recent years, it's still challenging for them to consistently deal with various underwater conditions, which could be caused by: 1) the use of the simplified atmospheric image formation model in UIE may result in severe errors; 2) the network trained solely with synthetic images might have difficulty in generalizing well to real underwater images. In this work, we, for the first time, propose a framework SyreaNet for UIE that integrates both synthetic and real data under the guidance of the revised underwater image formation model and novel domain adaptation (DA) strategies. First, an underwater image synthesis module based on the revised model is proposed. Then, a physically guided disentangled network is designed to predict the clear images by combining both synthetic and real underwater images. The intra- and inter-domain gaps are abridged by fully exchanging the domain knowledge. Extensive experiments demonstrate the superiority of our framework over other state-of-the-art (SOTA) learning-based UIE methods qualitatively and quantitatively. The code and dataset are publicly available at https://github.com/RockWenJJ/SyreaNet.git. keywords: {Adaptation models;Codes;Automation;Image color analysis;Image synthesis;Atmospheric modeling;Data models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161531&isnumber=10160212

W. Wang et al., "Real-Time Dense 3D Mapping of Underwater Environments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5184-5191, doi: 10.1109/ICRA48891.2023.10160266.Abstract: This paper addresses real-time dense 3D reconstruction for a resource-constrained Autonomous Underwater Vehicle (AUV). Underwater vision-guided operations are among the most challenging as they combine 3D motion in the presence of external forces, limited visibility, and absence of global positioning. Obstacle avoidance and effective path planning require online dense reconstructions of the environment. Autonomous operation is central to environmental monitoring, marine archaeology, resource utilization, and underwater cave exploration. To address this problem, we propose to use SVIn2, a robust VIO method, together with a real-time 3D reconstruction pipeline. We provide extensive evaluation on four challenging underwater datasets. Our pipeline produces comparable reconstruction with that of COLMAP, the state-of-the-art offline 3D reconstruction method, at high frame rates on a single CPU. keywords: {Underwater structures;Autonomous underwater vehicles;Three-dimensional displays;Navigation;Pipelines;Real-time systems;Path planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160266&isnumber=10160212

B. Joshi, H. Damron, S. Rahman and I. Rekleitis, "SM/VIO: Robust Underwater State Estimation Switching Between Model-based and Visual Inertial Odometry," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5192-5199, doi: 10.1109/ICRA48891.2023.10161407.Abstract: This paper addresses the robustness problem of visual-inertial state estimation for underwater operations. Underwater robots operating in a challenging environment are required to know their pose at all times. All vision-based localization schemes are prone to failure due to poor visibility conditions, color loss, and lack of features. The proposed approach utilizes a model of the robot's kinematics together with proprioceptive sensors to maintain the pose estimate during visual-inertial odometry (VIO) failures. Furthermore, the trajectories from successful VIO and the ones from the model-driven odometry are integrated in a coherent set that maintains a consistent pose at all times. Health-monitoring tracks the VIO process ensuring timely switches between the two estimators. Finally, loop closure is implemented on the overall trajectory. The resulting framework is a robust estimator switching between model-based and visual-inertial odometry (SM/VIO). Experimental results from numerous deployments of the Aqua2 vehicle demonstrate the robustness of our approach over coral reefs and a shipwreck. keywords: {Location awareness;Underwater structures;Visualization;Switches;Feature extraction;Robustness;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161407&isnumber=10160212

K. Yao et al., "Image-Based Visual Servoing Switchable Leader-follower Control of Heterogeneous Multi-agent Underwater Robot System," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5200-5206, doi: 10.1109/ICRA48891.2023.10160853.Abstract: Confined and cluttered aquatic environments present a number of significant challenges with respect to inspection by robotic platforms, including localisation and communications. Some of these can be mitigated by using collaborative heterogeneous multi-robot teams. An important element of such a system is collaborative control. This paper addresses this challenge by presenting an Image-Based Visual Servoing (IBVS), leader-follower control system for heterogeneous aquatic robots. Experiments were conducted in an uncluttered pond to demonstrate the capabilities of the system. The results show robots can maintain tracking each other with maximum $x$ and $y$ displacements of 0.42 m and 0.41 m, the maximum projection distance in the xy-plane of maintaining formation is 0.45 m, showing the stability and feasibility of deploying such system on underwater platforms. keywords: {Autonomous underwater vehicles;Automation;Aquatic robots;Collaboration;Switches;Inspection;Control systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160853&isnumber=10160212

S. Lensgraf, D. Balkcom and A. Q. Li, "Buoyancy enabled autonomous underwater construction with cement blocks," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5207-5213, doi: 10.1109/ICRA48891.2023.10160589.Abstract: We present the first free-floating autonomous underwater construction system capable of using active bal-lasting to transport cement building blocks efficiently. It is the first free-floating autonomous construction robot to use a paired set of resources: compressed air for buoyancy and a battery for thrusters. In construction trials, our system built structures of up to 12 components and weighing up to 100 Kg (75 Kg in water). Our system achieves this performance by combining a novel one-degree-of-freedom manipulator, a novel two-component cement block construction system that corrects errors in placement, and a simple active ballasting system combined with compliant placement and grasp behaviors. The passive error correcting components of the system minimize the required complexity in sensing and control. We also explore the problem of buoyancy allocation for building structures at scale by defining a convex program which allocates buoyancy to minimize the predicted energy cost for transporting blocks. keywords: {Electronic ballasts;Costs;Buildings;Buoyancy;Robot sensing systems;Manipulators;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160589&isnumber=10160212

T. M. C. Sears, M. R. Cooper and J. A. Marshall, "Mapping Waves with an Uncrewed Surface Vessel via Gaussian Process Regression," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5214-5220, doi: 10.1109/ICRA48891.2023.10160568.Abstract: Mobile robots are well suited for environmental surveys because they can travel to any area of interest and react to observations without the need for pre-existing infrastructure or significant setup time. However, vehicle motion constraints limit where and when measurements occur. This is challenging for a single vehicle observing a time-varying phenomenon, such as coastal waves, but the ability to generate a spatiotemporal map would have immediate scientific and engineering applications. In this paper, an uncrewed surface vessel (USV) was used to measure waves on the coast of Lake Ontario, Canada. Data were collected from a low-cost inertial measurement system onboard the USV and processed in an offline Gaussian process regression (GPR) workflow to create a spatiotemporal wave model. Frequency analysis of raw sensor data was used to best select and design kernel functions, and to initialize hyperparameters. The relative speed of the waves limited the ability to make complete wave reconstructions, but GPR captured the dominant periodic components of the waves despite irregularities in the signals. After optimization, the hyperparameters indicate a dominant signal with a wave period of 0.87 $\mathbf{s}$, which concurs with ground truth estimates. keywords: {Surface waves;Sea measurements;Gaussian processes;Robot sensing systems;Spatiotemporal phenomena;Velocity measurement;Motion measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160568&isnumber=10160212

L. Koutras, K. Vlachos, G. S. Kanakis, F. Dimeas, Z. Doulgeri and G. A. Rovithakis, "Enforcing Constraints for Dynamic Obstacle Avoidance by Compliant Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5221-5227, doi: 10.1109/ICRA48891.2023.10160360.Abstract: In this work a control scheme is proposed to enforce dynamic obstacle avoidance constraints to the full body of actively compliant robots. We argue that both compliance and accuracy are necessary to build safe collaborative robotic systems; obstacle avoidance is usually not enough, due to the reliance on perception systems which exhibit delays and errors. Our scheme is able to successfully avoid obstacles, while remaining compliant in the entirety of the executed task. Therefore, in case of unexpected collisions due to perception system errors, the robot remains safe for humans and its environment. Our approach is validated through experiments with simulated and real obstacles utilizing a 7-dof KUKA LBR iiwa robotic manipulator. keywords: {Service robots;Dynamics;Redundancy;End effectors;Trajectory;Safety;Collision avoidance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160360&isnumber=10160212

K. Samuel, K. Haninger and S. Oh, "Increasing Admittance of Industrial Robots By Velocity Feedback Inner-Loop Shaping," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5228-5234, doi: 10.1109/ICRA48891.2023.10161035.Abstract: Admittance and impedance controllers are often purely feedforward, using measured external force or motion, respectively, to generate a reference for an inner-loop controller. In this case, the range of dynamics which can be rendered is limited by the inner-loop, which causes, e.g. contact stability issues for low admittance industrial robots in stiff contact. When both position and force are measured, feedback control can be added to more flexibly reshape the rendered dynamics. This paper uses velocity feedback to increase the admittance of motion-controlled industrial robots in force control applications. This allows an industrial robot with a lower intrinsic admittance, which may be needed for payload, speed, or accuracy, to realize a higher admittance by control, allowing lighter manual guidance and safer contact. This is achieved by a modified disturbance observer, where an inverse dynamic model estimates external forces and amplifies them with positive feedback. This approach is compared with using positive velocity feedback with a shaping filter. Here, velocity reference calculated by the virtual admittance model is modified by the DOB (Dist-Add) or the positive velocity feedback (Vel-Add). When combined with an outer-loop admittance controller, these methods can render a higher admittance while maintaining contact stability compared to standard feedforward admittance control. keywords: {Force measurement;Force;Dynamics;Industrial robots;Stability analysis;Disturbance observers;Steady-state},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161035&isnumber=10160212

D. Ko, D. Lee, W. K. Chung and K. Kim, "Bounded Compensation with Friction Estimation for Accurate Motion Tracking and Compliant Behavior of Industrial Manipulators," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5235-5241, doi: 10.1109/ICRA48891.2023.10160818.Abstract: This paper proposes a control structure for accurate tracking and compliant behavior of industrial manipulators without additional sensors. To achieve control objectives, friction, one of the biggest causes of performance degradation, should be compensated. For tracking performance, the estimated friction cancels most friction effects as a feed-forward, and the modified robust control structure eliminates the remaining friction uncertainty, which was originally equivalent to the disturbance observer. For compliant behavior, the compensation force fed to the real plant is bounded in contrast to the conventional disturbance observer structure. The compensation bound could be determined through the experiments. The proposed method is validated by experiments with a 6-DOF collaborative industrial manipulator. keywords: {Robust control;Uncertainty;Tracking;Friction;Force;Estimation;Manipulators},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160818&isnumber=10160212

X. Chen et al., "A Passivity-based Approach on Relocating High-Frequency Robot Controller to the Edge Cloud," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5242-5248, doi: 10.1109/ICRA48891.2023.10160366.Abstract: As robots become more and more intelligent, the complexity of the algorithms behind them is increasing. Since these algorithms require high computation power from the onboard robot controller, the weight of the robot and energy consumption increases. A promising solution to tackle this issue is to relocate the expensive computation to the cloud. In this pioneering work, the possibility of relocating a state-of-the-art nonlinear control is investigated. To this end, the Unified Force-Impedance Controller (UFIC) is relocated to a remote location and high frequency feedback loop is established by including the remote controller in the loop. Passivity analysis is used to ensure the stability of the whole system, comprising the robot in interaction with the environment, the communication channel, as well as the remote controller. The instability associated with the communication channel is resolved by Time Domain Passivity Approach (TDPA). The performance of the proposed framework is experimentally evaluated on a robot arm in interaction with the environment. The results illustrate the stability of the system to a time-varying delay of up to 50 ± 10ms. keywords: {Feedback loop;Energy consumption;Communication channels;Manipulators;Stability analysis;Delays;High frequency},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160366&isnumber=10160212

S. Lloyd, R. Irani and M. Ahmadi, "A Framework for Simultaneous Workpiece Registration in Robotic Machining Applications," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5249-5255, doi: 10.1109/ICRA48891.2023.10160445.Abstract: This article presents a novel framework called Simultaneous Registration and Machining (SRAM), a generalized method to improve workpiece registration using real-time acquired data in robotic contouring applications. The method allows for online corrections to the toolpath, while a live covariance estimate is simultaneously leveraged to adaptively tune the force controller aggressively when uncertainty is high, but conservatively otherwise to minimize chatter and instability. The SRAM framework is validated in simulation and shown to significantly reduce the path corrections required from the force controller, while correctly predicting optimal controller tuning adaptations. The SRAM method is proposed to improve force control stability, increase peripheral accuracy, smooth surface finish, and reduce cycle times in contouring applications. keywords: {Adaptation models;Uncertainty;Force;Random access memory;Machining;Predictive models;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160445&isnumber=10160212

R. Bendfeld and C. D. Remy, "Contact Force Control with Continuously Compliant Robotic Legs," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5256-5262, doi: 10.1109/ICRA48891.2023.10160269.Abstract: This paper presents a novel robotic leg design and an associated control approach, which aims at providing an extension to the classical series elastic actuation concept. We propose to directly integrate the series compliance into the structure of the robotic leg itself, as opposed to co-locating spring and motor as done in traditional series elastic actuators. Our approach will eliminate mechanical design complexity and lead to a reduction of mass in the legs. This will, as a secondary benefit, improve the energy efficiency of locomotion. The primary contribution of this work is a model-based controller that can stably and precisely regulate the ground contact forces during stance. This control approach is demonstrated in a set of test-bench experiments, in which we control the contact forces of a modified version of the robotic leg ScarlETH. Here, the rigid shank is replaced by a continuously compliant element made of spring steel. This work presents the first step towards a new generation of robotic legs with structural compliance. keywords: {Legged locomotion;Costs;Force;Energy efficiency;Steel;Force sensors;Springs},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160269&isnumber=10160212

C. Relaño, D. Sanz-Merodio, M. López and C. A. Monje, "Generalization of Impact Response Factors for Proprioceptive Collaborative Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5263-5268, doi: 10.1109/ICRA48891.2023.10160613.Abstract: Physical Human-Robot Interaction(pHRI) re-quires taking safety into account from the design board to the collaborative operation of any robot. For collaborative robotic environments, where human and machine are sharing space and interacting physically, the analysis and quantification of impacts becomes very relevant and necessary. Furthermore, analyses of this kind are a valuable source of information for the design of safer, more efficient pHRI. In the definition of the first parameter for dynamic impact analysis, the dynamic impact mitigation capacity was considered for certain configurations of the robot, but the design characteristics of the robot, such as the inertia of actuators, were not included. This paradigm changed when MIT presented the “impact mitigation factor” (IMF) with which, in addition to considering the ability of a certain robot to mitigate impacts for every configuration, it was possible to quantify backdriveability by taking the inertia of actuators into account for the calculation of the factor. However, IMF was proposed as a method to analyse floating robots like. This paper presents the Generalised Impact Absorption Factor (GIAF), suitable for both floating and fixed-base robots. GIAF is a valuable design parameter, as it provides information about the backdriveability of each joint, while allowing the comparison of impact response between floating and fixed-base robotic platforms. In this work, the mathematical definition of GIAF is developed and examples of possible uses of GIAF are presented. keywords: {Actuators;Automation;Absorption;Collaboration;Propioception;End effectors;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160613&isnumber=10160212

L. Tang and Y. -B. Jia, "Robotic Fastening with a Manual Screwdriver," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5269-5275, doi: 10.1109/ICRA48891.2023.10161139.Abstract: The robotic hand is still no match for the human hand on many skills. Manipulation of hand tools, which usually requires sophisticated finger movements and fine controls, not only poses a clear technical challenge but also carries a great potential for enabling the robot to assist humans in a wide range of tasks accomplishable using tools. This paper takes a first step to investigate how a robotic arm mounts a rigidly attached screwdriver onto a screw (pre-mounted in a tapped hole) and then tightens it using the tool. Mounting begins with sliding the screwdriver tip on the screw head along preplanned paths to search for the drive and follows with rotating the screwdriver to drop the tip into the drive. Prevention of a slip off the screw head is achieved via impedance control to install a “virtual fence” along its boundary. Turning of the screw is conducted via hybrid position/admittance control based on modeling the reaction force between the screw and the substrate. Simulation results with a KUKA Arm demonstrate the smoothness of the entire action. keywords: {Hand tools;Simulation;Manuals;Fasteners;Turning;Manipulators;Impedance},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161139&isnumber=10160212

J. Becker, N. Imholz, L. Schwarzenbach, E. Ghignone, N. Baumann and M. Magno, "Model- and Acceleration-based Pursuit Controller for High-Performance Autonomous Racing," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5276-5283, doi: 10.1109/ICRA48891.2023.10161472.Abstract: Autonomous racing is a research field gaining large popularity, as it pushes autonomous driving algorithms to their limits and serves as a catalyst for general autonomous driving. For scaled autonomous racing platforms, the computational constraint and complexity often limit the use of Model Predictive Control (MPC). As a consequence, geometric controllers are the most frequently deployed controllers. They prove to be performant while yielding implementation and operational simplicity. Yet, they inherently lack the incorporation of model dynamics, thus limiting the race car to a velocity domain where tire slip can be neglected. This paper presents Model- and Acceleration-based Pursuit (MAP) a high-performance model-based trajectory tracking controller that preserves the simplicity of geometric approaches while leveraging tire dynamics. The proposed algorithm allows accurate tracking of a trajectory at unprecedented velocities compared to State-of-the-Art (SotA) geometric controllers. The MAP controller is experimentally validated and outperforms the reference geometric controller four-fold in terms of lateral tracking error, yielding a tracking error of 0.055 m at tested speeds up to 11 m/s on a scaled racecar. Code: https://github.com/ETH-PBL/MAP-Controller. keywords: {Adaptation models;Codes;Trajectory tracking;Computational modeling;Tires;Trajectory;System identification},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161472&isnumber=10160212

H. Khan and M. C. Lee, "Extremum Seeking-Based Adaptive Sliding Mode Control with Sliding Perturbation Observer for Robot Manipulators," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5284-5290, doi: 10.1109/ICRA48891.2023.10160262.Abstract: This paper proposed an adaptive robust sliding mode control (SMC) with a nonlinear sliding perturbation observer (SPO) for robot manipulators. SPO estimates the perturbation (nonlinearities, uncertainties, and disturbances) with minimal system information and enhances the controller performance. The estimation is mainly dependent on the selection of SMCSPO gain, and if not tuned well, it might result in increased error dynamics of the system. Therefore, minimizing the error dynamics by improving the estimation is the primary goal of this research. In this regard, the current study accomplishes adaptation of controller gain in real-time by using an optimization technique called extremum seeking (ES). The quality adaptation is controlled with the help of a cost function. Based on the Lyapunov-based stability analysis of SMCSPO, the cost function consisting of the estimation error of the observer and error dynamics is proposed. The unique cost function now guarantees the tracking performance within the defined error tolerance. The effectiveness of the proposed algorithm is illustrated and validated in simulation and experiments. It is shown that the adaptation based on ES with the proposed cost function converges to the optimal control gain enabling the reduced estimation error and error dynamics with enhanced tracking performance. keywords: {Estimation error;Uncertainty;Perturbation methods;Optimal control;Observers;Cost function;Stability analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160262&isnumber=10160212

S. Drost, P. Pustina, F. Angelini, A. De Luca, G. Smit and C. Della Santina, "Experimental Validation of Functional Iterative Learning Control on a One-Link Flexible Arm," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5291-5297, doi: 10.1109/ICRA48891.2023.10161397.Abstract: Performing precise, repetitive motions is essential in many robotic and automation systems. Iterative learning control (ILC) allows determining the necessary control command by using a very rough system model to speed up the process. Functional iterative learning control is a novel technique that promises to solve several limitations of classic ILC. It operates by merging the input space into a large functional space, resulting in an over-determined control task in the iteration domain. In this way, it can deal with systems having more outputs than inputs and accelerate the learning process without resorting to model discretizations. However, the framework lacks so far a validation in experiments. This paper aims to provide such experimental validation in the context of robotics. To this end, we designed and built a one-link flexible arm that is actuated by a stepper motor, which makes the development of an accurate model more challenging and the validation closer to the industrial practice. We provide multiple experimental results across several conditions, proving the feasibility of the method in practice. keywords: {Automation;Service robots;Merging;Process control;Aerospace electronics;Manipulators;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161397&isnumber=10160212

M. Al Saaideh, A. M. Boker and M. Al Janaideh, "Robust Output Feedback controller for a Serial Robotic Manipulator with Unknown Nonlinearities and External Disturbances," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5298-5303, doi: 10.1109/ICRA48891.2023.10160921.Abstract: This paper presents a robust output feedback controller for a n-link serial robotic manipulator with unknown dynamics and external disturbances. First, the robotic manipulator's model is formulated with unknown dynamics, including joint coupling, nonlinearities, and external disturbances. Second, an output feedback controller is proposed by combining a backstepping controller and an extended high-gain observer to estimate the unknown dynamic and external disturbances in addition to the system states. Experiments on 4 DOF robotic manipulators verify the proposed control approach. The proposed control approach achieved the end-effector's desired trajectory under unknown system dynamics and disturbances. keywords: {Backstepping;Service robots;System dynamics;Observers;Robustness;Trajectory;Nonlinear dynamical systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160921&isnumber=10160212

Y. Ping, M. Wang, J. Qi, C. Wu and J. Guo, "Collaborative Control Based on Payload- leading for the Multi-quadrotor Transportation Systems," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5304-5309, doi: 10.1109/ICRA48891.2023.10161414.Abstract: This paper presents a collaborative control method based on payload-leading for the multi-quadrotor transportation systems. The goal is to keep the relative distance between the quadrotors and the payload as constant as possible during the transportation, so as to ensure the stable attitude of the payload. The control mechanism consists of a guidance control law that generates the common desired velocity for the quadrotors, an internal feedback controller for each quadrotor, and a decentralized formation controller. The stability of the control structure is proved by Lyapunov theory. Finally, the experimental platform of the multi-quadrotor transportation system is built to verify the effectiveness of the control method. Experimental results show that the proposed method has an excellent control effect. keywords: {Fluctuations;Automation;Transportation;Collaboration;Safety;Adaptive control;Quadrotors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161414&isnumber=10160212

V. Pasandi and D. Pucci, "Torque Control with Joints Position and Velocity Limits Avoidance," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5310-5316, doi: 10.1109/ICRA48891.2023.10160693.Abstract: The design of a control architecture for providing the desired motion along with the realization of the joint limitation of a robotic system is still an open challenge in control and robotics. This paper presents a torque control architecture for fully actuated manipulators for tracking the desired time-varying trajectory while ensuring the joints position and velocity limits. The presented architecture stems from the parametrization of the feasible joints position and velocity space by exogenous states. The proposed parametrization transforms the control problem with constrained states to an un-constrained one by replacing the joints position and velocity with the exogenous states. With the help of Lyapunov-based arguments, we prove that the proposed control architecture ensures the stability and convergence of the desired joint trajectory along with the joints position and velocity limits avoidance. We validate the performance of proposed architecture through various simulations on a simple two-degree-of-freedom manipulator and the humanoid robot iCub. keywords: {Torque;Tracking;Torque control;Humanoid robots;Transforms;Aerospace electronics;Manipulators;torque control;position and velocity limit avoidance;state parametrization},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160693&isnumber=10160212

J. -K. Cho, C. Kim, M. K. M. Jaffar, M. W. Otte and S. -W. Kim, "Low-level controller in response to changes in quadrotor dynamics," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5317-5323, doi: 10.1109/ICRA48891.2023.10160987.Abstract: The dynamics of all real quadrotors inevitably differ even if they are the same product. In particular, the dynamics can change significantly during the flight due to additional device attachments or overheating motors. In this study, we focus on training a low-level controller, which operates in response to dynamics-changes without prior knowledge or fine-tuning of the parameters, using reinforcement learning. We randomize the dynamics of quadrotors in the simulator and train the policy based on dynamics information extracted from the state-action history through recurrent neural networks (RNNs). In addition, our experiment demonstrates the difficulties in applying existing actor-critic structures that extract dynamics information using end-to-end RNNs for unstable quadrotors; hence, we propose a novel structure with better performance. Finally, the excellent performance of the proposed controller is verified by testing experiments that stabilize quadrotors with different dynamics. The experiment videos and the code can be found at https://github.com/jackyoung96/RNN-Quadrotor-controller. keywords: {Training;Recurrent neural networks;Propellers;Heuristic algorithms;Reinforcement learning;Data mining;History},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160987&isnumber=10160212

C. Geckeler, B. A. Pizzani and S. Mintchev, "Biodegradable Origami Gripper Actuated with Gelatin Hydrogel for Aerial Sensor Attachment to Tree Branches," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5324-5330, doi: 10.1109/ICRA48891.2023.10160316.Abstract: Forest canopies are vital ecosystems, but remain understudied due to difficult access. Forests could be monitored with a network of biodegradable sensors that break down into environmentally friendly substances at the end of their life. As a first step in this direction, this paper details the development of a biodegradable origami gripper to attach conventional sensors to branches, deployable with an aerial robot. Through exposure to sufficient moisture the gripper loses contractile force, dropping the sensor to the ground for easier collection. The origami design of the gripper as well as biodegradable materials selection is detailed, allowing for further extensions utilizing biodegradable origami. Both the gripper and the gelatin hydrogel used as an actuating elastic element for generating the grasping force are experimentally characterized, with the gripper demonstrating a maximum holding force of 1 N. Additionally, the degradation of the gripper until failure in the presence of moisture is also investigated, where the gripper can absorb up to 10 ml of water before falling off a branch. Finally, deployment of the gripper on a tree branch with an aerial robot is demonstrated. Overall, the biodegradable origami gripper represents a first step towards a more scalable and environmentally sustainable approach for ecosystem monitoring. keywords: {Degradation;Hydrogels;Force;Ecosystems;Moisture;Vegetation;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160316&isnumber=10160212

P. Spieler et al., "PARSEC: An Aerial Platform for Autonomous Deployment of Self-Anchoring Payloads on Natural Vertical Surfaces," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5331-5337, doi: 10.1109/ICRA48891.2023.10161380.Abstract: PARSEC (Payload Anchoring Robotic System for the Exploration of Cliffs) is an autonomy-equipped aerial manipulator that can deploy self-anchoring payloads on rocky vertical surfaces. It consists of a hexacopter and a two Degrees of Freedom (2 DoF) mass balancing manipulator, which can autonomously deploy a self-anchoring payload from its custom end-effector. The payload anchors itself via an actuated microspine gripper. Payload sensor data is wirelessly transmitted to the primary vehicle during and after deployment. A novel state machine controls the four-stage PARSEC deployment process. First, the rotorcraft brings the payload into contact with the surface and applies a constant 6 N normal force through a feedback control loop to preload the payload microspine gripper. Second, while the rotorcraft maintains the constant normal force, the gripper is commanded to close until engagement with the surface is confirmed through the current feedback sensing. Then, the aerial manipulator pulls with 5 N force on the anchored payload to ensure a secure grip before releasing the package and flying away. We present experimental validation of a successful deployment of a 430 g payload on a vertical vesicular basalt surface. keywords: {Machine control;Force;Process control;Robot sensing systems;End effectors;Sensors;Feedback control},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161380&isnumber=10160212

T. Suys, S. Hwang, G. C. H. E. De Croon and B. D. W. Remes, "Autonomous Control for Orographic Soaring of Fixed-Wing UAVs," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5338-5344, doi: 10.1109/ICRA48891.2023.10161578.Abstract: We present a novel controller for fixed-wing UAVs that enables autonomous soaring in an orographic wind field, extending flight endurance. Our method identifies soaring regions and addresses position control challenges by introducing a target gradient line (TGL) on which the UAV achieves an equilibrium soaring position, where sink rate and updraft are balanced. Experimental testing validates the controller's effectiveness in maintaining autonomous soaring flight without using any thrust in a non-static wind field. We also demonstrate a single degree of control freedom in a soaring position through manipulation of the TGL. keywords: {Automation;Propellers;Wind tunnels;Wind speed;Position control;Elevators;Testing;wind hovering;orographic soaring;au-tonomous control;UAV},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161578&isnumber=10160212

J. Byun, B. Kim, C. Kim, D. D. Oh and H. J. Kim, "Stable Contact Guaranteeing Motion/Force Control for an Aerial Manipulator on an Arbitrarily Tilted Surface," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5345-5351, doi: 10.1109/ICRA48891.2023.10161172.Abstract: This study aims to design a motion/force controller for an aerial manipulator which guarantees the tracking of time-varying motion/force trajectories as well as the stability during the transition between free and contact motions. To this end, we model the force exerted on the end-effector as the Kelvin-Voigt linear model and estimate its parameters by recursive least-squares estimator. Then, the gains of the disturbance-observer (DOB)-based motion/force controller are calculated based on the stability conditions considering both the model uncertainties in the dynamic equation and switching between the free and contact motions. To validate the proposed controller, we conducted the time-varying motion/force tracking experiments with different approach speeds and orientations of the surface. The results show that our controller enables the aerial manipulator to track the time-varying motion/force trajectories. keywords: {Tracking;Force;Dynamics;Switches;Control systems;Mathematical models;Stability analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161172&isnumber=10160212

E. Cuniato et al., "Design and Control of a Micro Overactuated Aerial Robot with an Origami Delta Manipulator," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5352-5358, doi: 10.1109/ICRA48891.2023.10161060.Abstract: This work presents the mechanical design and control of a novel small-size and lightweight Micro Aerial Vehicle (MAV) for aerial manipulation. To our knowledge, with a total take-off mass of only 2.0 kg, the proposed system is the most lightweight Aerial Manipulator (AM) that has 8-DOF independently controllable: 5 for the aerial platform and 3 for the articulated arm. We designed the robot to be fully-actuated in the body forward direction. This allows independent pitching and instantaneous force generation, improving the platform's performance during physical interaction. The robotic arm is an origami delta manipulator driven by three servomotors, enabling active motion compensation at the end-effector. Its composite multimaterial links help reduce the weight, while their flexibility allow for compliant aerial interaction with the environment. In particular, the arm's stiffness can be changed according to its configuration. We provide an in depth discussion of the system design and characterize the stiffness of the delta arm. A control architecture to deal with the platform's overactuation while exploiting the delta arm is presented. Its capabilities are experimentally illustrated both in free flight and physical interaction, highlighting advantages and disadvantages of the origami's folding mechanism. keywords: {Couplings;Force;Inspection;End effectors;Robustness;Motion compensation;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161060&isnumber=10160212

M. Nail, N. Jänne, O. Ma, G. Arellano, E. Atkins and R. B. Gillespie, "Simplifying Aerial Manipulation Using Intentional Collisions," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5359-5365, doi: 10.1109/ICRA48891.2023.10161462.Abstract: Aerial manipulation describes a process that includes physical interaction between an unmanned aircraft system (UAS) and its environment. We aim to apply aerial manipulation to sample leaves and small branches from rain forest trees. Current approaches to aerial manipulation involve extended periods of UAS-environment interaction, during which forces and moments can lead to a loss in attitude or position control in underactuated multicopters. By adapting intelligent foot placement strategies found in dynamically stable hopping robots, this work proposes a strategy involving carefully managed intentional collisions between the UAS and its environment. We designed an attitude controller denoted a Velocity Matching controller that aligns a UAS-mounted pogo-stick foot with the center of mass velocity vector during collision approach to maximize UAS ability to recover a hover state after collision. We propose the use of a flight envelope involving altitude and horizontal speed states to assess recoverability prior to initiating each approach to collision. We identify this flight envelope from a simulation study built on a model of flight in Conventional Waypoint Following and Velocity Matching control modes as well as a model of collision response. Experimental flight testing evaluates the simulation-based envelope resulting in an actual envelope that is somewhat smaller but similarly shaped to the envelope identified in simulation. keywords: {Rain;Automation;Attitude control;Position control;Forestry;Collision avoidance;Aircraft},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161462&isnumber=10160212

Y. S. Sarkisov et al., "Hierarchical Whole-body Control of the cable-Suspended Aerial Manipulator endowed with Winch-based Actuation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5366-5372, doi: 10.1109/ICRA48891.2023.10160718.Abstract: During operation, aerial manipulation systems are affected by various disturbances. Among them is a gravitational torque caused by the weight of the robotic arm. Common propeller-based actuation is ineffective against such disturbances because of possible overheating and high power consumption. To overcome this issue, in this paper we propose a winch-based actuation for the crane-stationed cable-suspended aerial manipulator. Three winch-controlled suspension rigging cables produce a desired cable tension distribution to generate a wrench that reduces the effect of gravitational torque. In order to coordinate the robotic arm and the winch-based actuation, a model-based hierarchical whole-body controller is adapted. It resolves two tasks: keeping the robotic arm end-effector at the desired pose and shifting the system center of mass in the location with zero gravitational torque. The performance of the introduced actuation system as well as control strategy is validated through experimental studies. keywords: {Torque;Power cables;Robot kinematics;Dynamics;Arms;Winches;End effectors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160718&isnumber=10160212

M. Polzin, F. Centamori and J. Hughes, "Heading for the Abyss: Control Strategies for Exploiting Swinging of a Descending Tethered Aerial Robot," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5373-5378, doi: 10.1109/ICRA48891.2023.10160347.Abstract: The use of aerial vehicles for exploration and data collection has the potential to significantly aid environmental monitoring in environments which are dangerous and hard to navigate. However, within these environments navigation can often be restricted by overhangs which are challenging to navigate, particularly so with the high payloads required for environmental monitoring. We propose utilizing a tethered bicopter with horizontal propellers. This spherical pendulum like system can exploit the tether, not only as a means of powering and recovering the robot, but also to assist its motion, i.e. by swinging to increase the workspace of the robot. Using PD-based control, we demonstrate how the system can be stabilized and bang-bang control to excite the system to achieve large amplitude swinging. By combining these controllers, we show how the system can be used to navigate in a glacial-inspired scenario where there are overhangs and obstacles through which the robot must navigate. keywords: {Automation;Navigation;Propellers;Bang-bang control;Data collection;Autonomous aerial vehicles;Environmental monitoring},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160347&isnumber=10160212

A. Ndoye, J. J. Castillo-Zamora, S. Samorah-Laki, R. Miot, E. Van Ruymbeke and F. Ruffier, "Vector Field Aided Trajectory Tracking by a 10-gram Flapping-Wing Micro Aerial Vehicle," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5379-5385, doi: 10.1109/ICRA48891.2023.10160976.Abstract: Here we describe how a 10-gram Flapping-Wing Micro Aerial Vehicle (FWMAV) was able to perform an automatic trajectory tracking task based on a vector field method. In this study, the desired heading was provided by a vector field which was computed depending on the desired trajectory. The FWMAV's heading was changed by a rear steering mechanism. This rear mechanism simultaneously (i) tenses one wing and relaxes the opposite wing, and (ii) moves the rudder in the same direction as the wing is relaxed. Due to the complex dynamics, system identification methods were used to identify simple linear models using a set of dedicated free flight tests. This yaw and roll simple models help to adjust the yaw controller and the inner loop roll controller. The experimental results obtained here show that a time-independent vector field-based strategy is robust to various initial position and/or speed conditions. The task of tracking circular and 8-shaped trajectories was accomplished successfully over tens of meters. keywords: {Meters;Automation;Trajectory tracking;Magnetometers;Manuals;Trajectory;System identification},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160976&isnumber=10160212

B. Kim, D. Lee, J. Byun and H. J. Kim, "Globally Defined Dynamic Modelling and Geometric Tracking Controller Design for Aerial Manipulator," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5386-5392, doi: 10.1109/ICRA48891.2023.10160860.Abstract: This study presents a globally defined dynamics for a conventional multirotor equipped with a single $n\mathbf{-DOF}$ manipulator using modified Lagrangian dynamics. This enables the reformulation of entire dynamics directly on $\text{SO}(3)$ without exploiting any local coordinates, and thus problems such as the singularity of Euler angles can be avoided. Since skew-symmetric property of Coriolis matrix $C$ and inertia matrix facilitates stability analysis, we propose a method to compute $C$ which guarantees the skew-symmetric property by considering $C$ as a summation of two sub-matrices. Then, a geometric tracking controller is designed based on decoupled dynamics applying passive decomposition. The proposed controller guarantees almost global region of attraction. We validate our method via consecutive aerial flipping experiments. keywords: {Automation;Attitude control;Robot kinematics;Stability analysis;Matrix decomposition;History;Manipulator dynamics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160860&isnumber=10160212

N. Simon et al., "FlowDrone: Wind Estimation and Gust Rejection on UAVs Using Fast-Response Hot-Wire Flow Sensors," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5393-5399, doi: 10.1109/ICRA48891.2023.10160454.Abstract: Unmanned aerial vehicles (UAVs) are finding use in applications that place increasing emphasis on robustness to external disturbances including extreme wind. However, traditional multirotor UAV platforms do not directly sense wind; conventional flow sensors are too slow, insensitive, or bulky for widespread integration on UAVs. Instead, drones typically observe the effects of wind indirectly through accumulated errors in position or trajectory tracking. In this work, we integrate a novel flow sensor based on micro-electro-mechanical systems (MEMS) hot-wire technology developed in our prior work [1] onto a multirotor UAV for wind estimation. Our sensor is omnidirectional (in the plane), lightweight, fast, and accurate. In order to achieve superior hover performance in windy conditions, we train a ‘wind-aware’ residual-based controller via reinforcement learning using simulated wind gusts and their aerodynamic effects on the drone. In extensive hardware experiments, we demonstrate the wind-aware controller out-performing two strong ‘wind-unaware’ baseline controllers in challenging windy conditions. See: youtu.be/KWqkH9Z-338. keywords: {Micromechanical devices;Wind;Trajectory tracking;Estimation;Reinforcement learning;Autonomous aerial vehicles;Sensor systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160454&isnumber=10160212

A. Saviolo, J. Mao, R. B. T. M. B, V. Radhakrishnan and G. Loianno, "AutoCharge: Autonomous Charging for Perpetual Quadrotor Missions," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5400-5406, doi: 10.1109/ICRA48891.2023.10161503.Abstract: Battery endurance represents a key challenge for long-term autonomy and long-range operations, especially in the case of aerial robots. In this paper, we propose AutoCharge, an autonomous charging solution for quadrotors that combines a portable ground station with a flexible, lightweight charging tether and is capable of universal, highly efficient, and robust charging. We design and manufacture a pair of circular magnetic connectors to ensure a precise orientation-agnostic electrical connection between the ground station and the charging tether. Moreover, we supply the ground station with an electromagnet that largely increases the tolerance to localization and control errors during the docking maneuver, while still guaranteeing smooth un-docking once the charging process is completed. We demonstrate AutoCharge on a perpetual 10 hours quadrotor flight experiment and show that the docking and un-docking performance is solidly repeatable, enabling perpetual quadrotor flight missions. keywords: {Location awareness;Connectors;Automation;Process control;Electromagnets;Autonomous aerial vehicles;Batteries},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161503&isnumber=10160212

J. Jiang, L. Yang and L. Zhang, "DQN-based on-line Path Planning Method for Automatic Navigation of Miniature Robots," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5407-5413, doi: 10.1109/ICRA48891.2023.10161023.Abstract: Untethered magnetic microrobots with control-lable locomotion property and multiple functions have attracted lots of attention in recent years. Owing to the small scale, micro-robots with automatic navigation possess a promising perspec-tive for biomedical applications including precise delivery and targeted therapy in confined and narrow space, especially for in-vivo scenario. However, the practical working environment for microrobots can be various, dynamic, and complicated, and path planning algorithm applicable for both dynamic obstacle avoidance and planning in maze-like environments still remains a challenge. Furthermore, considering the sizes, different types of microrobots may occupy different proportions of the field of vision. The safe distance between the waypoints and the obstacles needs to be taken into thoughts. In this work, we proposed a reinforcement learning-based strategy capable of real-time path planning for microrobots in different scales. The reference moving direction at each control period is provided by a deep Q network (DQN) according to the local surrounding environment, and the corresponding control magnetic field is generated via a 3-axis Helmholtz coil system. A distur-bance observer (DOB) is responsible for the locomotion state observation and direction error compensation. Experiments demonstrate the effectiveness of our proposed strategy using microrobots with different locomotion mechanisms and scales, in both virtual dynamic obstacle environments and channel-like environments. keywords: {Navigation;Heuristic algorithms;Medical treatment;Observers;Path planning;Real-time systems;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161023&isnumber=10160212

S. Wang, Z. Yu, C. Hou, K. Wang and L. Dong, "Rendezvous and Docking of Magnetic Helical Microrobots Along Arc Orbits for Field-directed Assembly and Disassembly," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5414-5419, doi: 10.1109/ICRA48891.2023.10160397.Abstract: Due to the limited cargo/functional element loading and other capabilities of individual microrobots, assembling them for locomotion and disassembling them as arriving at the target is more effective. An approach called rendezvous and docking is proposed in this paper to control the assembly and disassembly of helical microrobots actuated by a uniform rotating magnetic field. Docking is realized around the intersection of their arc orbits with the assistance of a fluidic field. To adjust the distance between the adjacent helical robots suspending in solution but with a distance beyond the acceptable range of the magnetic interaction, their asynchronized velocities are achieved using the interaction between the robots and fluids. For robots rotating at different speeds around their longitudinal axes at a driving frequency lower than the cut-off frequency, different fluidic flows will be generated. Based on the interaction between the robots and the fluids, the translational trajectory paths may be tuned, causing the adjacent robots to move closer. Docking along the tangential direction of rendezvous arc trajectories avoids the instability of the helical robot rotating around the radial direction and the problem of excessive linear speed at the end during assembly so that the robot can rotate stably around its axis while completing the assembly. Besides these, assembled microrobots can also lower the requirements on the imaging resolution of motion tracking and the forces for driving; hence much lower cost for both imaging and driving equipment. keywords: {Image resolution;Fluids;Tracking;Magnetic resonance imaging;Loading;Magnetic liquids;Orbits},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160397&isnumber=10160212

M. E. Tiryaki, F. Doğangün, C. B. Dayan, P. Wrede and M. Sitti, "MRI-powered Magnetic Miniature Capsule Robot with HIFU-controlled On-demand Drug Delivery," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5420-5425, doi: 10.1109/ICRA48891.2023.10161197.Abstract: Magnetic resonance imaging (MRI)-guided robotic systems offer great potential for new minimally invasive medical tools, including MRI-powered miniature robots. By re-purposing the imaging hardware of an MRI scanner, the magnetic miniature robot could be navigated into the remote part of the patient's body without needing tethered endoscopic tools. However, state-of-art MRI-powered magnetic miniature robots have limited functionality besides navigation. Here, we propose an MRI-powered magnetic miniature capsule robot benefiting from acoustic streaming forces generated by MRI-guided high-intensity focus ultrasound (HIFU) for controlled drug release. Our design comprises a polymer capsule shell with a submillimeter-diameter drug-release hole that captures an air bubble functioning as a stopper. We use the HIFU pulse to initiate drug release by removing the air bubble once the capsule robot reaches the target location. By controlling acoustic pressure, we also regulate the drug release rate for multiple locations targeting during navigation. We demonstrated that the proposed magnetic capsule robot could travel at high speed, up to 1.13 cm/s in ex vivo porcine small intestine, and release drug to multiple target sites in a single operation, using a combination of MRI-powered actuation and HIFU-controlled release. The proposed MRI-guided microrobotic drug release system will greatly impact minimally invasive medical procedures by allowing on-demand targeted drug delivery. keywords: {Drugs;Minimally invasive surgery;Intestines;Ultrasonic imaging;Navigation;Magnetic resonance imaging;Magnetoacoustic effects},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161197&isnumber=10160212

A. Homayouni-Amlashi, M. Rakotondrabe and A. Mohand-Ousaid, "Structural Design and Frequency Tuning of Piezoelectric Energy Harvesters Based on Topology Optimization," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5426-5432, doi: 10.1109/ICRA48891.2023.10161313.Abstract: Vibrational piezoelectric energy harvesters (vPEH) are of great interest in several fields such as autonomous sensors and wireless sensor networks, bird tracking devices, or autonomous miniaturized robotic systems. They capture energy from mechanical vibrations available in the ambient environment and convert it into electrical one to power those systems. Basically, a vPEH is composed of three main parts: the transducer mechanical structure, an electronic interface and the storage unit. In this paper, we focus on the optimization of the mechanical structure of the harvester. To this end, an optimization framework based on topology optimization is proposed. It consists to combine the Solid Isotropic Material with Penalization (SIMP) approach and frequency tuning technique to further increase the efficiency of the harvesters. The fundamental frequency of the design is tuned by considering the mass of the attachment as an optimization variable in addition to the classical density and polarity variables. Two numerical examples, including a new piezoelectric energy harvester configuration, are investigated to demonstrate the effectiveness of the topology optimization framework. keywords: {Vibrations;Wireless sensor networks;Transducers;Solids;Robot sensing systems;Sensor systems;Topology},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161313&isnumber=10160212

L. -J. W. Ligtenberg and I. S. M. Khalil, "Input-Output Boundedness of a Magnetically-Actuated Helical Device," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5433-5438, doi: 10.1109/ICRA48891.2023.10160556.Abstract: To date, all previous research in the wireless magnetic actuation of untethered helical devices has achieved motion stability using feedback control in vitro. However, feedback control systems are likely to be affected by the increased sensory uncertainty during in vivo trials. In this study we investigate the input-output boundedness of an interconnection between a helical device and a single rotating magnet actuator in low-Reynolds-number regime. Using the resistive-force theory, the interconnection is expressed in terms of all possible input-output pairs. Inputs representing the actuation frequency, pitch angle, lateral speed, and field strength are analyzed numerically and experimentally. We demonstrate input-output boundedness of the states of the helical device during circular and straight runs in open-loop, and we demonstrate bounded input-output propulsion without orienting the angle of attack (the often used input to swim horizontally without vertical drift) of the helical device to counteract gravity. Our results are important for a number of minimally invasive applications and tasks requiring improved control authority for stable runs of helical devices without drift due to gravity and without feedback control and restricted configuration imposed on the helical device's motion. keywords: {Wireless communication;Wireless sensor networks;Uncertainty;Magnetic devices;Propulsion;Robot sensing systems;Stability analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160556&isnumber=10160212

Z. Qu, W. Zhang and L. Dong, "Atomic-level Tracking and Analyzing of Quantum-dot Motion Steered by an Electrostatic Field Positioned by a Nanorobotic Manipulation Tip," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5439-5444, doi: 10.1109/ICRA48891.2023.10161087.Abstract: Field-control-based nanorobotic manipulation of ions at the single atomic level is an enabling technique for such applications as in-situ prototyping and characterization for fundamental research and rapid product development of nanoscale and quantum devices such as sensors, batteries, neuromorphic devices, and neuro/brain interfaces. Taking the motion of quantum dots (QDs) manipulated by an electrostatic field steered by a probe tip on a target surface as an example, here we show a deep-learning-based approach for their global motion tracking via the individual atoms both on the surface and inside the body. Transmission electron graphs, element analysis, and crystal topology acquired from an aberration-corrected transmission electron microscope (Cs-TEM) are used to identify the positions, types, and structures of the atoms to understand their kinematics. The results show the feasibility of multi-target tracking of homogeneous atoms by their spatial structure projection, which is very encouraging for further extension to the tracking and regulation of crystalline grains, swarms of ions, ion filaments, and single ions. keywords: {Tracking;Transmission electron microscopy;Quantum dots;Crystals;Sensor phenomena and characterization;Ions;Robot sensing systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161087&isnumber=10160212

S. Kim and S. Bergbreiter, "3D-Printed Adaptive Microgripper Driven by Thin-Film NiTi Actuators," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5445-5451, doi: 10.1109/ICRA48891.2023.10160829.Abstract: Creating microscale actuated mechanisms in 3D space is extremely challenging due to limitations in microfabrication processes. In this work, we present a 3D-printed adaptive microgripper that is driven by thin-film NiTi microactuators with 3D-printed linkage mechanisms. The microgripper's fingers are passively adaptive so that the microgripper can provide conformal gripping on 3D objects. The microgripper can move its fingers by $\mathbf{225}\ \boldsymbol{\mu} \mathbf{m}$ and apply a blocking force of $\mathbf{30}\ \boldsymbol{\mu} \mathbf{N}$ per one finger when 20 mA was applied to the NiTi actuators. The microgripper was also integrated onto a printed circuit board with a current regulating circuit and a 9 V battery. Since the NiTi actuator requires a low voltage for actuation, the microgripper could be integrated with simple and affordable electronics. The fully integrated microgripper system was demonstrated playing with a shape sorting box at the microscale for the first time. keywords: {Couplings;Low voltage;Three-dimensional displays;Shape;Fingers;Microactuators;Silicon},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160829&isnumber=10160212

H. Gong, Y. Zhang, Y. Liu, Q. Zhao, X. Zhao and M. Sun, "Automatic Cell Rotation Method Based on Deep Reinforcement Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5452-5458, doi: 10.1109/ICRA48891.2023.10161043.Abstract: Cell rotation is widely used to adjust cell posture in sub-cellular micromanipulations. The trajectory planning of the injection micropipette is needed, so that the cells can be rotated with the minimum deformation to reduce cell damage and keep cell viability. Due to the uncertainty of cell properties and manipulation environment, it is difficult to identify the parameters of the mechanical models in traditional robotic cell rotation methods. In this paper, deep reinforcement learning is introduced into cell manipulation for the first time to perform trajectory planning of the micropipette. We first abstract the cell rotation process by using the mechanical model and microscopic vision techniques and build a cell rotation simulation environment. Then we design a reward function by combining various factors of cell rotation and implement a reinforcement learning framework based on deep Q-learning (DQL). Finally, we train the cell rotation process based on the deep reinforcement learning algorithm. The simulation results indicate the proposed DQL agent achieved an average success rate of 97% without useless exploration. Moreover, the proposed method rotated the cells in a way that causes less mechanical damage than humans, demonstrating the DRL ability for cell rotation with high efficiency and low cell damage. keywords: {Deep learning;Training;Uncertainty;Q-learning;Trajectory planning;Deformation;Microscopy},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161043&isnumber=10160212

Y. Zhang et al., "Noncontact Particle Manipulation on Water Surface with Ultrasonic Phased Array System and Microscopic Vision," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5459-5465, doi: 10.1109/ICRA48891.2023.10160724.Abstract: Noncontact particle manipulation (NPM) shows great application potential than its conventional counterpart particularly in terms of non-invasiveness, and thus has significantly extended robotic manipulation capacity into bio- medical engineering, material science, etc. As NPM by means of electric, magnetic, and optical field has successfully demonstrated powerful strength in both academia and industry, NPM boosted by acoustic field, however, still faces staggering challenges. It is indeed in the very recent years that controllable dynamic airborne or waterborne acoustic field modulation technology emerged in academia. In this paper, we report our latest research regarding dexterous and dynamic noncontact micro-particle manipulation on water surface effected by acoustic field in terms of automated trapping, closed-loop positioning, and real-time motion planning, which can be applied to scenarios such as parallel 3D printing, cell assembly, etc. The main contribution of this work is we demonstrated the feasibility of objective-oriented and fully automated acoustic manipulation of micro-particle in precision scale based on robotic approach in 2D plane. Experiment results showed that the repetitive positioning accuracy can reach as high as 16 μm, which is essentially the pixel scale factor. keywords: {Robust control;Visualization;Service robots;Dynamics;Three-dimensional printing;Real-time systems;Acoustic field},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160724&isnumber=10160212

C. Zhong, Z. Sun, T. Li, H. Su and S. Liu, "Real-time Acoustic Holography with Iterative Unsupervised Learning for Acoustic Robotic Manipulation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5466-5472, doi: 10.1109/ICRA48891.2023.10160962.Abstract: Phase-only acoustic holography is a fundamental and promising technique for contactless robotic manipulation. Through independently controlling phase-only hologram (POH) of phase array of transducers (PAT) and simultaneously driving each channel by sophisticated circuits, a certain acoustic field is dynamically generated in working medium (e.g., air, water or biological tissues) at certain moment. The phase profile of PAT is required dynamically and precisely as per arbitrary expected acoustic field for the sake of versatile and stable robotic manipulation. However, the most conventional methods rely on iterative optimization algorithms which are inevitably time-consuming and probably non-convergent, moreover hindering versatility and fidelity of acoustic robotic manipulation. To address these issues, this paper reports a real-time phase-only acoustic holography algorithm by virtue of iterative unsupervised learning. Using a physics model to construct two queues, which we refer to as experience pools, data pairs consisting of a target acoustic amplitude hologram in expected acoustic field and corresponding POH of PAT are collected on-the-fly, circumventing costly preparation of annotated dataset in advance. With iterative learning between neural network training and experience pools update, both the solution of objective inverse mapping and the adaptation for arbitrary desired acoustic field are mutually enhanced. The experiments and results validated that the proposed approach surpasses previous algorithms in terms of real time and precision. keywords: {Training;Transducers;Three-dimensional displays;Artificial neural networks;Holography;Real-time systems;Iterative algorithms},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160962&isnumber=10160212

R. Sakagami, S. G. Brunner, A. Dömel, A. Wedler and F. Stulp, "ROSMC: A High-Level Mission Operation Framework for Heterogeneous Robotic Teams," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5473-5479, doi: 10.1109/ICRA48891.2023.10161133.Abstract: Heterogeneous teams of multiple mobile robots will be important for future scientific explorations of extraterrestrial surfaces or hazardous areas. Mission operation in such harsh, unknown environments poses diverse challenges. Robots need to cooperate autonomously due to the large network latency to the ground station while operators need to adapt the ongoing mission flexibly based on new discoveries obtained during execution. Furthermore, shared situational awareness between operators and roboticists is highly required to deal with execution failures promptly. To overcome these challenges, this paper proposes the high-level mission operation framework ROSMC. The concept of mission synchronization to robots enables continuous mission adaptations and future planning by operators while robots execute the mission autonomously. The ROS-based GUIs enable operators to intuitively create and monitor the mission for robots as well as to communicate with roboticists smoothly. The proposed framework was evaluated by a pilot study with a simulator and demonstrated at a Moon-analogue field on Mt. Etna in Sicily, Italy, involving 3 robots and around 70 researchers for 4 weeks. keywords: {Hazardous areas;Automation;Planning;Synchronization;Mobile robots;Robots;Monitoring},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161133&isnumber=10160212

F. Liu, S. Yuan, W. Meng, R. Su and L. Xie, "Non-cooperative Stochastic Target Encirclement by Anti-synchronization Control via Range-only Measurement," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5480-5485, doi: 10.1109/ICRA48891.2023.10161054.Abstract: This paper investigates the stochastic moving target encirclement problem in a realistic setting. In contrast to typical assumptions in related works, the target in our work is non-cooperative and capable of escaping the circle containment by boosting its speed to maximum for a short duration. In extreme conditions, where GPS signals are not available, weight restrictions are present, and ground guidance is absent, the agents can rely solely on their onboard single-modality perception tools to measure the distances to the target. The distance measurement allows for creating a position estimator by providing a target position-dependent variable. Furthermore, the construction of the unique distributed anti-synchronization controller (DASC) can guarantee that the two agents track and encircle the target swiftly. The convergence of the estimator and controller is rigorously evaluated using the Lyapunov technique. A real-world UAV-based experiment is conducted to illustrate the performance of the proposed methodology in addition to a simulated Matlab numerical sample. Our video demonstration can be found in the URL https://youtu.be/EDVLvP-bk8M. keywords: {Weight measurement;Uniform resource locators;Target tracking;Stochastic processes;Approximation algorithms;Numerical simulation;Mathematical models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161054&isnumber=10160212

M. Raoufi, P. Romanczuk and H. Hamann, "Estimation of continuous environments by robot swarms: Correlated networks and decision-making," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5486-5492, doi: 10.1109/ICRA48891.2023.10161354.Abstract: Collective decision-making is an essential capability of large-scale multi-robot systems to establish autonomy on the swarm level. A large portion of literature on collective decision-making in swarm robotics focuses on discrete decisions selecting from a limited number of options. Here we assign a decentralized robot system with the task of exploring an unbounded environment, finding consensus on the mean of a measurable environmental feature, and aggregating at areas where that value is measured (e.g., a contour line). A unique quality of this task is a causal loop between the robots' dynamic network topology and their decision-making. For example, the network's mean node degree influences time to convergence while the currently agreed-on mean value influences the swarm's aggregation location, hence, also the network structure as well as the precision error. We propose a control algorithm and study it in real-world robot swarm experiments in different environments. We show that our approach is effective and achieves higher precision than a control experiment. We anticipate applications, for example, in containing pollution with surface vehicles. keywords: {Network topology;Decision making;Area measurement;Estimation;Switches;Robot sensing systems;Pollution measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161354&isnumber=10160212

J. Ichnowski et al., "FogROS2: An Adaptive Platform for Cloud and Fog Robotics Using ROS 2," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5493-5500, doi: 10.1109/ICRA48891.2023.10161307.Abstract: Mobility, power, and price points often dictate that robots do not have sufficient computing power on board to run contemporary robot algorithms at desired rates. Cloud computing providers such as AWS, GCP, and Azure offer immense computing power and increasingly low latency on demand, but tapping into that power from a robot is non-trivial. We present FogROS2, an open-source platform to facilitate cloud and fog robotics that is included in the Robot Operating System 2 (ROS 2) distribution. FogROS2 is distinct from its predecessor FogROS1 in 9 ways, including lower latency, overhead, and startup times; improved usability, and additional automation, such as region and computer type selection. Additionally, FogROS2 gains performance, timing, and additional improvements associated with ROS 2. In common robot applications, FogROS2 reduces SLAM latency by 50 %, reduces grasp planning time from 14 s to 1.2 s, and speeds up motion planning 45x. When compared to FogROS1, FogROS2 reduces network utilization by up to 3.8x, improves startup time by 63 %, and network round-trip latency by 97 % for images using video compression. The source code, examples, and documentation for FogROS2 are available at https://github.com/BerkeleyAutomation/FogROS2, and is available through the official ROS 2 repository at https://index.ros.org/p/FogROS2/. keywords: {Cloud computing;Codes;Automation;Simultaneous localization and mapping;Source coding;Video compression;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161307&isnumber=10160212

B. Yang, L. Zheng, L. J. Ratliff, B. Boots and J. R. Smith, "Stackelberg Games for Learning Emergent Behaviors During Competitive Autocurricula," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5501-5507, doi: 10.1109/ICRA48891.2023.10160875.Abstract: Autocurricular training is an important sub-area of multi-agent reinforcement learning (MARL) that allows multiple agents to learn emergent skills in an unsupervised co-evolving scheme. The robotics community has experimented auto-curricular training with physically grounded problems, such as robust control and interactive manipulation tasks. However, the asymmetric nature of these tasks makes the generation of sophisticated policies challenging. Indeed, the asymmetry in the environment may implicitly or explicitly provide an advantage to a subset of agents which could, in turn, lead to a low-quality equilibrium. This paper proposes a novel game-theoretic algorithm, Stackelberg Multi-Agent Deep Deterministic Policy Gradient (ST-MADDPG), which formulates a two-player MARL problem as a Stackelberg game with one player as the ‘leader’ and the other as the ‘follower’ in a hierarchical interaction structure wherein the leader has an advantage. We first demonstrate that the leader's advantage from ST-MADDPG can be used to alleviate the inherent asymmetry in the environment. By exploiting the leader's advantage, ST-MADDPG improves the quality of a co-evolution process and results in more sophisticated and complex strategies that work well even against an unseen strong opponent. keywords: {Training;Robust control;Automation;Games;Reinforcement learning;Approximation algorithms;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160875&isnumber=10160212

J. -L. Bastarache, C. Nielsen and S. L. Smith, "On Legible and Predictable Robot Navigation in Multi-Agent Environments," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5508-5514, doi: 10.1109/ICRA48891.2023.10160572.Abstract: Legible motion is intent-expressive, which when employed during social robot navigation, allows others to quickly infer the intended avoidance strategy. Predictable motion matches an observer's expectation which, during navigation, allows others to confidently carryout the interaction. In this work, we present a navigation framework capable of reasoning on its legibility and predictability with respect to dynamic interactions, e.g., a passing side. Our approach generalizes the previously formalized notions of legibility and predictability by allowing dynamic goal regions in order to navigate in dynamic environments. This generalization also allows us to quantitatively evaluate the legibility and the predictability of trajectories with respect to navigation interactions. Our approach is shown to promote legible behavior in ambiguous scenarios and predictable behavior in unambiguous scenarios. In a multi-agent environment, this yields an increase in safety while remaining competitive in terms of goal-efficiency when compared to other robot navigation planners in multi-agent environments. The code of this work is made publicly available1. keywords: {Codes;Automation;Navigation;Dynamics;Social robots;Cognition;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160572&isnumber=10160212

Y. Guo et al., "Explainable Action Advising for Multi-Agent Reinforcement Learning," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5515-5521, doi: 10.1109/ICRA48891.2023.10160557.Abstract: Action advising is a knowledge transfer technique for reinforcement learning based on the teacher-student paradigm. An expert teacher provides advice to a student during training in order to improve the student's sample efficiency and policy performance. Such advice is commonly given in the form of state-action pairs. However, it makes it difficult for the student to reason with and apply to novel states. We introduce Explainable Action Advising, in which the teacher provides action advice as well as associated explanations indicating why the action was chosen. This allows the student to self-reflect on what it has learned, enabling advice generalization and leading to improved sample efficiency and learning performance - even in environments where the teacher is sub-optimal. We empirically show that our framework is effective in both single-agent and multi-agent scenarios, yielding improved policy returns and convergence rates when compared to state-of-the-art methods. keywords: {Training;Automation;Reinforcement learning;Benchmark testing;Reflection;Knowledge transfer;Convergence},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160557&isnumber=10160212

K. Soma, K. Khateri, M. Pourgholi, M. Montazeri, L. Sabattini and G. Beltrame, "A Complete Set of Connectivity-aware Local Topology Manipulation Operations for Robot Swarms," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5522-5529, doi: 10.1109/ICRA48891.2023.10160312.Abstract: The topology of a robotic swarm affects the convergence speed of consensus and the mobility of the robots. In this paper, we prove the existence of a complete set of local topology manipulation operations that allow the transformation of a swarm topology. The set is complete in the sense that any other possible set of manipulation operations can be performed by a sequence of operations from our set. The operations are local as they depend only on the first and second hop neighbors' information to transform any initial spanning tree of the network's graph to any other connected tree with the same number of nodes. The flexibility provided by our method is similar to global methods that require full knowledge of the swarm network. We prove the existence of a sequence of transformations for any tree-to-tree transformation, and derive sequences of operations to form a line or star from any initial spanning tree. Our work provides a theoretical and practical framework for topological control of a swarm, establishing global properties using only local information. keywords: {Knowledge engineering;Automation;Stars;Transforms;Robot sensing systems;Manipulators;Topology},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160312&isnumber=10160212

H. J. He, A. Koppel, A. S. Bedi, D. J. Stilwell, M. Farhood and B. Biggs, "Decentralized Multi-agent Exploration with Limited Inter-agent Communications," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5530-5536, doi: 10.1109/ICRA48891.2023.10160599.Abstract: We consider the problem of decentralized multiagent environmental learning through maximizing the joint information gain among a team of agents. Inspired by subsea applications where bandwidth is severely limited, we explicitly consider the challenge of restricted communication between agents. The environment is modeled as a Gaussian process (GP), and the global information gain maximization problem in a GP is a set-valued optimization problem involving all agents' locally acquired data. We develop a decentralized method to solve it based on decomposition of information gain and exchange of limited subsets of data between agents. A key technical novelty of our approach is that we formulate the incentives for information exchange among agents as a submodular set optimization problem in terms of the log-determinant of their local covariance matrices. Numerical experiments on real-world data demonstrate the ability of our algorithm to explore trade-off between objectives. In particular, we demonstrate favorable performance on mapping problems where both decentralized information gathering and limited information exchange are essential. keywords: {Automation;Gaussian processes;Bandwidth;Data models;Communication networks;Covariance matrices;Optimization},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160599&isnumber=10160212

L. Pichierri, G. Carnevale, L. Sforni, A. Testa and G. Notarstefano, "A Distributed Online Optimization Strategy for Cooperative Robotic Surveillance," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5537-5543, doi: 10.1109/ICRA48891.2023.10160700.Abstract: In this paper, we propose a distributed algorithm to control a team of cooperating robots aiming to protect a target from a set of intruders. Specifically, we model the strategy of the defending team by means of an online optimization problem inspired by the emerging distributed aggregative framework. In particular, each defending robot determines its own position depending on (i) the relative position between an associated intruder and the target, (ii) its contribution to the barycenter of the team, and (iii) collisions to avoid with its teammates. We highlight that each agent is only aware of local, noisy measurements about the location of the associated intruder and the target. Thus, in each robot, our algorithm needs to (i) locally reconstruct global unavailable quantities and (ii) predict its current objective functions starting from the local measurements. The effectiveness of the proposed methodology is corroborated by simulations and experiments on a team of cooperating quadrotors. keywords: {Current measurement;Surveillance;Prediction algorithms;Particle measurements;Noise measurement;Collision avoidance;Distributed algorithms},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160700&isnumber=10160212

A. B. Asghar et al., "Risk-aware Recharging Rendezvous for a Collaborative Team of UAVs and UGVs," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5544-5550, doi: 10.1109/ICRA48891.2023.10161446.Abstract: We introduce and investigate the recharging rendezvous problem for a collaborative team of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs), in which UAVs with limited battery capacity and UGVS persistently monitor an area. The UGVs also act as mobile recharging stations for the UAVs. In contrast to prior work on such problems, we consider the challenge of dealing with stochastic energy consumption in a risk-aware fashion. Specifically, we consider a bi-criteria optimization problem of minimizing the time taken by the UAVs on recharging detours while ensuring that the probability that no UAV runs out of charge is greater than a user-defined risk tolerance. This problem (termed Risk-aware Recharging Rendezvous Problem (RRRP)) is a combinatorial problem with a matching constraint — to ensure UAVs are assigned to the limited UGV recharging slots, and a knapsack constraint — to capture the risk tolerance. We propose a novel bicriteria approximation algorithm to solve RRRP and demonstrate its effectiveness in the context of a persistent monitoring mission compared to baseline methods. keywords: {Energy consumption;Collaboration;Stochastic processes;Approximation algorithms;Autonomous aerial vehicles;Routing;Land vehicles},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161446&isnumber=10160212

P. Bänninger, I. Alzugaray, M. Karrer and M. Chli, "Cross-Agent Relocalization for Decentralized Collaborative SLAM," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5551-5557, doi: 10.1109/ICRA48891.2023.10160941.Abstract: State-of-the-art decentralized collaborative Simultaneous Localization And Mapping (SLAM) systems crucially lack the ability to effectively use well-mapped areas generated by other agents in the team for relocalization. This often leads to map redundancy between agents, inefficient communication, and the need for costly re-mapping of areas previously mapped by other agents. In this work, we propose a strategy to efficiently share the areas mapped by different agents in a collaborative, decentralized SLAM system. This approach directly addresses map redundancy while maintaining the consistency of the estimates across the agents and keeping the overall system scalable in terms of cross-agent communication and individual computational effort. Our method leverages covisibility information between keyframes instantiated by different agents to transfer local sub-maps on-the-fly in a completely decentralized, peer-to-peer fashion. A globally consistent estimate is achieved by solving a distributed bundle adjustment problem using the Alternating Direction Method of Multipliers (ADMM), where we enforce constraints on shared map points and keyframes across agents. keywords: {Simultaneous localization and mapping;Scalability;Redundancy;Collaboration;Optimized production technology;Distributed databases;Cameras},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160941&isnumber=10160212

F. Christianos, P. Karkus, B. Ivanovic, S. V. Albrecht and M. Pavone, "Planning with Occluded Traffic Agents using Bi-Level Variational Occlusion Models," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5558-5565, doi: 10.1109/ICRA48891.2023.10160604.Abstract: Reasoning with occluded traffic agents is a significant open challenge for planning for autonomous vehicles. Recent deep learning models have shown impressive results for predicting occluded agents based on the behaviour of nearby visible agents; however, as we show in experiments, these models are difficult to integrate into downstream planning. To this end, we propose Bi-Ievel Variational Occlusion Models (BiVO), a two-step generative model that first predicts likely locations of occluded agents, and then generates likely trajectories for the occluded agents. In contrast to existing methods, BiVO outputs a trajectory distribution which can then be sampled from and integrated into standard downstream planning. We evaluate the method in closed-loop replay simulation using the real-world nuScenes dataset. Our results suggest that BiVO can successfully learn to predict occluded agent trajectories, and these predictions lead to better subsequent motion plans in critical scenarios. keywords: {Deep learning;Automation;Predictive models;Cognition;Planning;Trajectory;Standards},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160604&isnumber=10160212

S. Agarwal, D. Fridovich-Keil and S. P. Chinchali, "Robust Forecasting for Robotic Control: A Game-Theoretic Approach," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5566-5573, doi: 10.1109/ICRA48891.2023.10160721.Abstract: Modern robots require accurate forecasts to make optimal decisions in the real world. For example, self-driving cars need an accurate forecast of other agents' future actions to plan safe trajectories. Current methods rely heavily on historical time series to accurately predict the future. However, relying entirely on the observed history is problematic since it could be corrupted by noise, have outliers, or not completely represent all possible outcomes. To solve this problem, we propose a novel framework for generating robust forecasts for robotic control. In order to model real-world factors affecting future forecasts, we introduce the notion of an adversary, which perturbs observed historical time series to increase a robot's ultimate control cost. Specifically, we model this interaction as a zero-sum two-player game between a robot's forecaster and this hypothetical adversary. We show that our proposed game may be solved to a local Nash equilibrium using gradient-based optimization techniques. Furthermore, we show that a forecaster trained with our method performs 30.14% better on out-of-distribution real-world lane change data than baselines. keywords: {Training;Time series analysis;Games;Predictive models;Robot sensing systems;Nash equilibrium;Transformers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160721&isnumber=10160212

Z. Zhang, S. Han, J. Wang and F. Miao, "Spatial-Temporal-Aware Safe Multi-Agent Reinforcement Learning of Connected Autonomous Vehicles in Challenging Scenarios," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5574-5580, doi: 10.1109/ICRA48891.2023.10161216.Abstract: Communication technologies enable coordination among connected and autonomous vehicles (CAVs). However, it remains unclear how to utilize shared information to improve the safety and efficiency of the CAV system in dynamic and complicated driving scenarios. In this work, we propose a framework of constrained multi-agent reinforcement learning (MARL) with a parallel Safety Shield for CAVs in challenging driving scenarios that includes unconnected hazard vehicles. The coordination mechanisms of the proposed MARL include information sharing and cooperative policy learning, with Graph Convolutional Network (GCN)-Transformer as a spatial-temporal encoder that enhances the agent's environment awareness. The Safety Shield module with Control Barrier Functions (CBF)-based safety checking protects the agents from taking unsafe actions. We design a constrained multi-agent advantage actor-critic (CMAA2C) algorithm to train safe and cooperative policies for CAVs. With the experiment deployed in the CARLA simulator, we verify the performance of the safety checking, spatial-temporal encoder, and coordination mechanisms designed in our method by comparative experiments in several challenging scenarios with unconnected hazard vehicles. Results show that our proposed methodology significantly increases system safety and efficiency in challenging scenarios. keywords: {Connected vehicles;Information sharing;Reinforcement learning;Hazards;Robustness;Communications technology;Noise measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161216&isnumber=10160212

X. Cai et al., "Analyzing Infrastructure LiDAR Placement with Realistic LiDAR Simulation Library," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5581-5587, doi: 10.1109/ICRA48891.2023.10161027.Abstract: Recently, Vehicle-to-Everything (V2X) cooperative perception has attracted increasing attention. Infrastructure sensors play a critical role in this research field; however, how to find the optimal placement of infrastructure sensors is rarely studied. In this paper, we investigate the problem of infrastructure sensor placement and propose a pipeline that can efficiently and effectively find optimal installation positions for infrastructure sensors in a realistic simulated environment. To better simulate and evaluate LiDAR place-ment, we establish a Realistic LiDAR Simulation library that can simulate the unique characteristics of different popular LiDARs and produce high-fidelity LiDAR point clouds in the CARLA simulator. Through simulating point cloud data in different LiDAR placements, we can evaluate the perception accuracy of these placements using multiple detection models. Then, we analyze the correlation between the point cloud distribution and perception accuracy by calculating the density and uniformity of regions of interest. Experiments show that when using the same number and type of LiDAR, the placement scheme optimized by our proposed method improves the average precision by 15%, compared with the conventional placement scheme in the standard lane scene. We also analyze the correlation between perception performance in the region of interest and LiDAR point cloud distribution and validate that density and uniformity can be indicators of performance. Both the RLS Library and related code will be released at https://github.com/PJLab-ADG/LiDARSimLib-and-Placement-Evaluation. keywords: {Point cloud compression;Measurement;Laser radar;Correlation;Three-dimensional displays;Pipelines;Libraries},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161027&isnumber=10160212

S. Su et al., "Uncertainty Quantification of Collaborative Detection for Self-Driving," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5588-5594, doi: 10.1109/ICRA48891.2023.10160367.Abstract: Sharing information between connected and autonomous vehicles (CAVs) fundamentally improves the performance of collaborative object detection for self-driving. However, CAVs still have uncertainties on object detection due to practical challenges, which will affect the later modules in self-driving such as planning and control. Hence, uncertainty quantification is crucial for safety-critical systems such as CAVs. Our work is the first to estimate the uncertainty of collaborative object detection. We propose a novel uncertainty quantification method, called Double- M Quantification, which tailors a moving block bootstrap (MBB) algorithm with direct modeling of the multivariant Gaussian distribution of each corner of the bounding box. Our method captures both the epistemic uncertainty and aleatoric uncertainty with one inference pass based on the offline Double- M training process. And it can be used with different collaborative object detectors. Through experiments on the comprehensive collaborative perception dataset, we show that our Double-M method achieves more than 4× improvement on uncertainty score and more than 3% accuracy improvement, compared with the state-of-the-art uncertainty quantification methods. Our code is public on https://coperception.github.io/double-m-quantification/. keywords: {Training;Uncertainty;Collaboration;Estimation;Object detection;Detectors;Gaussian distribution},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160367&isnumber=10160212

J. Ai, W. Ding, J. Zhao and J. Zhong, "WS-3D-Lane: Weakly Supervised 3D Lane Detection With 2D Lane Labels," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5595-5601, doi: 10.1109/ICRA48891.2023.10161184.Abstract: Compared to 2D lanes, real 3D lane data is difficult to collect accurately. In this paper, we propose a novel method for training 3D lanes with only 2D lane labels, called weakly supervised 3D lane detection WS-3D-Lane. By assumptions of constant lane width and equal height on adjacent lanes, we indirectly supervise 3D lane heights in the training. To overcome the problem of the dynamic change of the camera pitch during data collection, a camera pitch self-calibration method is proposed. In anchor representation, we propose a double-layer anchor with non-maximum suppression (NMS) method, which enables the anchor-based method to predict two lane lines that are close. Experiments are conducted on the base of 3D-LaneNet under two supervision methods. Under weakly supervised setting, our WS-3D-Lane outperforms previous 3D-LaneN et: F-score rises to 92.3% on Apollo 3D synthetic dataset, and F1 rises to 74.5% on ONCE-3DLanes. Meanwhile, WS-3D-Lane in purely supervised setting makes more increments and outperforms state-of-the-art. To the best of our knowledge, WS-3D- Lane is the first try of 3D lane detection under weakly supervised setting. Our code is available on https://github.com/SAIC-Vision/WS-3D-Lane. keywords: {Training;Solid modeling;Three-dimensional displays;Codes;Automation;Lane detection;Production},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161184&isnumber=10160212

H. Yang, X. Bai, X. Zhu and Y. Ma, "One Training for Multiple Deployments: Polar-based Adaptive BEV Perception for Autonomous Driving," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5602-5609, doi: 10.1109/ICRA48891.2023.10161552.Abstract: Current on-board chips usually have different computing power, which means multiple training processes are needed for adapting the same learning-based algorithm to different chips, costing huge computing resources. The situation becomes even worse for 3D perception methods with large models. Previous vision-centric 3D perception approaches are trained with regular grid-represented feature maps of fixed resolutions, which is not applicable to adapt to other grid scales, limiting wider deployment. In this paper, we leverage the Polar representation when constructing the BEV feature map from images in order to achieve the goal of training once for multiple deployments. Specifically, the feature along rays in Polar space can be easily adaptively sampled and projected to the feature in Cartesian space with arbitrary resolutions. To further improve the adaptation capability, we make multi-scale contextual information interact with each other to enhance the feature representation. Experiments on a large-scale autonomous driving dataset show that our method outperforms others as for the good property of one training for multiple deployments. keywords: {Training;Solid modeling;Adaptation models;Three-dimensional displays;Image resolution;Limiting;Automation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161552&isnumber=10160212

E. Meyer, L. F. Peiss and M. Althoff, "Deep Occupancy-Predictive Representations for Autonomous Driving," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5610-5617, doi: 10.1109/ICRA48891.2023.10160559.Abstract: Manually specifying features that capture the diversity in traffic environments is impractical. Consequently, learning-based agents cannot realize their full potential as neural motion planners for autonomous vehicles. Instead, this work proposes to learn which features are task-relevant. Given its immediate relevance to motion planning, our proposed architecture encodes the probabilistic occupancy map as a proxy for obtaining pre-trained state representations of the environment. By leveraging a map-aware traffic graph formulation, our agent-centric encoder generalizes to arbitrary road networks and traffic situations. We show that our approach significantly improves the downstream performance of a reinforcement learning agent operating in urban traffic environments. keywords: {Automation;Roads;Aggregates;Closed box;Reinforcement learning;Predictive models;Probabilistic logic},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160559&isnumber=10160212

Q. Qiu, H. Gao, W. Hua, G. Huang and X. He, "PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on Transformer," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5618-5624, doi: 10.1109/ICRA48891.2023.10161356.Abstract: Lane detection is one of the fundamental modules in self-driving. In this paper we employ a transformer-only method for lane detection, thus it could benefit from the blooming development of fully vision transformer and achieve the state-of-the-art (SOTA) performance on both CULane and TuSimple benchmarks, by fine-tuning the weight fully pre-trained on large datasets. More importantly, this paper proposes a novel and general framework called PriorLane, which is used to enhance the segmentation performance of the fully vision transformer by introducing the low-cost local prior knowledge. Specifically, PriorLane utilizes an encoder-only transformer to fuse the feature extracted by a pre-trained segmentation model with prior knowledge embeddings. Note that a Knowledge Embedding Alignment (KEA) module is adapted to enhance the fusion performance by aligning the knowledge embedding. Extensive experiments on our Zjlab dataset show that PriorLane outperforms SOTA lane detection methods by a 2.82% mIoU when prior knowledge is employed, and the code will be released at: https://github.com/vincentqqb/PriorLane. keywords: {Image segmentation;Adaptation models;Codes;Automation;Lane detection;Fuses;Benchmark testing;Lane detection;Vision transformer;Prior knowledge;Fusion;Knowledge Alignment},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161356&isnumber=10160212

S. Udatha, Y. Lyu and J. Dolan, "Reinforcement Learning with Probabilistically Safe Control Barrier Functions for Ramp Merging," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5625-5630, doi: 10.1109/ICRA48891.2023.10161418.Abstract: Prior work has looked at applying reinforcement learning (RL) approaches to autonomous driving scenarios, but the safety of the algorithm is often compromised due to instability or the presence of ill-defined reward functions. With the use of control barrier functions embedded into the RL policy, we arrive at safe policies to optimize the performance of the autonomous driving vehicle through the advantage of a safety layer over the RL methods to ease the design of reward functions. However, control barrier functions need a good approximation of the model of the system. We use probabilistic control barrier functions [4] to account for model uncertainty. Our Safety-Assured Policy Optimization - Ramp Merging (SAPO-RM) algorithm is implemented online in the CARLA [1] Simulator and offline on the US I-80 dataset extracted from the NGSIM Database provided by NHTSA [2]. We further test the algorithm and perform ablation studies of it on the US-101 and exi-D datasets to compare the approaches. The proposed algorithm can also be applied to other driving scenarios by changing the reward and safety constraints. keywords: {Uncertainty;Automation;Databases;Merging;Reinforcement learning;Probabilistic logic;Approximation algorithms},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161418&isnumber=10160212

R. Dagdanov, H. Durmus and N. K. Ure, "Self-Improving Safety Performance of Reinforcement Learning Based Driving with Black-Box Verification Algorithms," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5631-5637, doi: 10.1109/ICRA48891.2023.10160883.Abstract: In this work, we propose a self-improving artificial intelligence system to enhance the safety performance of reinforcement learning (RL)-based autonomous driving (AD) agents using black-box verification methods. RL algorithms have become popular in AD applications in recent years. However, the performance of existing RL algorithms heavily depends on the diversity of training scenarios. A lack of safety-critical scenarios during the training phase could result in poor generalization performance in real-world driving applications. We propose a novel framework in which the weaknesses of the training set are explored through black-box verification methods. After discovering AD failure scenarios, the RL agent's training is re-initiated via transfer learning to improve the performance of previously unsafe scenarios. Simulation results demonstrate that our approach efficiently discovers safety failures of action decisions in RL-based adaptive cruise control (ACC) applications and significantly reduces the number of vehicle collisions through iterative applications of our method. The source code is publicly available at https://github.com/data-and-decision-lab/self-improving-RL. keywords: {Training;Source coding;Simulation;Transfer learning;Closed box;Reinforcement learning;Safety;Deep Reinforcement Learning;Autonomous Driving;Black-Box Verification},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160883&isnumber=10160212

J. Yu, H. Oh, S. Fichera, P. Paoletti and S. Luo, "Multi-source Domain Adaptation for Unsupervised Road Defect Segmentation," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5638-5644, doi: 10.1109/ICRA48891.2023.10161099.Abstract: The performance of road defect segmentation (a.k.a. pixel-level road defect detection) has been improved alongside with remarkable achievement of deep learning. Those improvements need a large-scale and well-constructed dataset. However, road surface materials or designs vary from country to country, and the patterns of defects are hard to pre-define. In this paper, we propose a novel multi-source domain adaptation method to boost the performance of road defect segmentation on an unlabelled dataset. The proposed method generates multi-source ensembled labels using transferred information from models trained with multiple labelled source domains, which are utilised as supervisory signals for the unlabelled target domain. Furthermore, to reduce the domain gap between each source domain and a target domain, these domains are re-aligned with outlier repositioning to improve the defect segmentation performance. We demonstrate the effectiveness of our proposed method on Cracktree200, CRACK500, CFD, and Crack360 datasets. Experimental results show that the proposed method outperforms the existing unsupervised road defect segmentation methods and achieves competitive performance compared with recent supervised methods. The source code is publicly available on https://github.com/andreYoo/MSDA_RDS.git. keywords: {Deep learning;Adaptation models;Automation;Roads;Source coding;Transfer learning;Maintenance engineering},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10161099&isnumber=10160212

S. Rudra et al., "A Contextual Bandit Approach for Learning to Plan in Environments with Probabilistic Goal Configurations," 2023 IEEE International Conference on Robotics and Automation (ICRA), London, United Kingdom, 2023, pp. 5645-5652, doi: 10.1109/ICRA48891.2023.10160473.Abstract: Object-goal navigation (Object-nav) entails searching, recognizing and navigating to a target object. Object-nav has been extensively studied by the Embodied-AI community, but most solutions are often restricted to considering static objects (e.g., television, fridge, etc.), We propose a modular framework for object-nav that is able to efficiently search indoor environments for not just static objects but also movable objects (e.g. fruits, glasses, phones, etc.) that frequently change their positions due to human intervention. Our contextual-bandit agent efficiently explores the environment by showing optimism in the face of uncertainty and learns a model of the likelihood of spotting different objects from each navigable location. The likelihoods are used as rewards in a weighted minimum latency solver to deduce a trajectory for the robot. We evaluate our algorithms in two simulated environments and a real-world setting, to demonstrate high sample efficiency and reliability. keywords: {Uncertainty;TV;Navigation;Target recognition;Search problems;Probabilistic logic;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10160473&isnumber=10160212

