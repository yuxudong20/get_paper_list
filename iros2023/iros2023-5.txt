Y. Wang, Y. Wang, Y. Cao and G. Sartoretti, "Spatio-Temporal Attention Network for Persistent Monitoring of Multiple Mobile Targets," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 3903-3910, doi: 10.1109/IROS55552.2023.10341674.Abstract: This work focuses on the persistent monitoring problem, where a set of targets moving based on an unknown model must be monitored by an autonomous mobile robot with a limited sensing range. To keep each target's position estimate as accurate as possible, the robot needs to adaptively plan its path to (re-)visit all the targets and update its belief from measurements collected along the way. In doing so, the main challenge is to strike a balance between exploitation, i.e., re-visiting previously-located targets, and exploration, i.e., finding new targets or re-acquiring lost ones. Encouraged by recent advances in deep reinforcement learning, we introduce an attention-based neural solution to the persistent monitoring problem, where the agent can learn the inter-dependencies between targets, i.e., their spatial and temporal correlations, conditioned on past measurements. This endows the agent with the ability to determine which target, time, and location to attend to across multiple scales, which we show also helps relax the usual limitations of a finite target set with prior positional information. We experimentally demonstrate that our method outperforms other baselines in terms of number of targets visits and average estimation error in complex environments. Finally, we implement and validate our model in a drone-based simulation experiment to monitor mobile ground targets in a high-fidelity simulator. keywords: {Deep learning;Estimation error;Reinforcement learning;Position measurement;Robot sensing systems;Particle measurements;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341674&isnumber=10341342

Y. Kim and J. -H. Kim, "Subtask Aware End-to-End Learning for Visual Room Rearrangement," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 3911-3918, doi: 10.1109/IROS55552.2023.10342320.Abstract: The goal of intelligent embodied agents is to learn how to explore within the environment, interact with objects, and understand the environment in order to achieve task objectives. There are two main approaches to training such agents: one is to train an action policy that performs the task goal through end-to-end learning, and the other is to construct a policy by implementing the necessary abilities according to the task goal in a modular manner. For complex and long-horizon tasks, such as visual room rearrangement, a modular approach that infers task sequence by identifying the causality of actions through prior knowledge shows higher performance. Based on this insight, we propose an Online Subtask Prediction Network (OSPNet) that determines the subtask to be performed at each moment based on the environment information and past subtask inference history to train an embodied agent for long-horizon tasks through an end-to-end manner, and also propose a Subtask Aware Policy Network (SAPNet) as the action policy that decides actions based on the reasoning of the OSPNet. We implement an embodied agent that performs visual room rearrangement using the proposed SAPNet and train it through imitation learning, demonstrating similar or better performance with much fewer training steps than previous works. keywords: {Training;Visualization;Cognition;History;Task analysis;Intelligent robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342320&isnumber=10341342

C. Lin, J. Rhim and A. J. Moon, "Less Than Human: How Different Users of Telepresence Robots Expect Different Social Norms," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 3976-3982, doi: 10.1109/IROS55552.2023.10341962.Abstract: Does the norm of first-come-first-serve (FCFS) equally apply to those piloting a Mobile Remote Presence (MRP) system as to those who are physically present with it? While telepresence robots could make social interactions more accessible and enjoyable for geographically-constrained individuals, such an outcome requires both pilots and local users of MRPs to share the same social norm expectations that govern their use. To address this question, we conducted an online study $(N=903)$ involving simulated human-MRP interaction scenarios. Our results suggest that those remotely piloting the MRP-rather than local users-assign the robot to a lower social priority; they find it more appropriate when local users ignore queue order than when pilots ignore queue order. Furthermore, we provide significant empirical evidence that local users expect different social norms to be upheld depending on how they perceive the robot. Those who perceive MRPs simply as robots-rather than an extension of a person-do not expect the FCFS norm to be respected for MRPs. keywords: {Telepresence;Human-robot interaction;Elevators;Robots;Intelligent robots;Materials requirements planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341962&isnumber=10341342

S. Shin and S. S. Kwak, "Do Hierarchies in a Robot Team Impact the Service Evaluation by Users?," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 3983-3990, doi: 10.1109/IROS55552.2023.10341364.Abstract: Customer satisfaction is not only determined by how workers treat customers but also by how they treat their coworkers. In this sense, we examined whether the dynamics of robot workers influence user satisfaction. To optimize the robot team's atmosphere for Korean culture, we adopted the Korean honorific language system to express hierarchy. We set four types of relationships between two robots: Case 1) both using non honorific language, indicating intimacy and a flat hierarchy; Case 2) both using honorific language, indicating non intimacy and a flat hierarchy; Case 3) delivery robot using non honorific language and monitoring robot using honorific language, indicating non intimacy and a tall hierarchy; Case 4) vice versa. People preferred a robot team with a flat hierarchy and both robots using honorific language, common in the service industry. Interviews revealed discomfort with tall hierarchies. Case 4 was least satisfactory in service, while Case 3 was least socially intelligent. People perceive a robot team mirroring human society as socially intelligent, but negative representations like Case 4 led to less satisfaction. keywords: {Industries;Service robots;Hospitals;Employment;Organizations;Robot sensing systems;Interviews},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341364&isnumber=10341342

L. Grassi, C. T. Recchiuto and A. Sgorbissa, "Robot-Induced Group Conversation Dynamics: A Model to Balance Participation and Unify Communities," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 3991-3997, doi: 10.1109/IROS55552.2023.10342510.Abstract: The purpose of this research is to study the impact of robot participation in group conversations and assess the effectiveness of different addressing policies. The study involved a total of 300 participants, who were divided into groups of four and engaged in a dialogue with a humanoid robot. The robot acted as a moderator, using information obtained during the conversation to determine which speaker to address. The study found that the policy used by the robot significantly impacted the conversation dynamics. Specifically, the robot provided more balanced attention to each participant and reduced the number of subgroups. keywords: {Visualization;Sociology;Social robots;Humanoid robots;Oral communication;Medical services;User experience},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342510&isnumber=10341342

P. Tuttosi, E. Hughson, A. Matsufuji, C. Zhang and A. Lim, "Read the Room: Adapting a Robot's Voice to Ambient and Social Contexts," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 3998-4005, doi: 10.1109/IROS55552.2023.10341925.Abstract: How should a robot speak in a formal, quiet and dark, or a bright, lively and noisy environment? By designing robots to speak in a more social and ambient-appropriate manner we can improve perceived awareness and intelligence for these agents. We describe a process and results toward selecting robot voice styles for perceived social appropriateness and ambiance awareness. Understanding how humans adapt their voices in different acoustic settings can be challenging due to difficulties in voice capture in the wild. Our approach includes 3 steps: (a) Collecting and validating voice data interactions in virtual Zoom ambiances, (b) Exploration and clustering human vocal utterances to identify primary voice styles, and (c) Testing robot voice styles in recreated ambiances using projections, lighting and sound. We focus on food service scenarios as a proof-of-concept setting. We provide results using the Pepper robot's voice with different styles, towards robots that speak in a contextually appropriate and adaptive manner. Our results with N=120 participants provide evidence that the choice of voice style in different ambiances impacted a robot's perceived intelligence in several factors including: social appropriateness, comfort, awareness, human-likeness and competency. keywords: {Lighting;Acoustics;Noise measurement;Robots;Intelligent robots;Testing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341925&isnumber=10341342

S. Zojaji, A. B. Latupeirissa, I. Leite, R. Bresin and C. Peters, "Persuasive Polite Robots in Free-Standing Conversational Groups," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4006-4013, doi: 10.1109/IROS55552.2023.10341830.Abstract: Politeness is at the core of the common set of behavioral norms that regulate human communication and is therefore of significant interest in the design of Human-Robot Interactions. In this paper, we investigate how the politeness behaviors of a humanoid robot impact human decisions about where to join a group of two robots. We also evaluate the resulting impact on the perception of the robot's politeness. In a study involving 59 participants, the main (Pepper) robot in the group invited participants to join using six politeness behaviors derived from Brown and Levinson's politeness theory. It requests participants to join the group at the furthest side of the group which involves more effort to reach than a closer side that is also available to the participant but would ignore the request of the robot. We evaluated the robot's effectiveness in terms of persuasiveness, politeness, and clarity. We found that more direct and explicit politeness strategies derived from the theory have a higher level of success in persuading participants to join at the furthest side of the group. We also evaluated participants' adherence to social norms i.e. not walking through the center, or o-space, of the group when joining it. Our results showed that participants tended to adhere to social norms when joining at the furthest side by not walking through the center of the group of robots, even though they were informed that the robots were fully automated. keywords: {Legged locomotion;Humanoid robots;Human-robot interaction;Behavioral sciences;Robots;Intelligent robots;Social robotics;Politeness;Persuasiveness;Social norms;Human-Robot interaction;free-standing conversational groups},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341830&isnumber=10341342

A. Bacula, E. Villalovoz, D. Flynn, A. Mehta and H. Knight, "Social Triangles and Aggressive Lines: Multi-Robot Formations Impact Navigation and Approach," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4014-4020, doi: 10.1109/IROS55552.2023.10342372.Abstract: Spatial formations can give many social cues, such as illustrating a group of people are having a conversation (social affiliation), or that they are trying to move swiftly through a space (functional goal). This work explored how people perceive varied robots formations while navigating through a space and approaching people. Evaluation occurred across four different geometric formations: wedge, v-shape, vertical line, and horizontal line (Fig 3). Two studies were conducted: the first being an exploratory study of three robots navigating through a public space, and the second being a controlled user study of the same robots approaching humans in different formations. Results showed that triangle shapes were generally received more positively than lines, with wedge being the viewed as harmless, polite, welcoming, and encouraging the human to join the robot group, whereas horizontal line was seen as threatening and unwelcoming. From a path planning perspective, v-shape and wedge were also more robust to controller variance. Results from this work show that formation impacts how people perceive robots, and as a result may impact task success. Future researchers can use these results to inform their behavior design for multi-robot groups to increase task success and desired communication effects. keywords: {Navigation;Shape;Aerospace electronics;Robot sensing systems;Path planning;Behavioral sciences;Security},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342372&isnumber=10341342

E. Nichols, D. Szapiro, Y. Vasylkiv and R. Gomez, "How to Make a Robot Grumpy Teaching Social Robots to Stay in Character with Mood Steering," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4021-4028, doi: 10.1109/IROS55552.2023.10341906.Abstract: Conveying a robot's target mood is crucial to successful social interactions. The robot's expressive performance must be appropriate, persuasive, and consistent. However, this is challenging when interactions contain a mixture of scripted and improvised content, such as those generated by language models. In this paper, we take on the task of teaching robots to stay in character, that is to say, exhibit consistency in mood during interactions. We start by defining a communication strategy module that allows for the top-down specification of a target robot mood for a given task, goal, or context. We then propose a mood steering framework for enforcing robot mood consistency throughout an interaction that supports several target moods. Our framework consists of two components: 1. expressivity steering specifies the speech and behavior to be used by the robot to convey a target mood, and 2. language model steering ensures that improvised language is consistent with the robot's target mood. As a first step toward identifying effective communication strategies, we implement grumpy and cheerful strategies for a collaborative storytelling game and compare them to a neutral baseline. Evaluation in a collaborative storytelling game shows that our approach generates robot behavior that successfully conveys the robot's target mood throughout gameplay and language model steering generates story contributions that capture the target mood without quality degradation and raises important issues for communication strategy design. keywords: {Degradation;Mood;Education;Social robots;Collaboration;Games;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341906&isnumber=10341342

K. Yamada, J. Even and T. Kanda, "Enhancing Teleoperated Robot Customer Service through Speech Monitoring and Filtering," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4029-4036, doi: 10.1109/IROS55552.2023.10342098.Abstract: In this paper, we propose a system that supports operators who provide services to customers using teleoperated robots. We observed that unprofessional or lazy operators of teleoperated robots are a risk for businesses as they are likely to speak in ways that are inappropriate for customer services. The proposed system lets competent operators talk freely to customers and thus provide high quality service. For subpar operators, the proposed system filters inappropriate utterances to improve the service they provide. We conducted a user study with 21 participants to compare the proposed support system to a baseline system where operators talk freely to customers. For subpar operators, the quality of the service is significantly higher in terms of perceived politeness and reported customer satisfaction when using the proposed support system compared to when using the baseline system. For competent operators, we found no significant differences in the quality of the service between the two systems. keywords: {Customer services;Customer satisfaction;Speech enhancement;Behavioral sciences;Research and development;Monitoring;Intelligent robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342098&isnumber=10341342

B. Stoler, M. Jana, S. Hwang and J. Oh, "T2FPV: Dataset and Method for Correcting First-Person View Errors in Pedestrian Trajectory Prediction," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4037-4044, doi: 10.1109/IROS55552.2023.10341874.Abstract: Predicting pedestrian motion is essential for developing socially-aware robots that interact in a crowded environment. While the natural visual perspective for a social interaction setting is an egocentric view, the majority of existing work in trajectory prediction therein has been investigated purely in the top-down trajectory space. To support first-person view trajectory prediction research, we present T2FPV, a method for constructing high-fidelity first-person view (FPV) datasets given a real-world, top-down trajectory dataset; we showcase our approach on the ETH/UCY pedestrian dataset to generate the egocentric visual data of all interacting pedestrians, creating the T2FPV-ETH dataset. In this setting, FPV-specific errors arise due to imperfect detection and tracking, occlusions, and field-of-view (FOV) limitations of the camera. To address these errors, we propose CoFE, a module that further refines the imputation of missing data in an end-to-end manner with trajectory forecasting algorithms. Our method reduces the impact of such FPV errors on downstream prediction performance, decreasing displacement error by more than 10% on average. To facilitate research engagement, we release our T2FPV-ETH dataset and software tools§§https://github.com/cmubig/T2FPV. keywords: {Training;Visualization;Pedestrians;Navigation;Tracking;Software algorithms;Prediction algorithms},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341874&isnumber=10341342

A. Tyshka and W. -Y. G. Louie, "Interactive Task Learning for Social Robots: A Pilot Study," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 1-7, doi: 10.1109/IROS55552.2023.10341713.Abstract: For socially assistive robots to achieve widespread adoption, the ability to learn new tasks in the wild is critical. Learning from Demonstration (LfD) approaches are a popular method for learning in the wild, but current methods require significant amounts of data and can be difficult to interpret. Interactive Task Learning (ITL) is an emerging learning paradigm that aims to teach tasks in a structured manner, minimizing the need for data and increasing transparency. However, to date ITL has only been explored for physical robotics applications. Additionally, minimal research has explored how usable existing ITL systems are for non-expert users. In this work, we propose a novel approach to learn social tasks via ITL. This system utilizes recent advances in Natural Language Understanding (NLU) to learn from natural dialogue. We conducted a pilot study to compare the ITL system against an LfD approach to investigate differences in teaching performance as well as teachers' perceptions of trust and workload towards these systems. Additionally, we analyzed the teaching behavior of participants to identify successful and unsuccessful teaching strategies. Our findings suggest ITL could provide more transparency to users and improve performance by correcting speech recognition errors. However, participants generally preferred LfD and found it an easier teaching method. From the observed teaching behavior, we identify existing challenges in ITL for non-experts to teach social tasks. Using this, we propose areas of improvement toward future ITL learning paradigms that are intuitive, transparent, and performant. keywords: {Education;Social robots;Speech recognition;Assistive robots;Natural language processing;Behavioral sciences;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341713&isnumber=10341342

C. Cathcart, M. Santos, S. Park and N. E. Leonard, "Proactive Opinion-Driven Robot Navigation Around Human Movers," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4052-4058, doi: 10.1109/IROS55552.2023.10341745.Abstract: We propose, analyze, and experimentally verify a new proactive approach for robot social navigation driven by the robot's “opinion” for which way and by how much to pass human movers crossing its path. The robot forms an opinion over time according to nonlinear dynamics that depend on the robot's observations of human movers and its level of attention to these social cues. For these dynamics, it is guaranteed that when the robot's attention is greater than a critical value, deadlock in decision making is broken, and the robot rapidly forms a strong opinion, passing each human mover even if the robot has no bias nor evidence for which way to pass. We enable proactive rapid and reliable social navigation by having the robot grow its attention across the critical value when a human mover approaches. With human-robot experiments we demonstrate the flexibility of our approach and validate our analytical results on deadlock-breaking. We also show that a single design parameter can tune the trade-off between efficiency and reliability in human-robot passing. The new approach has the additional advantage that it does not rely on a predictive model of human behavior. keywords: {Navigation;Decision making;System recovery;Predictive models;Reliability engineering;Nonlinear dynamical systems;Behavioral sciences},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341745&isnumber=10341342

P. Shahverdi, K. Rousso, J. Klotz, I. Bakhoda, M. Zribi and W. -Y. G. Louie, "Emotionally Specific Backchanneling in Social Human-Robot Interaction and Human-Human Interaction," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4059-4064, doi: 10.1109/IROS55552.2023.10341823.Abstract: Backchanneling models, designed to enhance the interactive capabilities of robots, have primarily been trained on human-human interaction data. However, applying such data directly to social robots raises concerns due to dissimilarities in the way humans and robots exhibit verbal and nonverbal behaviors, particularly in the domain of emotional backchannels. This research aims to address this gap by conducting an exploratory study on the differences in human backchanneling behaviors during interactions with humans and social robots in various emotional contexts (e.g., happy and sad). Our findings reveal significant variations in emotionally specific backchannels between human-human and human-robot interactions under different emotional contexts. These results highlight the importance of designing backchanneling models that are tailored for human-robot interactions. keywords: {Social robots;Data models;Behavioral sciences;Intelligent robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341823&isnumber=10341342

M. I. Wu and L. Stirling, "Impact of Imperfect Exoskeleton Algorithms on Step Characteristics, Task Performance, and Perception of Exoskeleton Performance," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4088-4093, doi: 10.1109/IROS55552.2023.10341368.Abstract: Lower-limb exoskeletons may experience errors in operational settings, where an expected assistive torque is missing. These errors may affect user's gait strategies and perception of the exoskeleton's performance, leading to impacted human-exoskeleton fluency and user trust in the system. In this study, we introduced five different exoskeleton control algorithms with fixed error rates up to 10% error (90% accuracy). Two groups of participants (N=22, 11 per group) walked with a bilateral ankle exoskeleton while completing a targeted stepping task and experienced each controller twice, but in different orders. The impact of exoskeleton error rates was assessed on step characteristics (step length and width), task performance (absolute task error), and perception of exoskeleton performance (survey responses). Step character-istics were not impacted by exoskeleton errors, but multiple participants were not able to achieve acceptable task accuracy and increased task error over time across all error rates. Increasing error rates negatively impacted users' perception of algorithm predictability, exoskeleton supportiveness, and probability of future usage. Perceived predictability and future usage probability transitioned from positive to negative between 2% and 5% error. Understanding the effect of increasing exoskeleton error rates informs minimum algorithm accuracy to support human-exoskeleton fluency and performance for gait-assist exoskeletons. keywords: {Surveys;Torque;Error analysis;System performance;Exoskeletons;Prediction algorithms;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341368&isnumber=10341342

L. Wang et al., "Can Quadruped Guide Robots be Used as Guide Dogs?," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4094-4100, doi: 10.1109/IROS55552.2023.10341792.Abstract: Quadruped robots have the potential to guide blind and low vision (BLV) people due to their highly flexible locomotion and emotional value provided by their bionic forms. However, the development of quadruped guide robots rarely involves BLV users' participatory designs and evaluations. In this paper, we conducted two empirical experiments both in indoor controlled and outdoor field scenarios, exploring the benefits and drawbacks of quadruped guide robots. The results show that the nowadays commercial quadruped robots exposed significant disadvantages in usability and trust compared with wheeled robots. It is concluded that the moving gait and walking noise of quadruped robots would limit the guiding effectiveness to a certain extent, and the empathetic effect of its bionic form for BLV users could not be fully reflected. Based on the findings of wheeled robots and quadruped robots' advantages, we discuss the design implications for the future guide robot design for BLV users. This paper reports the first empirical experiment about quadruped guide robots with BLV users and preliminary explores their potential improvement space in substituting guide dogs, which can inspire the further specialized design of quadruped guide robots. keywords: {Legged locomotion;Navigation;Dogs;Market research;Biology;Quadrupedal robots;Usability},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341792&isnumber=10341342

J. Lee, T. Lim and W. Kim, "Investigating the Usability of Collaborative Robot Control Through Hands-Free Operation Using Eye Gaze and Augmented Reality," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4101-4106, doi: 10.1109/IROS55552.2023.10342045.Abstract: This paper proposes a novel operation for controlling a mobile robot using a head-mounted device. Conventionally, robots are operated using computers or a joystick, which creates limitations in usability and flexibility because control equipment has to be carried by hand. This lack of flexibility may prevent workers from multitasking or carrying objects while operating the robot. To address this limitation, we propose a hands-free method to operate the mobile robot with a human gaze in an Augmented Reality (AR) environment. The proposed work is demonstrated using the HoloLens 2 to control the mobile robot, Robotnik Summit-XL, through the eye-gaze in AR. Stable speed control and navigation of the mobile robot were achieved through admittance control which was calculated using the gaze position. The experiment was conducted to compare the usability between the joystick and the proposed operation, and the results were validated through surveys (i.e., SUS, SEQ). The survey results from the participants after the experiments showed that the wearer of the HoloLens accurately operated the mobile robot in a collaborative manner. The results for both the joystick and the HoloLens were marked as easy to use with above-average usability. This suggests that the HoloLens can be used as a replacement for the joystick to allow hands-free robot operation and has the potential to increase the efficiency of human-robot collaboration in situations when hands-free controls are needed. keywords: {Surveys;Velocity control;Robot control;Collaboration;Trajectory;Mobile robots;Synchronization},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342045&isnumber=10341342

S. Balali et al., "Development and Evaluation of Exploratory Experiences to Facilitate Reasoning About Robotic Systems," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4107-4114, doi: 10.1109/IROS55552.2023.10342409.Abstract: This paper introduces a novel interactive approach —Exploratory Experiences— that aims to improve the ability of people to reason about the capabilities and limitations of robotic technology. We focus on two areas: robot navigation and object detection. We evaluate the Exploratory Experiences with a novel approach that measures the participant's ability to predict when the robot will fail, following up with asking the reason and a possible fix. We show that our approach is effective at improving participants' understanding of potential robot navigation failures and that they already have the skills to detect potential object detection failures when presented with the correct stimuli. keywords: {Navigation;Atmospheric measurements;Object detection;Particle measurements;Cognition;Intelligent robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342409&isnumber=10341342

C. D. Guerrero-Méndez, C. F. Blanco-Díaz, A. Lopez-Delis, T. Bastos-Filho and R. M. Andrade, "Decoding sEMG Under Non-Ideal Conditions Toward Robust Muscle-Machine Interface Control," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4115-4120, doi: 10.1109/IROS55552.2023.10341503.Abstract: The evaluation of systems under non-ideal conditions is a research problem, particularly in robotic applications for the rehabilitation of people with disabilities. Accordingly, the evaluation of algorithmic strategies for robustness validation under different non-ideal conditions is a current challenge for the scientific community. Therefore, in this study, a computational methodology based on Extreme Learning Machine (ELM) was evaluated for the recognition of seven hand gestures using sEMG under five non-ideal conditions. The shift of eight sEMG electrodes, three upper-limb postures, increased muscle fatigue, and inter-subject and inter-day variabilities were evaluated. The results indicate that the proposed methodology performs well under specific conditions in comparison with previous strategies reported in the literature using Machine Learning classifiers. Therefore, the findings of this study are potentially important for the field of robotics; however, more efforts are still needed to develop more robust computational methods to obtain higher accuracy under non-ideal conditions, with the aim of implementing more controllable, usable, and reliable systems. keywords: {Machine learning algorithms;Extreme learning machines;Scholarships;Finance;Machine learning;Muscles;Fatigue},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341503&isnumber=10341342

H. Yu, R. M. Aronson, K. H. Allen and E. S. Short, "From “Thumbs Up” to “10 out of 10”: Reconsidering Scalar Feedback in Interactive Reinforcement Learning," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4121-4128, doi: 10.1109/IROS55552.2023.10342458.Abstract: Learning from human feedback is an effective way to improve robotic learning in exploration-heavy tasks. Compared to the wide application of binary human feedback, scalar human feedback has been used less because it is believed to be noisy and unstable. In this paper, we compare scalar and binary feedback, and demonstrate that scalar feedback benefits learning when properly handled. We collected binary or scalar feedback respectively from two groups of crowdworkers on a robot task. We found that when considering how consistently a participant labeled the same data, scalar feedback led to less consistency than binary feedback; however, the difference vanishes if small mismatches are allowed. Additionally, scalar and binary feedback show no significant differences in their correlations with key Reinforcement Learning targets. We then introduce Stabilizing TEacher Assessment DYnamics (STEADY) to improve learning from scalar feedback. Based on the idea that scalar feedback is muti-distributional, STEADY reconstructs underlying positive and negative feedback distributions and re-scales scalar feedback based on feedback statistics. We show that models trained with scalar feedback + STEADY outperform baselines, including binary feedback and raw scalar feedback, in a robot reaching task with non-expert human feedback. Our results show that both binary feedback and scalar feedback are dynamic, and scalar feedback is a promising signal for use in interactive Reinforcement Learning. keywords: {Negative feedback;Heuristic algorithms;Education;Thumb;Human-robot interaction;Reinforcement learning;Noise measurement},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342458&isnumber=10341342

B. Tout, J. Chevrie, A. Dequidt and L. Vermeiren, "Towards Continuous Identification of Passive Human Joint Impedance Using Physical Human-Robot Interaction System," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4129-4134, doi: 10.1109/IROS55552.2023.10341372.Abstract: The identification of human joint impedance is necessary for various applications, such as improving rehabilitation efficiency or monitoring the human operator's state (fatigue, stress). To this end, in this paper we combine robot's payload identification methods with sliding window recursive least squares algorithm allowing a continuous identification of the varying human joint model without the need for external sensors. We also propose a threshold for detecting fake changes in the identified model parameters due to numerical issues. The presented approach is validated by simulations and experiments using elastic rubber bands representing a simplified passive human joint model attached to a one degree of freedom robotic system. Comparison with simple recursive least squares shows that the proposed method is promising, as it converges to the new parameter in a single window length, whereas the other method takes much longer. In addition, it distinguishes real from fake changes depending on the validity of the used model. keywords: {Robot sensing systems;Numerical models;Sensors;Impedance;Rubber;Object recognition;Stress},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341372&isnumber=10341342

S. Oliver, P. Paik, X. Zhou and S. F. Atashzar, "The MyoPassivity Puzzle: How Does Muscle Fatigue Affect Energetic Behavior of the Human Upper-Limb During Physical Interaction with Robots?," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4135-4140, doi: 10.1109/IROS55552.2023.10341902.Abstract: The human limb possesses a remarkable capacity to absorb energy during physical human-robot interaction (pHRI), which can be quantified as the biomechanical “Excess of Passivity” (EoP) using non-linear control theory. This biome-chanical passivity index can be used to reduce conservatism and increase the transparency of pHRI stabilizers. Previous work on EoP has used system identification techniques to compute EoP offline. However, for use in real-time controllers, an instantaneous method for EoP estimation would be desired. This paper hypothesizes that muscle fatigue can potentially be a complicating factor which can cumulatively affect the ability of human biomechanics to absorb mechanical energy over time during physical interaction with robots. In this work, we focused on the energetic behavior of the human wrist during pHRI, and, for the first time, we investigated the effect of fatigue on EoP. The EoP for five participants was computed throughout one hundred-second trials of high-frequency wrist perturbations in four directions. Subjects maintained a stiff and consistent grip throughout each trial, causing an accumulation of fatigue in the forearm muscles. Muscle activity was recorded using an array of sixteen sEMG sensors. It was found that the EoP degraded (in a statistically significant manner) with increased muscle fatigue in all directions, even when the level of muscle co-contraction was controlled consistently through a visual myofeedback mechanism. 100% of the subjects exhibited this decline in energy absorption capacity in all directions studied. The median drop in EoP after one-hundred seconds of perturbation was 11% for trials in the abduction and adduction directions and 22% in the pronation and supination directions. These results indicate a need for more robust estimation methods or new modalities to account for muscle fatigue in the control architectures of physical human-robot interaction. keywords: {Wrist;Absorption;Perturbation methods;Estimation;Human-robot interaction;Muscles;Fatigue},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341902&isnumber=10341342

X. Zhou, P. Paik and S. F. Atashzar, "Harnessing the Power of Human Biomechanics in Force-Position Domain: A 3D Passivity Index Map for Upper Limb Physical Human-(Tele) Robot Interaction," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4141-4146, doi: 10.1109/IROS55552.2023.10341393.Abstract: In the context of physical human-(tele)robot interaction, passivity-based stabilizers have been used to guarantee the physical or (tele) physical stability. In most of these examples, human biomechanics is considered an inherently passive system that dissipates energy. This assumption may not hold true when the interaction is implemented in the force-position domain, even though such a setting would be needed to boost positional accuracy and avoid the common kinematic drifts in the force-velocity domains. The aforementioned topic is examined in this paper using the concept of shortage versus excess of passivity index for human biomechanics in the force-position domain. We also investigate the compounding effect of the frequency of interaction. The outcomes of this paper will be imperative for the design of force-position domain pURI stabilizers when the classical assumption of passivity of human biomechanics can lead to serious safety issues. In this work, for the first time, we quantitatively present the passivity margin and, thus, the energetic behavior of the human arm's biomechanics under various interaction scenarios in the Force-Position domain. The outcome of this work includes a three-dimensional passivity index map (3DPiM) that is validated on five healthy participants. The goal is to illustrate the passivity margin of the human upper limb biomechanics for two distinct levels of muscle co-contractions, as indicated by the Electromyography (EMG) signal, across four interaction frequencies and eight geometric directions. This outcome enables the future development of biomechanics-aware stabilizers in the force-position domain, quantifying the passivity margin in real-time and thus significantly reducing the stabilizer's conservatism while ensuring the safety of human-robot interactions. keywords: {Biomechanics;Three-dimensional displays;Frequency-domain analysis;Stability criteria;Muscles;Rendering (computer graphics);Electromyography},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341393&isnumber=10341342

P. M. Riek and A. R. Wu, "No Contact Needed: Humans Adapt Their Gait to Suit Legged Robot Companions," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4147-4152, doi: 10.1109/IROS55552.2023.10341255.Abstract: Legged robots companions may one day assist humans with everyday tasks, but their possible impact on human gait is unknown. While previous studies have shown that humans adjust their gait when walking with other humans, it is uncertain whether walking with legged robots would yield similar results. In this study, we measured the gait of healthy participants (N = 14) while they walked alone and with a small quadruped robot. Spatiotemporal and stability gait parameters were calculated to determine whether the presence of the robot affected participants' gait. We found that walking with robots primarily affected measures in the walking direction. Participants walked slower and with altered anterior-posterior stability with the robot, but we did not find significant differences in the mediolateral direction in terms of step width or stability. However, we also observed that variability in the mediolateral distance between the robot and our participants also influenced participant gait behaviour. Our results demonstrate that robots do influence human gait even without physical contact and through seemingly innocuous actions such as walking near them. keywords: {Legged locomotion;Atmospheric measurements;Particle measurements;Spatiotemporal phenomena;Quadrupedal robots;Task analysis;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341255&isnumber=10341342

G. -E. Cha, W. Jo and B. -C. Min, "Implications of Personality on Cognitive Workload, Affect, and Task Performance in Remote Robot Control," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4153-4160, doi: 10.1109/IROS55552.2023.10341633.Abstract: This paper explores how the personality traits of robot operators can influence their task performance during remote control of robots. It is essential to explore the impact of personal dispositions on information processing, both directly and indirectly, when working with robots on specific tasks. To investigate this relationship, we utilize the open-access multi-modal dataset MOCAS to examine the robot operator's personality traits, affect, cognitive load, and task performance. Our objective is to confirm if personality traits have a total effect, including both direct and indirect effects, that could significantly impact the performance levels of operators. Specifically, we examine the relationship between personality traits such as extroversion, conscientiousness, and agreeableness, and task performance. We conduct a correlation analysis between cognitive load, self-ratings of workload and affect, and quantified individual personality traits along with their experimental scores. The findings show that personality traits do not have a total effect on task performance. A supplementary video can be accessed at: https://youtu.be/h3XUtVn7nzg. keywords: {Correlation;Robot control;Information processing;Cognitive load;Task analysis;Remote control;Intelligent robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341633&isnumber=10341342

L. Keselman, K. Shih, M. Hebert and A. Steinfeld, "Optimizing Algorithms from Pairwise User Preferences," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4161-4167, doi: 10.1109/IROS55552.2023.10342081.Abstract: Typical black-box optimization approaches in robotics focus on learning from metric scores. However, that is not always possible, as not all developers have ground truth available. Learning appropriate robot behavior in human-centric contexts often requires querying users, who typically cannot provide precise metric scores. Existing approaches leverage human feedback in an attempt to model an implicit reward function; however, this reward may be difficult or impossible to effectively capture. In this work, we introduce SortCMA to optimize algorithm parameter configurations in high dimensions based on pairwise user preferences. SortCMA efficiently and robustly leverages user input to find parameter sets without directly modeling a reward. We apply this method to tuning a commercial depth sensor without ground truth, and to robot social navigation, which involves highly complex preferences over robot behavior. We show that our method succeeds in optimizing for the user's goals and perform a user study to evaluate social navigation results. keywords: {Measurement;Navigation;Closed box;Robot sensing systems;Robustness;Behavioral sciences;Tuning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342081&isnumber=10341342

N. D. Rawal, R. L. Medrano, G. C. Thomas and E. J. Rouse, "A Sensitivity Analysis of an Economic Value Metric for Quantifying the Success of Lower-Limb Exoskeletons and Their Assistance," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4168-4175, doi: 10.1109/IROS55552.2023.10342452.Abstract: Modern exoskeletons are typically developed to optimize for a single, physiological objective, the “gold standard” of which is a reduction of the wearer's metabolic rate. However, recent research suggests that these changes in metabolic rate are not yet perceivable on average. To address this gap, this study explores a novel economic value metric to quantify the value of exoskeleton assistance. The overarching goal of this work is the development of a perceptible metric that leverages the user experience to quantify exoskeleton success. We use the Vickrey second-price auction to obtain the monetary compensation needed for participants to continue walking for consecutive two-minute bouts. Comparing the participant's bidding trends when wearing and not wearing an exoskeleton captures the economic value of the experience, termed Marginal Value (MV). To reduce the logistical burden of the auction, we simulated human participants (robo-bidders) to compete alongside real participants. This work presents a sensitivity analysis to understand how the number and bidding behavior of the robo-bidders affects our economic value metric, MV. We found that MV was not significantly affected by the number of robo-bidders or their bidding behavior (i.e. effort rate). The bidding behavior of the human participants was affected by the robo-bidder effort rate, indicating that there is interplay in the bidding dynamics among the auction participants, but these changes do not significantly affect the marginal value. This study tentatively validates the current approach in generating our proposed metric for exoskeleton success, paving the way for economic value to be further explored as a holistic, personalized metric for the development of lower-limb exoskeletons. keywords: {Measurement;Economics;Legged locomotion;Sensitivity analysis;Exoskeletons;Market research;User experience},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342452&isnumber=10341342

T. Li, F. Xie, Q. Qiu and Q. Feng, "Multi-Arm Robot Task Planning for Fruit Harvesting Using Multi-Agent Reinforcement Learning," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4176-4183, doi: 10.1109/IROS55552.2023.10341822.Abstract: The emergence of harvesting robotics offers a promising solution to the issue of limited agricultural labor resources and the increasing demand for fruits. Despite notable advancements in the field of harvesting robotics, the utilization of such technology in orchards is still limited. The key challenge for harvesting robots is to improve the operational efficiency. Taking into account inner-arm conflicts, couplings of DoFs, and the dynamic tasks, we propose a task planning strategy for a harvesting robot with four arms in this paper. The proposed method employs a Markov game framework to formulate the four-arm robotic harvesting task, which avoids the computational complexity of solving an NP-hard scheduling problem. Furthermore, a multi-agent reinforcement learning (MARL) structure with a fully centralized collaboration protocol is used to train a MARL-based task planning network. Several simulations and orchard experiments are conducted to validate the effectiveness of the proposed method for a multi-arm harvesting robot in comparison with the existing method. keywords: {Protocols;Processor scheduling;Reinforcement learning;Markov processes;Manipulators;Planning;Labor resources},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341822&isnumber=10341342

R. Dorosh et al., "Design, Modeling, and Control of a Low-Cost and Rapid Response Soft-Growing Manipulator for Orchard Operations," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4184-4190, doi: 10.1109/IROS55552.2023.10341507.Abstract: Tree fruit growers around the world are facing labor shortages for critical operations, including harvest and pruning. There is a great interest in developing robotic solutions for these labor-intensive tasks, but current efforts have been prohibitively costly, slow, or require a reconfiguration of the orchard in order to function. In this paper, we introduce an alternative approach to robotics using a novel and low-cost soft-growing robotic platform. Our platform features the ability to extend up to 1.2 m linearly at a maximum speed of 0.27 m/s. The soft-growing robotic arm can operate with a terminal payload of up to 1.4 kg (4.4 N), more than sufficient for carrying an apple. This platform decouples linear and steering motions to simplify path planning and the controller design for targeting. We anticipate our platform being relatively simple to maintain compared to rigid robotic arms. Herein we also describe and experimentally verify the platform's kinematic model, including the prediction of the relationship between the steering angle and the angular positions of the three steering motors. Information from the model enables the position controller to guide the end effector to the targeted positions faster and with higher stability than without this information. Overall, our research show promise for using soft-growing robotic platforms in orchard operations. keywords: {Vibrations;Robot kinematics;Kinematics;Bending;End effectors;Steady-state;Feedforward systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341507&isnumber=10341342

H. Zhang, Y. Ma, X. Wang, R. Mao and M. Wang, "Lightweight Real-Time Detection Model for Multi-Sheep Abnormal Behaviour Based on Yolov7-Tiny," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4191-4196, doi: 10.1109/IROS55552.2023.10342186.Abstract: Animal behaviour can reflect the health and physiological stage of the animal. Animal behaviour recognition is a vital part of automated farming systems. Although image-based deep learning algorithms can accurately identify animal behaviour, the lack of data on animal abnormal behaviour makes the practical deployment of models of limited significance. At the same time, the ageing of farm monitoring equipment is also a key factor hindering automated farming. This paper constructs a sheep abnormal behaviour dataset ABSB to address these issues and proposes a lightweight real-time multi-sheep abnormal behaviour detection model YOLOv7-Lrab based on the YOLOv7-tiny network. The abnormal behaviour dataset includes four normal behaviours: standing, lying, eating and drinking, and three abnormal behaviours: lameness, attack and death. In the proposed YOLOv7-Lrab model, the small target detection layer, Coordinate attention module, SPD-Conv and Mobileone module are added compared to YOLOv7-tiny. The experimental results show that with a 7:3 ratio of training data to test data, 96.5% recognition accuracy and 95.5% recall can be achieved, and the model size is only 4.5MB with fps of 156. The model is compressed to a minimum without loss of accuracy, providing a new idea for deploying deep learning model in practical application scenarios. keywords: {Deep learning;Animals;Target recognition;Training data;Object detection;Real-time systems;Data models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342186&isnumber=10341342

R. Menon, T. Zaenker, N. Dengler and M. Bennewitz, "NBV-SC: Next Best View Planning Based on Shape Completion for Fruit Mapping and Reconstruction," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4197-4203, doi: 10.1109/IROS55552.2023.10341855.Abstract: Active perception for fruit mapping and harvesting is a difficult task since occlusions occur frequently and the location as well as size of fruits change over time. State-of-the-art viewpoint planning approaches utilize computationally expensive ray casting operations to find good viewpoints aiming at maximizing information gain and covering the fruits in the scene. In this paper, we present a novel viewpoint planning approach that explicitly uses information about the predicted fruit shapes to compute targeted viewpoints that observe as yet unobserved parts of the fruits. Furthermore, we formulate the concept of viewpoint dissimilarity to reduce the sampling space for more efficient selection of useful, dissimilar viewpoints. Our simulation experiments with a UR5e arm equipped with an RGB-D sensor provide a quantitative demonstration of the efficacy of our iterative next best view planning method based on shape completion. In comparative experiments with a state-of-the-art viewpoint planner, we demonstrate improvement not only in the estimation of the fruit sizes, but also in their reconstruction, while significantly reducing the planning time. Finally, we show the viability of our approach for mapping sweet pepper plants with a real robotic system in a commercial glasshouse. keywords: {Casting;Shape;Estimation;Active perception;Robot sensing systems;Planning;Iterative methods},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341855&isnumber=10341342

M. Li, M. Hasltead and C. McCool, "Knowledge Distillation for Efficient Panoptic Semantic Segmentation: Applied to Agriculture," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4204-4211, doi: 10.1109/IROS55552.2023.10342527.Abstract: Panoptic segmentation provides both holistic and detailed image parsing information at both the pixel and the instance level. However, the computational burdens restrict its applications in real-time scenarios. A potential approach to learn more efficient models is to employ knowledge distillation. However, previous knowledge distillation schemes have focused mainly on classification with limited attention given to rearession-related tasks which is key for panoptic segmentation. In this paper, we establish a logits-based, a hints-based, and a combination-based scheme for panoptic knowledge distillation by using logits from the final layers and features in the middle layers. Then we explore different combinations of balancing weights for optimal solutions according to different network structures and datasets. To validate our proposed approach, various experiments on different datasets have been conducted and efficient networks with higher performance have been obtained. We show that knowledge distillation can be applied to develop accurate ResNet-34 networks improving their panoptic quality on things by an absolute amount of 4.1 points for sweet pepper (glasshouse environment) and 2.2 points for sugar beet (arable farming environment). These student ResNet-34 networks are able to run inference at faster than a framerate of 53Hz on computing infrastructure similar to PATHoBot (a glasshouse robot). To the best of our knowledge, this is the first work to propose knowledge distillation schemes for panoptic semantic segmentation. keywords: {Knowledge engineering;Computer vision;Semantic segmentation;Computational modeling;Agriculture;Sugar industry;Real-time systems;Computer Vision for Agriculture Automation;Knowledge Distillation;Efficient Panoptic Segmentation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342527&isnumber=10341342

L. Lobefaro, M. V. R. Malladi, O. Vysotska, T. Guadagnino and C. Stachniss, "Estimating 4D Data Associations Towards Spatial-Temporal Mapping of Growing Plants for Agricultural Robots," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4212-4218, doi: 10.1109/IROS55552.2023.10342449.Abstract: Our world is non-static, and robots should be able to track its changing geometry. For tracking changes, data asso-ciations between 3D points over time are key. In this paper, we investigate the problem of associating 3D points on plant organs from different mapping runs over time while the plants grow. We achieve a high spatial-temporal matching performance by combining 3D RGB-D SLAM, visual place recognition, and 2D/3D matching exploiting background knowledge. We showcase our approach in a real agricultural glasshouse used to grow sweet peppers, using RGB-D observations from a mobile robot traversing the environment. Our experiments suggest that with our approach, we can robustly make data associations in highly repetitive scenes and under changing geometries caused by plant growth. We see our approach as an important step towards spatial-temporal data association for robotic agriculture. keywords: {Geometry;Point cloud compression;Visualization;Three-dimensional displays;Simultaneous localization and mapping;Shape;Plants (biology)},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342449&isnumber=10341342

T. Zaenker, J. Rückin, R. Menon, M. Popović and M. Bennewitz, "Graph-Based View Motion Planning for Fruit Detection," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4219-4225, doi: 10.1109/IROS55552.2023.10342532.Abstract: Crop monitoring is crucial for maximizing agricultural productivity and efficiency. However, monitoring large and complex structures such as sweet pepper plants presents significant challenges, especially due to frequent occlusions of the fruits. Traditional next-best view planning can lead to unstructured and inefficient coverage of the crops. To address this, we propose a novel view motion planner that builds a graph network of viable view poses and trajectories between nearby poses, thereby considering robot motion constraints. The planner searches the graphs for view sequences with the highest accumulated information gain, allowing for efficient pepper plant monitoring while minimizing occlusions. The generated view poses aim at both sufficiently covering already detected and discovering new fruits. The graph and the corresponding best view pose sequence are computed with a limited horizon and are adaptively updated in fixed time intervals as the system gathers new information. We demonstrate the effectiveness of our approach through simulated and real-world experiments using a robotic arm equipped with an RGB-D camera and mounted on a trolley. As the experimental results show, our planner produces view pose sequences to systematically cover the crops and leads to increased fruit coverage when given a limited time in comparison to a state-of-the-art single next-best view planner. keywords: {Robot motion;Productivity;Motion segmentation;Robot vision systems;Crops;Manipulators;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342532&isnumber=10341342

Y. Pan et al., "Panoptic Mapping with Fruit Completion and Pose Estimation for Horticultural Robots," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4226-4233, doi: 10.1109/IROS55552.2023.10342067.Abstract: Monitoring plants and fruits at high resolution play a key role in the future of agriculture. Accurate 3D information can pave the way to a diverse number of robotic applications in agriculture ranging from autonomous harvesting to precise yield estimation. Obtaining such 3D information is non-trivial as agricultural environments are often repetitive and cluttered, and one has to account for the partial observability of fruit and plants. In this paper, we address the problem of jointly estimating complete 3D shapes of fruit and their pose in a 3D multi-resolution map built by a mobile robot. To this end, we propose an online multi-resolution panoptic mapping system where regions of interest are represented with a higher resolution. We exploit data to learn a general fruit shape representation that we use at inference time together with an occlusion-aware differentiable rendering pipeline to complete partial fruit observations and estimate the 7 DoF pose of each fruit in the map. The experiments presented in this paper, evaluated both in the controlled environment and in a commercial greenhouse, show that our novel algorithm yields higher completion and pose estimation accuracy than existing methods, with an improvement of 41 % in completion accuracy and 52 % in pose estimation accuracy while keeping a low inference time of 0.6 s in average. keywords: {Three-dimensional displays;Shape;Plants (biology);Pose estimation;Pipelines;Green products;Rendering (computer graphics)},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342067&isnumber=10341342

E. Liu, J. Monica, K. Gold, L. Cadle-Davidson, D. Combs and Y. Jiang, "Vision-Based Vineyard Navigation Solution with Automatic Annotation," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4234-4241, doi: 10.1109/IROS55552.2023.10341261.Abstract: Autonomous navigation is crucial for achieving the full automation of agricultural research and production management using agricultural robots. In this paper, we present a vision-based autonomous navigation approach for agriculture robots in trellised cropping systems, which stands out for its remarkable performance achieved entirely without human annotation. We propose a novel learning-based method that directly estimates the path traversibility heatmap from an RGB-D image and subsequently converts it into a preferred traversal path. One key advantage of our approach lies in its capability to predict the robot's preferred path directly, allowing us to obtain training labels without manual annotation. Specifically, we propose an automatic annotation pipeline that leverages the robot's path recorded during data collection. Furthermore, we develop a full navigation framework by integrating our path detection model with row switching modules, enabling the robot to smoothly transition between crop rows within the vineyard. We conduct extensive field trials in three different vineyards to validate the performance of our autonomous navigation framework. The results demonstrate that our approach provides a cost-effective, accurate, and robust solution for vineyard navigation. keywords: {Heating systems;Training;Production management;Annotations;Navigation;Pipelines;Switches},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341261&isnumber=10341342

Y. Karabatis, X. Lin, N. J. Sanket, M. G. Lagoudakis and Y. Aloimonos, "Detecting Olives with Synthetic or Real Data? Olive the Above," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4242-4249, doi: 10.1109/IROS55552.2023.10341765.Abstract: Modern robotics has enabled the advancement in yield estimation for precision agriculture. However, when applied to the olive industry, the high variation of olive colors and their similarity to the background leaf canopy presents a challenge. Labeling several thousands of very dense olive grove images for segmentation is a labor-intensive task. This paper presents a novel approach to detecting olives without the need to manually label data. In this work, we present the world's first olive detection dataset comprised of synthetic and real olive tree images. This is accomplished by generating an auto-labeled photorealistic 3D model of an olive tree. Its geometry is then simplified for lightweight rendering purposes. In addition, experiments are conducted with a mix of synthetically generated and real images, yielding an improvement of up to 66% compared to when only using a small sample of real data. When access to real, human-labeled data is limited, a combination of mostly synthetic data and a small amount of real data can enhance olive detection. keywords: {Industries;Solid modeling;Three-dimensional displays;Service robots;Rendering (computer graphics);Yield estimation;Labeling},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341765&isnumber=10341342

B. Walt and G. Krishnan, "Grasp State Classification in Agricultural Manipulation," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4250-4255, doi: 10.1109/IROS55552.2023.10341881.Abstract: The agricultural setting poses additional challenges for robotic manipulation, as fruit is firmly attached to plants and the environment is cluttered and occluded. Therefore, accurate feedback about the grasp state is essential for effective harvesting. This study examines the different states involved in fruit picking by a robot, such as successful grasp, slip, and failed grasp, and develops a learning-based classifier using low-cost, computationally light sensors (IMU and IR reflectance). The Random Forest multi-class classifier accurately determines the current state and along with the sensors can operate in the occluded environment of a plant. The classifier was successfully trained and tested in the lab and showed 100% success at identifying slip and grasp failure and 80% success identifying successful picks on a real cherry tomato plant. By using this classifier, corrective actions can be planned based on the current state, thus leading to more efficient fruit harvesting. keywords: {Reflectivity;Plants (biology);Robot sensing systems;Agriculture;Sensors;Research initiatives;Artificial intelligence},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341881&isnumber=10341342

D. P. Banuelos, R. Falque, T. Patten and A. Alempijevic, "Skirting Line Estimation Using Sparse to Dense Deformation," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4256-4262, doi: 10.1109/IROS55552.2023.10342451.Abstract: Automating the process of fleece contaminant removal has the potential to drastically improve the quality of wool leaving the farm gate. Towards this goal, we present a method to automatically extract skirting lines, i.e., the separations between clean and contaminated wool of a fleece using RGB images. We propose a learning-based sparse-to-dense approach for estimating the non-rigid deformation of fleeces in order to estimate the skirting lines. Our method is bootstrapped from a set of sparse inlier feature correspon-dences, which are heavily filtered through a set of strict criteria. The inlier correspondences are then greedily expanded by adding correspondences from a denser set through a filtering process. This process is based on a learning approach that takes as inputs the pixel similarity and the consistency with their inlier neighbours. Each greedy iteration is initialised with a non-rigid deformation using as-rigid-as-possible as a prior to the filtering process. The proposed method outperforms both a rigid deformation baseline and optic flow deep learning approach, as evidenced by the quantitative evaluation of pixel location error in controlled experiments. To further prove its practicality, we demonstrate qualitative results comparing the predicted skirting line from various methods on images of skirted fleeces collected from several wool sheds. keywords: {Optical filters;Deep learning;Deformation;Filtering;Estimation;Logic gates;Feature extraction},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342451&isnumber=10341342

G. Lu, "Bird-View 3D Reconstruction for Crops with Repeated Textures," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4263-4270, doi: 10.1109/IROS55552.2023.10341478.Abstract: Large-scale in-situ 3D reconstruction of crop fields presents a challenging task, as the 3D crop structures play a crucial role in plant phenotyping and significantly influence crop growth and yield. While existing efforts focus on close-range plants, only a limited number of deep learning-based methods have been developed explicitly for large-scale 3D crop reconstruction, mainly due to the scarcity of large-scale crop sensing data. In this paper, we leverage unmanned aerial vehicles (UAVs) in agriculture and utilize a recently captured multi-view real-world snap beans crop dataset to develop an unsupervised structure-from-motion (SfM) framework. Our framework is designed specifically for reconstructing large-scale 3D crop structures. It addresses the challenge of inaccurate depth inference caused by excessively repeated patterns in the crop dataset, resulting in highly accurate 3D crop reconstruction for large-scale scenarios. Through experiments conducted on the crop dataset, we demonstrate the accuracy and robustness of our 3D crop reconstruction algorithm. The application of our proposed framework has the potential to advance research in agriculture, enabling better plant phenotyping and understanding of crop growth and yield. keywords: {Three-dimensional displays;Neural networks;Crops;Robot sensing systems;Agriculture;Robustness;Sensors},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341478&isnumber=10341342

D. Xing, Y. Yang, Z. Wang, J. Li and B. Xu, "Generalized Robot Dynamics Learning and Gen2Real Transfer," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4279-4284, doi: 10.1109/IROS55552.2023.10342406.Abstract: Acquiring dynamics is critical for robot learning and is fundamental to planning and control. This paper concerns two fundamental questions: How can we learn a model that covers massive, diverse robot dynamics? Can we construct a model that lifts the data-collection pain and domain expertise required for building specific robot models? We learn the dynamics involved in a dataset containing a large number of serial articulated robots and propose a new concept, “Gen2Real”, to transfer simulated, generalized models to physical, specific robots. We generate a large-scale dataset by randomizing dynamics parameters, topology configurations, and model dimensions, which, in sequence, correspond to different properties, connections, and numbers of robot links. A structure modified from the generative pre-trained transformer is applied to approximate the dynamics of massive heterogeneous robots. In Gen2Real, we transfer the pre-trained model to a target robot using distillation, for the sake of real-time computation. The results demonstrate the superiority of the proposed method in terms of its accuracy in learning a tremendous amount of robot dynamics and its generality to transfer to different robots. keywords: {Parallel robots;Parameter estimation;Pain;Computational modeling;Transformers;Robot learning;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342406&isnumber=10341342

Z. Liu and K. Karydis, "Dynamic Modeling and Analysis of Impact-Resilient MAVs Undergoing High-Speed and Large-Angle Collisions with the Environment," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4285-4292, doi: 10.1109/IROS55552.2023.10341848.Abstract: Micro Aerial Vehicles (MAVs) often face a high risk of collision during autonomous flight, particularly in cluttered and unstructured environments. To mitigate the collision impact on sensitive onboard devices, resilient MAVs with mechanical protective cages and reinforced frames are commonly used. However, compliant and impact-resilient MAVs offer a promising alternative by reducing the potential damage caused by impacts. In this study, we present novel findings on the impact-resilient capabilities of MAVs equipped with passive springs in their compliant arms. We analyze the effect of compliance through dynamic modeling and demonstrate that the inclusion of passive springs enhances impact resilience. The impact resilience is extensively tested to stabilize the MAV following wall collisions under high-speed and large-angle conditions. Additionally, we provide comprehensive comparisons with rigid MAVs to better determine the tradeoffs in flight by embedding compliance onto the robot's frame. keywords: {Analytical models;Tracking;Motion capture;Collision avoidance;Vehicle dynamics;Springs;State estimation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341848&isnumber=10341342

Y. Zheng, L. Li and S. Ma, "Legged Locomotion Control of an Under-Actuated Eccentric Paddle Mechanism with Torso Stabilization," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4293-4298, doi: 10.1109/IROS55552.2023.10342488.Abstract: Rescue robots require versatility and the capability to operate in various environments to carry out a diverse set of tasks effectively. The eccentric paddle (ePaddle) mechanism stands out for its high efficiency and adaptability. Generally, it is designed as a quadruped robot with a combined structure for fully-actuated control, this approach is often both inefficient and inflexible due to the requirement for repeated front-to-back paths. Unlike the fully-actuated controller that assume torso is fixed, this study proposes an under-actuated controller, consisting of a single ePaddle mechanism and a free torso for more efficient and flexible movement. Inspired by human gait, precision walking, and non-precision walking are introduced to discuss the stability of zero dynamics. Additionally, the stability condition is presented and demonstrated by numerical simulation. Since this control is based on robot dynamics, it has a high fault-tolerance and benefited from its dynamics attractor. The concept of under-actuated controller we proposed in this study is not only applicable to the ePaddle mechanism, but also to other under-actuated legged locomotion models. keywords: {Legged locomotion;Torso;Numerical simulation;Stability analysis;Numerical models;Quadrupedal robots;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342488&isnumber=10341342

J. Vertens, N. Dorka, T. Welschehold, M. Thompson and W. Burgard, "Improving Deep Dynamics Models for Autonomous Vehicles with Multimodal Latent Mapping of Surfaces," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4299-4306, doi: 10.1109/IROS55552.2023.10341771.Abstract: The safe deployment of autonomous vehicles relies on their ability to effectively react to environmental changes. This can require maneuvering on varying surfaces which is still a difficult problem, especially for slippery terrains. To address this issue we propose a new approach that learns a surface-aware dynamics model by conditioning it on a latent variable vector storing surface information about the current location. A latent mapper is trained to update these latent variables during inference from multiple modalities on every traversal of the corresponding locations and stores them in a map. By training everything end-to-end with the loss of the dynamics model, we enforce the latent mapper to learn an update rule for the latent map that is useful for the subsequent dynamics model. We implement and evaluate our approach on a real miniature electric car. The results show that the latent map is updated to allow more accurate predictions of the dynamics model compared to a model without this information. We further show that by using this model, the driving performance can be improved on varying and challenging surfaces. keywords: {Training;Temperature sensors;Temperature;Roads;Vehicle safety;Tire pressure;Predictive models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341771&isnumber=10341342

W. Choo and E. Kayacan, "Data-Based MHE for Agile Quadrotor Flight," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4307-4314, doi: 10.1109/IROS55552.2023.10342084.Abstract: This paper develops a data-based moving horizon estimation (MHE) method for agile quadrotors. Accurate state estimation of the system is paramount for precise trajectory control for agile quadrotors; however, the high level of aerodynamic forces experienced by the quadrotors during high-speed flights make this task extremely challenging. These complex turbulent effects are difficult to model and the unmodelled dynamics introduce inaccuracies in the state estimation. In this work, we propose a method to model these aerodynamic effects using Gaussian Processes which we integrate into the MHE to achieve efficient and accurate state estimation with minimal computational burden. Through extensive simulation and experimental studies, this method has demonstrated significant improvement in state estimation performance displaying superior robustness to poor state measurements. keywords: {Accelerometers;Training;Computational modeling;Current measurement;Predictive models;Aerodynamics;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342084&isnumber=10341342

A. U. Kilic and D. J. Braun, "A Novel Approximation for the Spring Loaded Inverted Pendulum Model of Locomotion," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4315-4321, doi: 10.1109/IROS55552.2023.10341418.Abstract: The Spring-Loaded Inverted Pendulum (SLIP) is one of the simplest models of robot locomotion. SLIP is commonly used to predict the center of mass motion and derive simple control laws for stable locomotion. However, the SLIP model is not integrable, which means that no closed-form relation can be derived to understand how the design and control parameters of the SLIP model affect stable locomotion. There exist a number of different analytical approximations to the SLIP model when considering small step lengths and symmetric steps. In this paper, we present a novel approximation to the SLIP model without relying on the small step length and the symmetric step assumption. The model was found to accurately predict the stability of the SLIP model for large and asymmetric steps and was used to design a controller to stabilize the SLIP model in a couple of steps. keywords: {Analytical models;Predictive models;Stability analysis;Springs;Intelligent robots;Load modeling},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341418&isnumber=10341342

I. Stewart and P. Tallapragada, "A Fast Steerable Soft Robot for Navigating a Pipe Network," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4322-4327, doi: 10.1109/IROS55552.2023.10341708.Abstract: Soft vibrational bristlebots are robots with deformable bristles on their outside that propel the robot through the stick slip motion of the bristle tips interacting with the ground when a vibration is induced in the robot. Experimental results and theoretical analysis of the dynamics for this style of robot have been investigated on flat surfaces. However, for the soft vibrational bristlebots traveling through pipes, controlled steering and the ability for the robot to navigate intersections has not been achieved or understood. This paper presents a two unit vibrational bristlebot with connecting helical coils. Through models and experiments it is demonstrated that a full range of controlled motion (traveling forwards, turning left and right and going up or down a vertical pipe) within a pipe network is possible for such soft vibrational bristlebots. Such fast steerable motion is all achieved merely by changing the polarity and spin speed of the vibrational motors. keywords: {Vibrations;Navigation;Friction;Soft robotics;Propulsion;Turning;Nonlinear dynamical systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341708&isnumber=10341342

R. Jilani, P. -F. Villard and E. Kerrien, "An Orthogonal Collocation Method for Static and Dynamic Cosserat Rods," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4328-4333, doi: 10.1109/IROS55552.2023.10341631.Abstract: We propose an orthogonal collocation method (CM) for solving Cosserat rod Dirichlet-Neumann boundary value problems in static and dynamic modes. We interpolate the internal loading and collocate the strong form of the differential equations. The method uses Chebyshev polynomials in order to minimize Runge's phenomenon. The time derivatives are implicitly discretized using the backward differentiation formula BDF- $\alpha$ We compare our method with the shooting method (SM), multiple shooting method (MSM) and two isogeometric CM against three static and one dynamic applications. The results show that our CM is more stable than SM and faster than MSM. keywords: {Friction;Loading;Force;Dynamics;Chebyshev approximation;Bending;Stability analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341631&isnumber=10341342

W. Tao, K. Patnaik, F. Chen, Y. Kumar and W. Zhang, "Design, Characterization and Control of a Whole-body Grasping and Perching (WHOPPEr) Drone," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 1-7, doi: 10.1109/IROS55552.2023.10341722.Abstract: Flying robots can exploit perching abilities to position themselves on strategically-chosen locations and monitor the areas of interest from a critical vantage point. Moreover, they can significantly extend their battery life by turning off the propulsion systems when carrying out a surveillance mission. However, unknown disturbances arise from the physical interactions between the robot and the object, making it challenging to stabilize the robot during perching. In this paper, we present a Whole-body Grasping and Perching (WHOPPEr) Drone, which is capable of fast and robust perching by utilizing its entire body as the grasper in lieu of an add-on grasper. We first present the design concept, parameter selection and characterization of the novel whole-body grasping drone. Next, we analyze the grasping ability of the morphing chassis and present an aerodynamic analysis for the effect of motor thrust on the compliant arm. We finally demonstrate, via real-time experiments, the performance of WHOPPEr in autonomous perching and payload delivery tasks. keywords: {Computational modeling;Surveillance;Grasping;Propulsion;Turning;Robustness;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341722&isnumber=10341342

C. Wang, Y. Zhang, C. Li, W. Wang and Y. Li, "A Rotor Flywheel Robot: Land-air Amphibious Design and Control," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4341-4346, doi: 10.1109/IROS55552.2023.10341371.Abstract: Most land-air amphibious UAVs feature a four-wheel design that limits their adaptability in narrow and uneven spaces. This study proposes the rotor flywheel as a new land-air design that integrates a one-wheel structure and eight-rotor wings for more flexible motion. The dynamics model is then conducted with the Kane method, finding two power-saving self-balance state while rolling. Its controller design highlights the multi-input decoupling approach utilizing feedback, along with the dynamic model-based component to enable efficient control of its intricate operations. Results of simulations and experimental tests have validated the stability and adaptability of the mode-switching and rolling of the robot in ground motion. keywords: {Analytical models;Adaptation models;Dynamics;Rotors;Aerospace electronics;Stability analysis;Flywheels},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341371&isnumber=10341342

B. M. Gonultas, P. Mukherjee, O. G. Poyrazoglu and V. Isler, "System Identification and Control of Front-Steered Ackermann Vehicles Through Differentiable Physics," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4347-4353, doi: 10.1109/IROS55552.2023.10342391.Abstract: In this paper, we address the problem of system identification and control of a front-steered vehicle which abides by the Ackermann geometry constraints. This problem arises naturally for on-road and off-road vehicles that require reliable system identification and basic feedback controllers for various applications such as lane keeping and way-point navigation. Traditional system identification requires expensive equipment and is time consuming. In this work we explore the use of differentiable physics for system identification and controller design and make the following contributions: i) We develop a differentiable physics simulator (DPS) to provide a method for the system identification of front-steered class of vehicles whose system parameters are learned using a gradient-based method; ii) We provide results for our gradient-based method that exhibit better sample efficiency in comparison to other gradient-free methods; iii) We validate the learned system parameters by implementing a feedback controller to demonstrate stable lane keeping performance on a real front-steered vehicle, the F1TENTH; iv) Further, we provide results exhibiting comparable lane keeping behavior for system parameters learned using our gradient-based method with lane keeping behavior of the actual system parameters of the F1TENTH. keywords: {Geometry;Navigation;Control systems;System identification;Behavioral sciences;Reliability;Adaptive control},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342391&isnumber=10341342

H. Das, B. K. Sæbø, K. Y. Pettersen and C. Ott, "Hardware-in-the-Loop Simulation of Vehicle-Manipulator Systems for Physical Interaction Tasks," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4390-4396, doi: 10.1109/IROS55552.2023.10342250.Abstract: Hardware-in-the-loop simulation (HILS) allows a more realistic evaluation of control approaches than what is possible with pure software simulations, but without the actual complexity of the complete system. This is important for some complex systems such as orbital robots, where testing of the system is typically not possible after its launch, and an on-ground replica is used to validate the performance of such a system. In this article, an impedance-matching approach is presented to match the end-effector dynamics of a fixed-base robot manipulator with that of a target vehicle-manipulator system (VMS), while taking into account the redundant nullspace dynamics in a connected real-time simulation framework. This approach ensures that the forces and torques exerted by the system on the environment matches with that of the simulated system. The contact wrenches used in our approach are not obtained from numerical simulations, but rather from real physical interaction, which is one of the main advantages of our approach. The effectiveness of our method is validated by demonstrating various physical interaction tasks with the environment, using a suspended aerial manipulator as the target system. keywords: {Hardware-in-the-loop simulation;Dynamics;Numerical simulation;Software;Real-time systems;Orbits;Vehicle dynamics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342250&isnumber=10341342

R. Bendfeld and C. D. Remy, "Modeling and Workspace Characterization of Continuously Compliant Robotic Legs," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4405-4411, doi: 10.1109/IROS55552.2023.10342327.Abstract: This work introduces a new design paradigm for robotic legs. Our concept extends upon classical series elastic actuation and directly integrates the series compliance into the structure of the leg. This integration reduces the mechanical design complexity and can potentially reduce the overall weight of the leg. In this paper, we introduce a prototype leg with a continuously compliant shank and derive and analyze a non-linear beam model that is used to predict its contact forces. The model is validated in two static experiments: one on the isolated shank and one on the full leg. It shows good agreement with measurements. In our validation, we also studied the influence of the model discretization, showing that about 10 nodes are sufficent. Furthermore, we introduce the concept of a force workspace: the range of forces that can be created by controlling the joint angles of the leg. Due to the coupling of nonlinear deformations and nonlinearities in the kinematics, this workspace is non-trivial. In particular, we demonstrate that it is bounded by a force-singularity in which the force/joint-angle relationship cannot be inverted. The results presented in this work can be applied in the development of state-estimators, set-point filters and controllers, and they can inform the future design of suitable geometries of compliant elements. keywords: {Legged locomotion;Geometry;Couplings;Deformation;Force;Prototypes;Kinematics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342327&isnumber=10341342

N. Georgiev, "Efficiency Estimation and Optimization of Multistage Compound Planetary Gearboxes and Application to the Design of the Active Skin Propulsion of EELS," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4412-4419, doi: 10.1109/IROS55552.2023.10341515.Abstract: This paper outlines a novel versatile geometric method for the estimation of the efficiency of multistage compound planetary gearboxes. The approach is based on a virtual pitch point modeling that allows for accurate representation of the gear interaction with forces applied at the pitch point. When this modeling is applied to all gears in a multistage compound planetary gearbox, the gearbox efficiency may be estimated directly from the free body diagram of the compound planets in a simple and easy to implement fashion. The gear design parameters that determine the gearing efficiency are identified and a consistent strategy for maximizing the efficiency of such gearboxes is outlined. Finally, the introduced methods are applied to the design of a three-stage compound planetary gearbox used in a novel snake-like robot. keywords: {Gears;Planets;Estimation;Propulsion;Fasteners;Skin;Compounds},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341515&isnumber=10341342

J. Zhao, G. J. G. Lahr, F. Tassi, A. Santopaolo, E. De Momi and A. Ajoudani, "Impact-Friendly Object Catching at Non-Zero Velocity Based on Combined Optimization and Learning," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4428-4435, doi: 10.1109/IROS55552.2023.10341600.Abstract: This paper proposes a combined optimization and learning method for impact-friendly, non-prehensile catching of objects at non-zero velocity. Through a constrained Quadratic Programming problem, the method generates optimal trajectories up to the contact point between the robot and the object to minimize their relative velocity and reduce the impact forces. Next, the generated trajectories are updated by Kernelized Movement Primitives, which are based on human catching demonstrations to ensure a smooth transition around the catching point. In addition, the learned human variable stiffness (HVS) is sent to the robot's Cartesian impedance controller to absorb the post-impact forces and stabilize the catching position. Three experiments are conducted to compare our method with and without HVS against a fixed-position impedance controller (FP-IC). The results showed that the proposed methods outperform the FP-IC while adding HVS yields better results for absorbing the post-impact forces. keywords: {Measurement;Learning systems;Torque;Redundancy;Trajectory;Impedance;Quadratic programming},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341600&isnumber=10341342

H. Wu, H. Yang and Y. Li, "Online Estimation of 2D Human Arm Stiffness for Peg-in-Hole Tasks with Variable Impedance Control," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4436-4442, doi: 10.1109/IROS55552.2023.10341960.Abstract: This paper proposes an online estimation model for 2D arm stiffness in humans. The proposed model is based on recent physiological findings which suggest that: (1) joint stiffness is linearly related to the magnitude of joint torque and increases to compensate for environmental disturbances; and (2) the endpoint stiffness of the arm is proportional to grasp force. To validate the proposed model, perturbation experiments were conducted under different grasp forces. The model parameters were identified and the accuracy of the model was assessed. The results showed that the proposed model has advantages over previous models for estimating human arm endpoint stiffness, in the sense of simplicity and robustness. The proposed model was also used to design a variable stiffness controller for peg-in-hole tasks, demonstrating the potential of the model for human-robot collaboration. keywords: {Solid modeling;Torque;Three-dimensional displays;Human-robot interaction;Estimation;Robot sensing systems;Robustness},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341960&isnumber=10341342

W. Han, W. Yun and S. Oh, "Workspace Force/Acceleration Disturbance Observer for Precise and Safe Motion Control," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4450-4456, doi: 10.1109/IROS55552.2023.10341933.Abstract: The use of impedance control has become widespread in applications requiring simultaneous position tracking and compliance in contact. However, disturbances such as friction and model uncertainties can adversely affect the performance of impedance-based motion control. The disturbance observer (DOB) has been proposed to address this issue, which is a widely-utilized robust controller that eliminates observed disturbances with the nominal model. However, current DOB applications fail to consider the aspect of interactive force control properly. This study proposes a novel Workspace Force/Acceleration Disturbance Observer (WFADOB) controller, which utilizes both interaction force and acceleration to design a disturbance observer loop, enabling precise motion tracking even with low-impedance gain settings. Additionally, the proposed controller offers fine impedance rendering performance, offering safe contact while maintaining low impedance. This paper discusses the problem of motion tracking performance due to friction and the interaction force that arises during contact. The proposed controller is theoretically analyzed and experimentally verified, demonstrating its performance compared to conventional methods. keywords: {Uncertainty;Tracking;Friction;Force;Stability criteria;Disturbance observers;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341933&isnumber=10341342

Y. Michel, M. Saveriano, F. J. Abu-Dakka and D. Lee, "Orientation Control with Variable Stiffness Dynamical Systems," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4457-4463, doi: 10.1109/IROS55552.2023.10342531.Abstract: Recently, several approaches have attempted to combine motion generation and control in one loop to equip robots with reactive behaviors, that cannot be achieved with traditional time-indexed tracking controllers. These approaches however mainly focused on positions, neglecting the orientation part which can be crucial to many tasks e.g. screwing. In this work, we propose a control algorithm that adapts the robot's rotational motion and impedance in a closed-loop manner. Given a first-order Dynamical System representing an orientation motion plan and a desired rotational stiffness profile, our approach enables the robot to follow the reference motion with an interactive behavior specified by the desired stiffness, while always being aware of the current orientation, represented as a Unit Quaternion (UQ). We rely on the Lie algebra to formulate our algorithm, since unlike positions, UQ feature constraints that should be respected in the devised controller. We validate our proposed approach in multiple robot experiments, showcasing the ability of our controller to follow complex orientation profiles, react safely to perturbations, and fulfill physical interaction tasks. keywords: {Tracking loops;Tracking;Heuristic algorithms;Perturbation methods;Aerospace electronics;Behavioral sciences;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342531&isnumber=10341342

M. M. Marinho, H. -C. Lin and J. Zhao, "UMIRobot: An Open-{Software, Hardware} Low-Cost Robotic Manipulator for Education," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4464-4471, doi: 10.1109/IROS55552.2023.10341347.Abstract: Robot teleoperation has been studied for the past 70 years and is relevant in many contexts, such as in the handling of hazardous materials and telesurgery. The COVID19 pandemic has rekindled interest in this topic, but the existing robotic education kits fall short of being suitable for teleoperated robotic manipulator learning. In addition, the global restrictions of motion motivated large investments in online/hybrid education. In this work, a newly developed robotics education kit and its ecosystem are presented which is used as the backbone of an online/hybrid course in teleoperated robots. The students are divided into teams. Each team designs, fabricates (3D printing and assembling), and implements a control strategy for a master device and gripper. Coupling those with the UMIRobot, provided as a kit, the students compete in a teleoperation challenge. The kit is low cost (<100USD), which allows higher-learning institutions to provide one kit per student and they can learn in a risk-free environment. As of now, 73 such kits have been assembled and sent to course participants in eight countries. As major success stories, we show an example of gripper and master designed for the proposed course. In addition, we show a teleoperated task between Japan and Bangladesh executed by course participants. Design files, videos, source code, and more information are available at https://mmmarinho.github.io/UMIRobot/ keywords: {Temperature sensors;Three-dimensional displays;Education;Ecosystems;Manipulators;Three-dimensional printing;Hardware},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341347&isnumber=10341342

F. Voigt, A. Naceri and S. Haddadin, "I2mpedance - A Passivity Based Integrative Impedance Controller for Precise and Compliant Manipulation and Interaction," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4472-4479, doi: 10.1109/IROS55552.2023.10342370.Abstract: Sophisticated manipulation requires both compliance and accuracy. While tactile robots excel at being compliant, their accuracy is often inadequate for complex manipulation. Contact-rich assembly tasks, such as the insertion and manipulation of objects with small tolerances pose an enormous challenge. Complex, highly integrated assemblies, especially in high-tech areas such as robotics, sensors, or machines, still require human personnel, as they cannot be automated in a satisfactory way. To automate such tasks, especially in the context of labor shortage and Industry 4.0, these limitations must be overcome. Robots need to guarantee force limits for active environments in order to avoid harm or damage. Therefore, in this work, we adapt standard Cartesian impedance control by introducing an integration term for position accuracy and wrench limits for safe compliant interaction with unknown and active environments. We combine this with a virtual energy tank to guarantee the general passivity of the controller. Our controller is benchmarked against standard impedance control for absolute positioning accuracy across the robot workspace. Furthermore, we show its applicability to an industrial insertion task. We demonstrate absolute positioning accuracy (residual error| Ax| < 4e – 4) comparable to rigid robots while preserving compliant behavior. keywords: {Service robots;Force;Robot sensing systems;Sensors;Fourth Industrial Revolution;Impedance;Personnel},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342370&isnumber=10341342

J. Gao, H. Guo, Z. Cao, P. Huang and G. Zhou, "Real is Better than Perfect: Sim-to-Real Robotic System in Secondary School Education," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4480-4487, doi: 10.1109/IROS55552.2023.10341903.Abstract: Simulation systems of robots can facilitate the prediction, development, and debugging of robotic systems. However, they seldom applied in robotics education for primary and secondary school students. In this paper, we present a sim-to-real robotic system that enables students to optimize their algorithms in a simulated environment and validate them in a remote physical laboratory with data logs and remote cameras. Moreover, the system employs an automated submit-test-reset subsystem that minimizes the need for human intervention and provides 24/7 testing support. Experimental data from a trial with 28 students in remote areas show that the sim-to-real robotic experimental environment has comparable learning outcomes to a pure real robot environment and is significantly better than a pure simulation environment. Given the results, we validate that our system can substantially reduce the costs of teaching equipment and space while maintaining high-quality robotics education. keywords: {Learning systems;Codes;Education;Robot vision systems;Laboratories;Cameras;Prediction algorithms},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341903&isnumber=10341342

J. Buzzatto et al., "A Soft, Multi-Layer, Kirigami Inspired Robotic Gripper with a Compact, Compression-Based Actuation System," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4488-4495, doi: 10.1109/IROS55552.2023.10341893.Abstract: Over the last decade, a plethora of soft robotic devices have been proposed for the execution of complex grasping and dexterous manipulation tasks. Tasks requiring such increased dexterity are typically executed using fully-actuated, rigid end-effectors equipped with sophisticated sensing and controlled with complex control laws. The new class of soft robotic devices offers an alternative to the traditional end-effectors and facilitates the development of robotic grasping and manipulation solutions that are lightweight, safe to interact with, affordable, and easy to use and control. Within the class of soft robotic grippers and hands, promising recent developments were made in ultra-affordable, even disposable mechanisms based on origami and kirigami structures. This paper proposes a new kirigami-inspired robotic gripper geometry employing compression-based actuation. The compression actuation fundamentally differentiates this new design class from previous kirigami grippers, resulting in more compact robotic grippers with superior grasping capabilities. In particular, we investigate how the shapes of the internal cuts of the kirigami geometries can affect the gripper performance in terms of force exertion and grasping capabilities. A series of experiments are conducted to understand better the working principles behind this new type of kirigami grippers and experimentally validate their efficacy in the execution of complex, everyday life tasks. Further demonstrations of the gripper's capabilities include the pick-and-placing of human hair, egg yolk, and even liquids. keywords: {Hair;Geometry;Liquids;Shape;Force;Grasping;Soft robotics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341893&isnumber=10341342

S. Li et al., "Visuotactile Sensor Enabled Pneumatic Device Towards Compliant Oropharyngeal Swab Sampling," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4504-4511, doi: 10.1109/IROS55552.2023.10342266.Abstract: Manual oropharyngeal (OP) swab sampling is an intensive and risky task. In this article, a novel OP swab sampling device of low cost and high compliance is designed by combining the visuotactile sensor and the pneumatic actuator-based gripper. Here, a concave visuotactile sensor called CoTac is first proposed to address the problems of high cost and poor reliability of traditional multi-axis force sensors. Besides, by imitating the doctor's fingers, a soft pneumatic actuator with a rigid skeleton structure is designed, which is demonstrated to be reliable and safe via finite element modeling and experiments. Furthermore, we propose a sampling method that adopts a compliant control algorithm based on the adaptive virtual force to enhance the safety and compliance of the swab sampling process. The effectiveness of the device has been verified through sampling experiments as well as in vivo tests, indicating great application potential. The cost of the device is around 30 US dollars and the total weight of the functional part is less than 0.1 kg, allowing the device to be rapidly deployed on various robotic arms. keywords: {In vivo;Costs;Force;Tactile sensors;Sampling methods;Skeleton;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342266&isnumber=10341342

M. Maggi, G. Reina and G. Mantriota, "Mathematical Modelling and Experimental Validation of an Articulated Vacuum Gripper," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4512-4517, doi: 10.1109/IROS55552.2023.10342100.Abstract: This paper presents the underactuated vacuum gripper named Polypus. What is unique in Polypus is that it combines under-actuation and vacuum grasping to apply both power and unilateral grasp to objects of various shape and geometry. In addition, the gripper features modularity, i.e., single phalanges can be added or removed based on the application. The high flexibility also comes with a cost-effective (less than 100€ and simple design that can be manufactured with a consumer-grade 3D printer using FDM technology. While the analytical model has been introduced by the authors in previous research, here its experimental validation is described using a physical prototype that shows that the theoretical assumptions are reasonable. Experimental results also suggest a small variation in the original theoretical model. keywords: {Analytical models;Three-dimensional displays;Shape;Force;Prototypes;Programmable logic arrays;Predictive models;Underactuated grippers;vacuum grasping;robotic gripper;prototyping;experimental validation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342100&isnumber=10341342

J. Hong, K. Shin, D. C. Mathur, S. Yamsani, J. Yim and J. Kim, "Lip-Inspired Passive Jamming Gripper with Teeth Structure," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4518-4524, doi: 10.1109/IROS55552.2023.10342175.Abstract: In this paper, we propose a lip-inspired passive jamming gripper by mimicking teeth structures from a dog's oral structure. Animal lips are hydrostatic structures. To mimic the features, which are usually soft but rigid when contacted, we used the passive particle jamming effect. To increase the adaptability of our previous gripper to grasp various shaped objects, we focused on the dogs' oral structure and holding behaviors. Dogs use spaces inside their mouths to hold sticks firmly when moving. The grasping force of the upgraded gripper was improved by generating teeth structures with the mimicked lip structures. Experiments were conducted to demonstrate the grasping ability of the gripper with the teeth structures by comparing it to other types of grippers with cylindrical and cuboid objects of various dimensions. We also showed that the proposed gripper could hold daily kitchen objects better than the previous version gripper by using closing lip-pouches. keywords: {Shape;Atmospheric measurements;Lips;Force;Grasping;Teeth;Dogs},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342175&isnumber=10341342

N. Fukaya, A. Ummadisingu, K. Takahashi, G. Maeda and S. -I. Maeda, "Two-Fingered Hand with Gear-Type Synchronization Mechanism with Magnet for Improved Small and Offset Objects Grasping: F2 Hand," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4525-4532, doi: 10.1109/IROS55552.2023.10342060.Abstract: A problem that plagues robotic grasping is the misalignment of the object and gripper due to difficulties in precise localization, actuation, etc. Under-actuated robotic hands with compliant mechanisms are used to adapt and compensate for these inaccuracies. However, these mechanisms come at the cost of controllability and coordination. For instance, adaptive functions that let the fingers of a two-fingered gripper adapt independently may affect the coordination necessary for grasping small objects. In this work, we develop a two-fingered robotic hand capable of grasping objects that are offset from the gripper's center, while still having the requisite coordination for grasping small objects via a novel gear-type synchronization mechanism with a magnet. This gear synchronization mechanism allows the adaptive finger's tips to be aligned enabling it to grasp objects as small as toothpicks and washers. The magnetic component allows this coordination to automatically turn off when needed, allowing for the grasping of objects that are offset/misaligned from the gripper. This equips the hand with the capability of grasping light, fragile objects (strawberries, creampuffs, etc.) to heavy frying pan lids, all while maintaining their position and posture which is vital in numerous applications that require precise positioning or careful manipulation. keywords: {Location awareness;Manufacturing processes;Costs;Gears;Robot kinematics;Grasping;Synchronization},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342060&isnumber=10341342

R. Deimel and A. Kugi, "An Inflatable Eversible Finger Pad for Variable-Stiffness Grasping with Parallel-Jaw Grippers," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4533-4539, doi: 10.1109/IROS55552.2023.10341676.Abstract: We present an inflatable finger pad that allows regular parallel-jaw grippers to vary their grasp stiffness while maintaining a contact force and contact to non-planar surfaces. An eversible radial bellows structure made of silicone rubber allows the pad to extend to four times its original height and to retract into a rigid pod when not needed. The bellows act as passive universal joints when everted, enabling aerial contact with surfaces inclined by up to 45 degree. The bellow geometry is intentionally nonlinear but avoids bistable configurations to facilitate control. We find that the nonlinear stiffness behavior allows a pair of opposing pads to increase the compliance of a grasp twenty fold, resulting in a total of two orders of magnitude difference between the most stiff and most compliant configuration. Crucially, high compliance can be achieved while exerting a contact force between 0.7 N and 5 N, allowing for compliant but firm grasps. Pads are manufactured using printed molds and sacrificial-mold casting. keywords: {Geometry;Surface impedance;Bellows;Fingers;Force;Grasping;Rubber},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341676&isnumber=10341342

A. Patra and A. J. Spiers, "D-PALI: A Low-Cost Open Source Robotic Gripper Platform for Planar In-Hand-Manipulation," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4540-4546, doi: 10.1109/IROS55552.2023.10341860.Abstract: Robot grippers are widely used in industrial automation for pick-and-place tasks on a variety of objects. Whilst the majority of commercial grippers are capable of establishing stable grasps, few can perform in-hand-manipulation (IHM). IHM is has the potential to increase robotic motion efficiency, yet most IHM-capable manipulation platforms are anthropomorphic in nature and cost over $10,000, posing a barrier to entry for many. In this work we propose a IHM capable gripper platform that is open-source and may be assembled for £150 ($162) and access to a 3D printer. The gripper consists of two fully actuated 2DOF fingers, each of which is based on a five-bar linkage mechanism with one link extended. The fingers are modular, allowing the gripper to be easily expanded into 3+ finger configurations via simple modification of the central mount. We define the inverse kinematics and effective workspace of the gripper (via the use of Freudenstein equations), providing guidance for translation and rotation of gripped objects. We demonstrate the gripper's ability to manipulate a 1-inch cube's pose within a ±5% error margin and rotate various other YCB objects via open-loop position control. keywords: {Robot motion;Three-dimensional displays;Service robots;Fingers;Position control;Kinematics;Printers;Grippers and Other End-Effectors;In-Hand Manipulation;Dexterous Manipulation},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341860&isnumber=10341342

V. D. Hoang, A. Kramberger and E. Ebeid, "Adaptive and Fail-Safe Magnetic Gripper with Charging Function for Drones on Power Lines," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4547-4554, doi: 10.1109/IROS55552.2023.10341434.Abstract: Drone grasping on power lines for recharging is challenging since it requires the gripper to be lightweight, carried by a drone, and efficient for a firm grasp. A deep understanding of the power line nature and its magnetic characteristic helps ease such challenges and bring new knowledge to gripper design. In this work, a novel adaptive, lightweight, and fail-safe magnetic gripper with a recharging feature is presented. The gripper exploits the radiated magnetic field of the lines for charging and holding the drone and can easily detach from the line. The gripper design has been validated in the lab and on a quadcopter with a real power line. keywords: {Power cables;Grasping;Switches;Inspection;Magnetic fields;Grippers;Magnetic switching},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341434&isnumber=10341342

X. Zhou and A. J. Spiers, "InstaGrasp: An Entirely 3D Printed Adaptive Gripper with TPU Soft Elements and Minimal Assembly Time," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4555-4561, doi: 10.1109/IROS55552.2023.10341385.Abstract: Fabricating existing and popular open-source adaptive robotic grippers commonly involves using multiple professional machines, purchasing a wide range of parts, and tedious, time-consuming assembly processes. This poses a significant barrier to entry for some robotics researchers and drives others to opt for expensive commercial alternatives. To provide both parties with an easier and cheaper (under £100) solution, we propose a novel adaptive gripper design where every component (with the exception of actuators and the screws that come packaged with them) can be fabricated on a hobby-grade 3D printer, via a combination of inexpensive and readily available PLA and TPU filaments. This approach means that the gripper's tendons, flexure joints and finger pads are now printed, as a replacement for traditional string-tendons and molded urethane flexures / pads. A push-fit systems results in an assembly time of under 10 minutes. The gripper design is also highly modular and requires only a few minutes to replace any part, leading to extremely user-friendly maintenance and part modifications. An extensive stress test has shown a level of durability more than suitable for research, whilst grasping experiments (with perturbations) using items from the YCB object set has also proven its mechanical adaptability to be highly satisfactory. keywords: {Three-dimensional displays;Pulleys;Perturbation methods;Grasping;Programmable logic arrays;Printers;Grippers},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341385&isnumber=10341342

W. Chungsangsatiporn and R. Chancharoen, "A Bio-Inspired Robotic Finger: Mechanics and Control," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4562-4567, doi: 10.1109/IROS55552.2023.10342443.Abstract: A robotic finger is successfully designed, fabricated, analyzed, and examined. The finger consists of bones, joint ligaments, and an extensor hood. Driven by two tendons, it is two degrees on the freedom finger. Although the behavior of this design is not uniform, it provides useful dexterity, sensitivity, and versatility. The artificial bone is lightweight and compact. The actuation is backdrivable in good visibility. Tendon muscles effectively actuate the finger in a grasp direction. This exceptional behavior has the potential to be suitable for a flexible task and may lead to a next-generation gripper and prosthetic hand. keywords: {Fabrication;Sensitivity;Muscles;Bones;Robot sensing systems;Behavioral sciences;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342443&isnumber=10341342

E. Zhao, M. M. Marinho and K. Harada, "Autonomous Robotic Drilling System for Mice Cranial Window Creation: An Evaluation with an Egg Model," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4592-4599, doi: 10.1109/IROS55552.2023.10341693.Abstract: Robotic assistance for experimental manipulation in the life sciences is expected to enable precise manipulation of valuable samples, regardless of the skill of the scientist. Experimental specimens in the life sciences are subject to individual variability and deformation, and therefore require autonomous robotic control. As an example, we are studying the installation of a cranial window in a mouse. This operation requires the removal of the skull, which is approximately 300 um thick, to cut it into a circular shape 8 mm in diameter, but the shape of the mouse skull varies depending on the strain of mouse, sex and week of age. The thickness of the skull is not uniform, with some areas being thin and others thicker. It is also difficult to ensure that the skulls of the mice are kept in the same position for each operation. It is not realistically possible to measure all these features and pre-program a robotic trajectory for individual mice. The paper therefore proposes an autonomous robotic drilling method. The proposed method consists of drilling trajectory planning and image-based task completion level recognition. The trajectory planning adjusts the z-position of the drill according to the task completion level at each discrete point, and forms the 3D drilling path via constrained cubic spline interpolation while avoiding overshoot. The task completion level recognition uses a DSSD-inspired deep learning model to estimate the task completion level of each discrete point. Since an egg has similar characteristics to a mouse skull in terms of shape, thickness and mechanical properties, removing the egg shell without damaging the membrane underneath was chosen as the simulation task. The proposed method was evaluated using a 6-DOF robotic arm holding a drill and achieved a success rate of 80% out of 20 trials. keywords: {Drilling;Trajectory planning;Shape;Skull;Mice;Real-time systems;Trajectory},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341693&isnumber=10341342

A. Zhang, Z. Min, Y. Wang and M. Q. . -H. Meng, "Towards an Accurate Augmented-Reality-Assisted Orthopedic Surgical Robotic System Using Bidirectional Generalized Point Set Registration," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4600-4607, doi: 10.1109/IROS55552.2023.10341401.Abstract: This paper presents a novel augmented reality (AR)-assisted orthopedic surgical robotic system based on Head-Mounted Display (HMD) devices. The proposed system can overlay the preoperative plans over the patient's anatomy and provide useful guidance for surgeons during interventions, with integrated calibration and registration components. A novel bi-directional generalised point set registration algorithm that utilises robust features is developed to accurately align the pre-operative CT and intra-operative patient spaces, which has been demonstrated to outperform existing registration methods. The efficacy of the system is both qualitatively and quantitatively assessed with an in vitro study simulating a total knee arthroplasty (TKA) procedure. The experimental results showed that 1) the system can successfully align the preoperative and intraoperative spaces, with the mean target registration error (TRE) being 2.7771 mm; 2) the models can be properly overlaid to the physical scenarios with the mean AR visualization accuracy being 6.9726 mm. keywords: {Visualization;Medical robotics;Simultaneous localization and mapping;Robot kinematics;Robot vision systems;Surgery;Resists},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341401&isnumber=10341342

A. Wang, M. Islam, M. Xu and H. Ren, "Generalizing Surgical Instruments Segmentation to Unseen Domains with One-to-Many Synthesis," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4608-4614, doi: 10.1109/IROS55552.2023.10341609.Abstract: Despite their impressive performance in various surgical scene understanding tasks, deep learning-based methods are frequently hindered from deploying to real-world surgical applications for various causes. Particularly, data collection, annotation, and domain shift in-between sites and patients are the most common obstacles. In this work, we mitigate data-related issues by efficiently leveraging minimal source images to generate synthetic surgical instrument segmentation datasets and achieve outstanding generalization performance on unseen real domains. Specifically, in our framework, only one background tissue image and at most three images of each foreground instrument are taken as the seed images. These source images are extensively transformed and employed to build up the foreground and background image pools, from which randomly sampled tissue and instrument images are composed with multiple blending techniques to generate new surgical scene images. Besides, we introduce hybrid training-time augmentations to diversify the training data further. Extensive evaluation on three real-world datasets, i.e., Endo2017, Endo2018, and RoboTool, demonstrates that our one-to-many synthetic surgical instruments datasets generation and segmentation framework can achieve encouraging performance compared with training with real data. Notably, on the RoboTool dataset, where a more significant domain gap exists, our framework shows its superiority of generalization by a considerable margin. We expect that our inspiring results will attract research attention to improving model generalization with data synthesizing. keywords: {Training;Learning systems;Image segmentation;Annotations;Instruments;Training data;Data collection},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341609&isnumber=10341342

E. Iovene et al., "Reducing Workload During Brain Surgery with Robot-Assisted Autonomous Exoscope," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4615-4620, doi: 10.1109/IROS55552.2023.10341799.Abstract: In this paper, a position-based visual-servoing control approach is introduced for a robotic camera holder to improve ergonomics and reduce mental stress during brain surgery. The visual tracking system controls and moves the robotic camera holder by following a selected surgical instrument without the need for artificial markers. The system was validated using a 7 Degree-of-Freedoms (DoFs) redundant robotic manipulator with an eye-in-hand stereo camera configuration and compared with conventional control methods using NASA TLX survey and four objective metrics, including execution time, time out of field of view (FoV), target score, and path length. Experimental results demonstrate that the proposed system can reduce the surgeon's workload during brain surgery-related task execution, improve ergonomics and achieve higher performance than traditional control methods. keywords: {Surveys;Visualization;Tracking;Instruments;Robot vision systems;Cameras;Control systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341799&isnumber=10341342

V. Penza et al., "Augmented Reality Navigation in Robot-Assisted Surgery with a Teleoperated Robotic Endoscope," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4621-4626, doi: 10.1109/IROS55552.2023.10342282.Abstract: Augmented reality (AR) is considered one of the most promising solutions for safer procedures in several surgical specialities. Fusing patient-specific pre-operative information, typically 3D models extracted from CT scans or MRI, with real-time surgical images allows the surgeon to have detailed information on the anatomical structure of the surgical target intra-operatively. The coupling of AR and Robotics represents the next step towards introducing awareness into the surgical room, thus enhancing the surgeon's perceptual, cognitive and manipulative capabilities. This paper presents a novel integrated system for real-time AR navigation in robotic minimally invasive surgery (RMIS), composed of a robotic endoscopic camera, a robotic teleoperation implementing a software-based Remote Center of Motion (RCM), and an AR navigation software based on an initial manual registration of virtual 3D models with the real anatomy. The integrated system, as well as the individual modules, were evaluated in simulated surgical-like setups for accuracy and repeatability. The proposed system can perform high-precision tasks (position accuracy around $1 mm$ and AR error lower than 7%), showing potential for application in different surgical procedures and setting the basis for autonomous robotic surgery operations. keywords: {Solid modeling;Three-dimensional displays;Minimally invasive surgery;Navigation;Robot vision systems;Real-time systems;Software},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342282&isnumber=10341342

Y. Huang, Q. Wei, J. L. Demer and N. Yao, "See What a Strabismus Patient Sees Using Eye Robots," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4627-4632, doi: 10.1109/IROS55552.2023.10342099.Abstract: Ocular mobility disorders such as strabismus af-fect millions of people. Patients' descriptions of their symptoms, such as what they see and how their vision has changed, are important for ophthalmologists to diagnose, monitor pro-gression, and evaluate treatment effectiveness. However, such verbal depiction may be vague and Subjective. A data-driven simulator that visualizes abnormal vision experienced by a strabismic patient can be helpful to objectively illustrate each individual's vision condition and thus to better understand and manage strabismus. To fulfill this technical void, this paper presents the first vision visualization robot that uses human eye movement data to simulate strabismic vision. We developed a robotic binocular eye platform, which is capable of displaying simulated visual scenes using its onboard cameras. Based on the hypothesis that a human's binocular vision fusion process can be mimicked as a homography transformation from one view to another view, we developed a pipeline to estimate the time-varying homography matrix, and generate the fused view of a human's binocular vision. The effectiveness of the proposed method is demonstrated through experiments with eye movement data from both healthy individuals and strabismic patients. keywords: {Visualization;Robot vision systems;Pipelines;Data visualization;Cameras;Monitoring;Intelligent robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342099&isnumber=10341342

J. Liu, Y. Long, K. Chen, C. H. Leung, Z. Wang and Q. Dou, "Visual-Kinematics Graph Learning for Procedure-Agnostic Instrument Tip Segmentation in Robotic Surgeries," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4633-4639, doi: 10.1109/IROS55552.2023.10342120.Abstract: Accurate segmentation of surgical instrument tip is an important task for enabling downstream applications in robotic surgery, such as surgical skill assessment, tool-tissue interaction and deformation modeling, as well as surgical autonomy. However, this task is very challenging due to the small sizes of surgical instrument tips, and significant variance of surgical scenes across different procedures. Although much effort has been made on visual-based methods, existing segmentation models still suffer from low robustness thus not usable in practice. Fortunately, kinematics data from the robotic system can provide reliable prior for instrument location, which is consistent regardless of different surgery types. To make use of such multi-modal information, we propose a novel visual-kinematics graph learning framework to accurately segment the instrument tip given various surgical procedures. Specifically, a graph learning framework is proposed to encode relational features of instrument parts from both image and kinematics. Next, a cross-modal contrastive loss is designed to incorporate robust geometric prior from kinematics to image for tip segmentation. We have conducted experiments on a private paired visual-kinematics dataset including multiple procedures, i.e., prostatectomy, total mesorectal excision, fundoplication and distal gastrectomy on cadaver, and distal gastrectomy on porcine. The leave-one-procedure-out cross validation demon-strated that our proposed multi-modal segmentation method significantly outperformed current image-based state-of-the-art approaches, exceeding averagely 11.2% on Dice. keywords: {Image segmentation;Visualization;Medical robotics;Deformation;Instruments;Surgery;Kinematics},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342120&isnumber=10341342

K. Yan, W. Yan and S. S. Cheng, "Dynamic Heart Simulator for Ultrasound-Guided Pericardiocentesis," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4640-4647, doi: 10.1109/IROS55552.2023.10342122.Abstract: Pericardiocentesis is an important surgical intervention to treat a medical condition called pericardial effusion, during which excessive fluid accumulates around the heart, potentially leading to life-threatening situation. It involves the insertion of a needle and catheter towards the heart into the pericardial space to drain the excessive fluid under ultrasound (US) guidance. The risky procedure requires surgeons to acquire sufficient training to ensure safe execution of the procedure. However, existing heart simulators lack dynamic features, do not offer realistic images under US imaging, and are not reusable. This work presents a dynamic heart simulator (DHS) with pericardial effusion to mimic the beating motion of the human heart and the realistic US imaging results. The beating heart motion is realized using a hydraulic actuation system connected to a double-layer balloon set. The clear and realistic US imaging results are obtained through a unique formula proposed for the chest tissue and the cardiac muscle. A characterization method was also developed to allow customization of important anatomical parameters in the DHS. The experimental results show that the DHS allowed highly realistic simulation of the beating heart, cardiac muscle, and pericardium under US imaging and has been demonstrated to enable successful US-guided pericardiocentesis. keywords: {Heart;Training;Ultrasonic imaging;Fluids;Heart beat;Dynamics;Surgery},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342122&isnumber=10341342

J. Wang, I. Iordachita and P. Kazanzides, "Method for Robotic Motion Compensation During PET Imaging of Mobile Subjects," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4648-4654, doi: 10.1109/IROS55552.2023.10341444.Abstract: Studies of the human brain during natural activities, such as locomotion, would benefit from the ability to image deep brain structures during these activities. While Positron Emission Tomography (PET) can image these structures, the bulk and weight of current scanners are not compatible with the desire for a wearable device. This has motivated the design of a robotic system to support a PET imaging system around the subject's head and to move the system to accommodate natural motion. We report here the design and experimental evaluation of a prototype robotic system that senses motion of a subject's head, using parallel string encoders connected between the robot-supported imaging ring and a helmet worn by the subject. This measurement is used to robotically move the imaging ring (coarse motion correction) and to compensate for residual motion during image reconstruction (fine motion correction). Minimization of latency and measurement error are the key design goals, respectively, for coarse and fine motion correction. The system is evaluated using recorded human head motions during locomotion, with a mock imaging system consisting of lasers and cameras, and is shown to provide an overall system latency of about 80 ms, which is sufficient for coarse motion correction and collision avoidance, as well as a measurement accuracy of about 0.5 mm for fine motion correction. keywords: {Weight measurement;Head;Imaging;Prototypes;Robot sensing systems;Magnetic heads;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341444&isnumber=10341342

N. Venkatayogi, Q. Hu, O. C. Kara, T. G. Mohanraj, S. F. Atashzar and F. Alambeigi, "On the Potentials of Surface Tactile Imaging and Dilated Residual Networks for Early Detection of Colorectal Cancer Polyps," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4655-4661, doi: 10.1109/IROS55552.2023.10342161.Abstract: This study proposes a novel diagnosis framework to decrease the early detection miss rate of colorectal cancer (CRC) polyps by using a hypersensitive vision-based tactile sensor (HySenSe) and a deep residual neural network. The HySenSe generates high-resolution 3D textural images of 160 realistic polyp phantoms for accurate classification via the proposed deep learning (DL) architecture. The DL module explores lightweight dilated convolutions, residual neural network architecture, and transfer learning to overcome the challenge of a small dataset of 229 images. Results show that the proposed architecture outperforms state-of-the-art DL models (i.e., EfficientNet and DenseNet) with a 94% accuracy, offering a promising solution for improving early detection of CRC polyps. The proposed framework can be used as a diagnostic module within tele-assessment medical robots, highlighting the potential of advanced technology and deep learning to revolutionize the early detection and treatment of CRC. keywords: {Deep learning;Three-dimensional displays;Transfer learning;Tactile sensors;Phantoms;Imaging phantoms;Robustness},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342161&isnumber=10341342

O. C. Kara et al., "A Smart Handheld Edge Device for on-Site Diagnosis and Classification of Texture and Stiffness of Excised Colorectal Cancer Polyps," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4662-4668, doi: 10.1109/IROS55552.2023.10341678.Abstract: This paper proposes a smart handheld textural sensing medical device with complementary Machine Learning (ML) algorithms to enable on-site Colorectal Cancer (CRC) polyp diagnosis and pathology of excised tumors. The proposed unique handheld edge device benefits from a unique tactile sensing module and a dual-stage machine learning algorithms (composed of a dilated residual network and a t-SNE engine) for polyp type and stiffness characterization. Solely utilizing the occlusion-free, illumination-resilient textural images captured by the proposed tactile sensor, the framework is able to sensitively and reliably identify the type and stage of CRC polyps by classifying their texture and stiffness, respectively. Moreover, the proposed handheld medical edge device benefits from internet connectivity for enabling remote digital pathology (boosting the diagnosis in operating rooms and promoting accessibility and equity in medical diagnosis). keywords: {Pathology;Machine learning algorithms;Image edge detection;Tactile sensors;Sensors;Reliability;Medical diagnostic imaging},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341678&isnumber=10341342

C. Zhang, C. Zhang, J. Qu and X. Qian, "Underwater and Surface Aquatic Locomotion of Soft Biomimetic Robot Based on Bending Rolled Dielectric Elastomer Actuators," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4677-4682, doi: 10.1109/IROS55552.2023.10342144.Abstract: All-around, real-time navigation and sensing across the water environments by miniature soft robotics are promising, for their merits of small size, high agility and good compliance to the unstructured surroundings. In this paper, we propose and demonstrate a mantas-like soft aquatic robot which propels itself by flapping-fins using rolled dielectric elastomer actuators (DEAs) with bending motions. This robot exhibits fast-moving capabilities of swimming at 57mm/s or 1.25 body length per second (BL/s), skating on water surface at 64 mm/s (1.36 BL/s) and vertical ascending at 38mm/s (0.82 BL/s) at 1300 V, 17 Hz of the power supply. These results show the feasibility of adopting rolled DEAs for mesoscale aquatic robots with high motion performance in various water-related scenarios. keywords: {Aquatic robots;Power supplies;Bending;Soft robotics;Propulsion;Robot sensing systems;Real-time systems},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342144&isnumber=10341342

T. Smith, R. M. Butts, N. Adkins and Y. Gu, "Swarm of One: Bottom-Up Emergence of Stable Robot Bodies from Identical Cells," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4683-4689, doi: 10.1109/IROS55552.2023.10342118.Abstract: Unlike most human-engineered systems, biological systems are emergent from low-level interactions, allowing much broader diversity and superior adaptation to complex environments. Inspired by the process of morphogenesis in nature, a bottom-up design approach for robot morphology is proposed to treat a robot's body as an emergent response to underlying processes rather than a predefined shape. This paper presents Loopy, a “Swarm-of-One” polymorphic robot testbed that can be viewed simultaneously as a robotic swarm and a single robot. Loopy's shape is determined jointly by self-organization and morphological computing using physically linked homogeneous cells. Experimental results show that Loopy can form symmetric shapes consisting of lobes. Using the same set of parameters, even small amounts of initial noise can change the number of lobes formed. However, once in a stable configuration, Loopy has an “inertia” to transfiguring in response to dynamic parameters. By making the connections among self-organization, morphological computing, and robot design, this work lays the foundation for more adaptable robot designs in the future. keywords: {Shape;Morphology;Biological systems;Self-organizing networks;Modeling;Robots;Intelligent robots;Robotic Swarm;Robot Design;Morphogenesis;Morphological Computing},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342118&isnumber=10341342

X. Guo, G. Jia, M. Al-Khulaqui, Z. Chen, T. Fukuda and Q. Shi, "Real-Time Pose Estimation of Rats Based on Stereo Vision Embedded in a Robotic Rat," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4690-4695, doi: 10.1109/IROS55552.2023.10342475.Abstract: In this paper, we propose a system for real-time rat pose estimation based on stereo vision. The system is dedicated to robot-rat interaction research. First, we design a lightweight, high-resolution network (RRKDNet) for keypoint detection of the rat. The network is trained on a dataset of rat images, which are captured by the robotic rat in first-person view. Second, based on the keypoint detection results, the pose of the rat is obtained by stereo vision model calculation and robot coordinate transformation. At last, we complete a real-time simulation experiment to reproduce the pose of the rat and the robotic rat. The system has been subjected to a series of experiments and the results demonstrate that our network performs better in speed and performance than similar networks. Compared to similar networks, our network has about one-third the number of parameters, while the detection rate increases by 45.25% (the detection rate is 71.57%). The inference speed (34.42 FPS with dual model simultaneous inference) is also faster. The validation error is only 13.85 pixels on the homemade dataset, which is lower than all backbones in Deeplabcut (a toolbox more frequently used for rat keypoint detection). Thus, this work is a significant step in the autonomous intelligent interaction between robots and rats. keywords: {Visualization;Three-dimensional displays;Robot kinematics;Pose estimation;Rats;Real-time systems;Stereo vision},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342475&isnumber=10341342

Y. Liu et al., "Design and Development of a Rapidly Deployable Low-Cost Tensegrity In-Pipe Robot," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4696-4701, doi: 10.1109/IROS55552.2023.10341489.Abstract: Existing in-pipe robots have insufficient adaptability when dealing with accidents in unfamiliar pipe environments. Developing a pipe robot that can be designed and manufactured quickly is one solution. The tensegrity structure is a self-stressing spatial structure formed by the interaction of rigid members and flexible cables, which has the advantages of simple structure, good flexibility, deformability, and impact resistance. Inspired by this structure, we design a novel worm-like tensegrity robot for different pipe environments, which can be manufactured rapidly at low cost. Firstly, a robotic module based on the tensegrity structure is designed inspired by the motion patterns of worm-like organisms. Then, the design process of the module is presented based on the mathematical analysis of the deformation. Finally, a prototype of the tensegrity robot is developed using simple and low-cost parts in less than an hour. To test the motion performance, load performance, and inspection capability of the tensegrity robot, we designed a series of experiments on horizontal pipes, vertical pipes, elbows, and steel pipes. Experimental results show that the worm-like tensegrity robot is simple in structure, easy to manufacture, low in cost, and good in performance. keywords: {Vibrations;Costs;Deformation;Prototypes;Inspection;Steel;Elbow},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341489&isnumber=10341342

J. Z. Qu, W. Z. Qu, L. Li and Y. Jia, "Reinforcement Learning Based Multi-Layer Bayesian Control for Snake Robots in Cluttered Scenes," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4702-4708, doi: 10.1109/IROS55552.2023.10342171.Abstract: The majority of current research on reinforcement learning (RL) for snake robot control do not sufficiently account for the spatial and temporal dependencies within the robot or its interaction with its environment during movement. To address this issue, we propose an RL based multi-layer Bayesian method for autonomous snake robot control, which handles challenging scenarios and improves navigation efficiency. There are three major contributions: 1) An innovative hierarchical Bayesian framework unifies gait control, locomotion control, and stimulus reaction; 2) The dynamics of environment is modeled by density propagation and exploited by an LSTM-based agent to improve the learning process; 3) A stimulus reaction model is derived by combining spatial correlation among robot modules and temporal dependency along time sequence. Comparison experiments with a simulated snake robot show that performance of the proposed approach with challenging obstacles is superior to state-of-the-art baseline. keywords: {Legged locomotion;Uncertainty;Navigation;Snake robots;Stochastic processes;Process control;Reinforcement learning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342171&isnumber=10341342

J. Han, D. Rus and S. Miyashita, "Roblets: Robotic Tablets That Self-Assemble and Self-Fold into a Robot," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4709-4714, doi: 10.1109/IROS55552.2023.10342239.Abstract: Inspired by human proteins that are synthesized from only 20 types of amino acids, the development of self-assembly methods that allow robots to be built simply by randomly stirring the parts has been explored for many years. The key challenges include how to synthesize parts in pieces into a three-dimensional functional structure in a practical time, and subsequently, achieve a controlled robotic motion, all with minimal human intervention. This study proposes a method of self-assembling a 3D robot by first self-assembling random parts into a 2D structure and then self-folding it into a 3D shape. Once self-folded, the robot, whose compositional parts contain magnets, becomes capable of performing basic tasks such as block-pushing upon an application of an external magnetic field. Self-assembly from parts into a two-dimensional structure was performed by repeatedly colliding the parts with each other, and combining them with complementary-shaped parts, like matching jigsaw puzzle pieces. Self-folding was performed by shrinking a heat-responsive film attached across the hinge of each assembly part in hot water, causing the entire 2D structure to self-fold. The experiment demonstrated a series of 13 parts self-assembling into the shape of a 3D beetle, then walking and pushing an object in 13 minutes. The self-assembly process is programmed (mechanically) to generate the same geometry even if the number of parts is greater than the necessary number for the structure, thus is capable of generating multiple structures simultaneously. keywords: {Robot motion;Proteins;Legged locomotion;Three-dimensional displays;Self-assembly;Shape;Water heating},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342239&isnumber=10341342

A. Wolek and D. A. Paley, "Output Feedback Formation Control of a School of Robotic Fish with Artificial Lateral Line Sensing," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4715-4720, doi: 10.1109/IROS55552.2023.10342055.Abstract: This paper presents an estimation and control framework to stabilize the parallel motion of a school of robotic fish using sensory feedback. Each robot is modeled as a constant speed, planar, self-propelled particle that produces a flowfield according to a dipole potential flow model. An artificial lateral line system senses pressure fluctuations at several locations along each robot's body. The equations of motion and measurement model are formulated in a path frame that translates and rotates with each robot's position and velocity, respectively. A particle filter estimates the relative position and heading of other nearby robots. The resulting estimate drives a Lyapunov-based formation controller to synchronize the headings of the robots and achieve a parallel formation. Numerical simulations illustrate the proposed approach. keywords: {Estimation;Robot sensing systems;Fish;Numerical simulation;Mathematical models;Particle filters;Numerical models},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342055&isnumber=10341342

Z. Xiong et al., "An Origami-Based Miniature Jumping Robot with Adjustable Jumping Trajectory and Enhanced Intermittent Jumps," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4721-4726, doi: 10.1109/IROS55552.2023.10342330.Abstract: A small-scale jumping robot can reach obstacles much larger than its size. It is important for a jumping robot to perform intermittent jumps to cross through rough terrains. However, the limitations of conventional structures hinder the further integration of functions to a miniature (sub-50 g) jumping robot. No sub-50 g jumpers could perform intermittent jumps with adjustable jumping trajectories. In this work, we proposed an origami-based miniature jumper, which performed intermittent jumps with adjustable omni-directional trajectories. The intermittent jumps were achieved by the jumping and self-righting mechanisms, which were actuated by a single motor. The clockwise and counterclockwise rotation of the motor actuated the loading, self-righting and triggering process, respectively. The jumping height was adjustable by adjusting the rotation angle of the motor. Meanwhile, the take-off pitch & yaw angle adjustment methods were integrated into the robot. Therefore, we demonstrated a 9 cm, 13.5 g prototype with functions of re-loading, self-righting, jumping height adjustment and take-off pitch & yaw angle adjustment. The robot could adjust jumping height from 16 to 34 cm and self-right for the next jump. The results revealed that our robot could jump across different obstacles with different scales and directions. The mobility was greatly increased compared with other miniature jumping robots. keywords: {Loading;Prototypes;Trajectory;Robots;Intelligent robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342330&isnumber=10341342

T. Schoepe and E. Chicca, "Finding the Goal: Insect-Inspired Spiking Neural Network for Heading Error Estimation," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4727-4733, doi: 10.1109/IROS55552.2023.10342210.Abstract: Insects have extraordinary navigational abilities. Monarch butterflies migrate every year to the same forest over hundreds of kilometers, desert ants find their way back to the nest tens of meters away and dung beetles maintain the same heading direction over meters. The performance of these agents has been optimized by evolution over the last 500 million years leading to power-efficient, low-latency and precise sensorimotor systems. Research efforts in the field of neuroscience, biology and robotics are instrumental for uncovering the neural substrate of insect navigation abilities. The development of models of insect navigation tightly coupled with the insect connectome and neurophysiology and their embedding in closed loop systems support the understanding of embodied animal cognition and can advance robotic systems. In this work, we focus on insect navigation because of the efficient insect navigational apparatus. Furthermore, the recent discovery of the central complex, the neuronal center of insect navigation, facilitates the development of new hypotheses about insect navigation. All navigating insects need to perform some kind of goal-directed behavior during which they have to reach a specific goal location or maintain the same movement direction over long distances. Such behavior requires the agent to be aware of its current heading direction, desired heading direction, and the error between them. Building on previous research in the field, we propose a novel model for this error estimation that can in principle be generalized for all navigating insect species. We implement the model in a spiking neural network and test its capabilities on a simulated robotic platform. The precision of the network is comparable to or even better than the biological role model. Thus, our implementation serves as a working hypothesis for how the heading error might be computed in the insect brain. Our model will help to explain navigational behavior in fruit flies, orchid bees, bumble bees and some less researched insect species. Furthermore, its simplicity in comparison to other models and implementation in a spiking neural network makes it very suitable for neuromorphic systems, an emerging field of brain-inspired hardware. keywords: {Meters;Navigation;Error analysis;Insects;Biological system modeling;Computational modeling;Brain modeling},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342210&isnumber=10341342

B. Güney and M. M. Ankaralı, "Motion Control and Planning of a Bio-Inspired Aerial Vehicle with an Actively Controlled Abdomen-Like Appendage," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4734-4741, doi: 10.1109/IROS55552.2023.10341458.Abstract: Animals' anatomies have control systems combined with multi-motors and high-bandwidth sensors. Their complicated mechanisms give them high maneuverability with sufficient inertial stabilization performance during walking, jumping, and flying. From the point of aerial locomotion, flying insects use abdomen reflexes to stabilize their head positions. Articulation of the thoracic-abdominal joint contributes to the reorientation of their bodies over the law of conservation of angular momentum. Since acceleration is a fundamental component of maneuverability, increasing the acceleration without destabilizing the body is achieved with additional appendages such as the tail and abdomen. Highly actuated abdominal muscles are an essential feature of these natural flyers, conspicuously missing from the current aerial vehicles regarding maneuverability. This study proposes a bio-inspired aerial vehicle morphology with an actively controlled abdomen-like appendage. We aim to investigate the advantages and disadvantages of the abdomen-like appendage mounted on a bi-rotor aerial vehicle by constructing the dynamical model and designing optimization-based controllers; Linear Quadratic Regulator (LQR), Model Predictive Control (MPC), and Adaptive Model Predictive Control (A-MPC). We complete our analysis with a motion planning algorithm by combining the sampling-based neighborhood graph approach with the A-MPC strategy. We demonstrate through simulation experiments that the appendage improves the stability and maneuverability of aerial vehicles and the resulting motion planning structure with A-MPC ensures that the state and input constraints are not violated. keywords: {Costs;Three-dimensional displays;Insects;Tail;Planning;Topology;Task analysis},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341458&isnumber=10341342

J. Liang, J. Buzzatto and M. Liarokapis, "A Tailsitter UAV Based on Bioinspired, Tendon-Driven, Shape-Morphing Wings with Aerofoil-Shaped Artificial Feathers," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4750-4756, doi: 10.1109/IROS55552.2023.10341538.Abstract: Unmanned aerial vehicles (UAVs) have revolutionised various industries, such as agriculture, remote sensing, and infrastructure inspection. To explore new designs and improve UAV flight performance, roboticists are seeking inspiration from nature. In this paper, we present a bioinspired tailsitter UAV utilizing shape-morphing wings with aerofoil-shaped artificial feathers. The design of the UAV is inspired by the shape and motion of bird wings, which can change their shape and span to adapt to different flight conditions. The pigeon's wing skeletal structure serves as the basis for the design, and the wing was developed to be fully tendon-driven employing a single motor for each side. The wings can contract and extend, resulting in a contraction ratio of 49% of the extended wing span. In hovering flight mode, the wing contraction shows a 42% decrease in drag for improved wind disturbance rejection. Wind tunnel testing characterises the wing's aerodynamic performance, revealing significant deflection at high angles of attack due to the articulated skeletal structure. The wings demonstrate low power consumption, averaging only 5.1 W during morphing in experiments. Finally, we demonstrate the wing's robustness through outdoor flight experiments. The research findings provide insights into the potential of bioinspired designs for tailsitter UAVs and offer a promising avenue for future research in this field. keywords: {Feathers;Solid modeling;Shape;Service robots;Wind tunnels;Autonomous aerial vehicles;Birds},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341538&isnumber=10341342

G. Manduca, G. Santaera, P. Dario, C. Stefanini and D. Romano, "How to Achieve Maneuverability and Adaptability in an Underactuated Robotic Fish by using a Bio-inspired Control Approach," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4757-4762, doi: 10.1109/IROS55552.2023.10342036.Abstract: Biomimetic robotics can help support underwater exploration and monitoring while minimizing ecosystem distur-bance. It also has potential applications in sustainable aqua-farming management, biodiversity preservation, and animal-robot interaction studies. This study proposes a bio-inspired control strategy for an underactuated robotic fish, which utilizes a single DC motor to drive a mechanism that converts the motor's oscillating motion into an oscillatory motion of the robotic fishtail through a magnetic coupling and a wire-driven system. The proposed control strategy for the robotic fish is based on central pattern generators (CPGs) and incorporates proprioceptive sensory feedback. The torque exerted on the fishtail is adjusted based on its position, allowing for increased or decreased body speed and steering with different angular speeds and radii of curvature despite the underactuated design. The robotic fish can vary the swimming speed of 0.08 body lengths per second (BL/s) with a related change in the tail-beating frequency up to 2.3 Hz, and it can vary the steering angular speed in the range of 0.08 rad/s with a relative change in the curvature radius of 0.25 m. The controller can adapt to changes in tail structure, weight, or the surrounding environment based on the proprioceptive feedback. Design changes to the modular design can improve speed and steering performances, maintaining the control strategy developed. keywords: {Bio-inspired control;Torque;Propioception;Tail;Fish;Magnetosphere;Robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342036&isnumber=10341342

G. Zhuang et al., "An Energy-Efficient Lane-Keeping System Using 3D LiDAR Based on Spiking Neural Network," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4763-4769, doi: 10.1109/IROS55552.2023.10342044.Abstract: Lane keeping, as a fundamental functionality of autonomous navigation, remains a challenging task for autonomous robots and vehicles. Recently, spiking neural networks (SNNs) have gained attention and research interest due to their biological plausibility and application potential on neuromorphic processors. SNNs have also been successfully deployed on robots to solve autonomous navigation problems. However, lane keeping with a LiDAR sensor is still an open problem for SNNs. In this work, we propose an end-to-end approach based on an SNN to solve the lane-keeping problem using a 3D LiDAR sensor. For the first time, we explore the capability of the proposed SNN controller to perceive the LiDAR input and exploit the features to perform reward-based feedback learning. To ensure the effectiveness of the controller, the proposed method is deployed and evaluated on two high-fidelity simulators. The experimental results demonstrate the high applicability and performance in different scenarios. Furthermore, experiments show that the SNN is capable of performing lane keeping in a simulated urban environment with only 18 control neurons and 32 synapse connections, producing on average only a 17cm deviation from lane center, which is 4.3 % of the lane width. keywords: {Laser radar;Three-dimensional displays;Urban areas;Robot sensing systems;Feature extraction;Task analysis;Biological neural networks},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342044&isnumber=10341342

T. Kundu and I. Saha, "Approximation Algorithms for Charging Station Placement for Mobile Robots," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4770-4776, doi: 10.1109/IROS55552.2023.10341361.Abstract: Optimal placement of charging stations in a workspace is a crucial problem to address, for efficient operation of battery-driven mobile robots. When the battery charge of a robot reaches a certain threshold, the robot must be able to reach a nearby charging station to recharge its battery. In this paper, we deal with two different versions of the optimization problem related to the optimal placement of charging stations in a robot workspace. The first problem is formulated to find an optimal number of charging stations given a battery threshold deciding the need to move to a charging station, and the second problem finds an optimal battery threshold for a given number of charging stations. Both the problems involve finding the locations of charging stations, such that from any obstacle-free location at least one charging station is reachable with at most threshold amount of battery charge remaining with the robot. In this paper, we prove these optimization problems to be NP-hard, i.e., computationally intractable. To handle intractability of the above minimization problems, we design two polynomial-time approximation algorithms to find near-optimal solutions. Our algorithms achieve significantly high scalability without compromising the quality of the solution beyond a certain factor of the optimal solution. Experimental results show that our algorithms run order-of-magnitude faster than a recently proposed Satisfiability Modulo Theory (SMT)-based approach and maintain solution quality within the theoretical bounds on the optimal solution. keywords: {NP-hard problem;Scalability;Charging stations;Approximation algorithms;Minimization;Batteries;Mobile robots},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341361&isnumber=10341342

J. Fejlek and S. Ratschan, "LQR-Trees with Sampling Based Exploration of the State Space," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4777-4782, doi: 10.1109/IROS55552.2023.10341767.Abstract: This paper introduces an extension of the LQR-tree algorithm, which is a feedback-motion-planning algorithm for stabilizing a system of ordinary differential equations from a bounded set of initial conditions to a goal. The constructed policies are represented by a tree of exemplary system trajec-tories, so called demonstrations, and linear-quadratic regulator (LQR) feedback controllers. Consequently, the crucial component of any LQR-tree algorithm is a demonstrator that provides suitable demonstrations. In previous work, such a demonstrator was given by a local trajectory optimizer. However, these require appropriate initial guesses of solutions to provide valid results, which was pointed out, but largely unresolved in previous implementations. In this paper, we augment the LQR-tree algorithm with a randomized motion-planning procedure to discover new valid demonstration candidates to initialize the demonstrator in parts of state space not yet covered by the LQR-tree. In comparison to the previous versions of the LQR-tree algorithm, the resulting exploring LQR-tree algorithm reliably synthesizes feedback control laws for a far more general set of problems. keywords: {Regulators;Heuristic algorithms;Aerospace electronics;Ordinary differential equations;Trajectory;Feedback control;Reliability},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341767&isnumber=10341342

J. McMahon, R. Parker, P. Baldoni, S. Anstee and E. Plaku, "Simultaneous Survey and Inspection with Autonomous Underwater Vehicles," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 1-7, doi: 10.1109/IROS55552.2023.10341736.Abstract: As the future of autonomous underwater vehicle (AUV) deployments tends to multi-vehicle systems, new approaches in coordination and control are needed. In this work, we consider the problem of simultaneous survey and inspection where one vehicle dynamically discovers objects while another vehicle must inspect as many of the objects as possible over the course of the mission. This requires a fully autonomous inspection vehicle, and to this end, we present a planning approach which couples sampling-based motion planning with timed roadmap constraints as well as a real-time execution framework. The methods presented address the underlying challenges that arise during simultaneous survey and inspection using AUVs, namely those of communication constraints, safety of navigation constraints, and dynamically discovered tasks. Additionally, we present field results for the simultaneous survey and inspection mission using teamed AUVs. keywords: {Surveys;Autonomous underwater vehicles;Navigation;Inspection;Real-time systems;Planning;Safety},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341736&isnumber=10341342

L. Wang, T. Niu, S. Wang, S. Wang and J. Wang, "Relative Roughness Measurement Based Real-Time Speed Planning for Autonomous Vehicles on Rugged Road," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4790-4796, doi: 10.1109/IROS55552.2023.10341375.Abstract: In order to guarantee autonomous vehicles' autonomy, mobility, and ride quality in rugged environments, a real-time speed planning method based on the time-frequency transformation of terrain characteristics is designed to achieve adaptive speed planning of autonomous vehicles in rough ground. On the one hand, the vertical profile of the lidar's point cloud data is converted from the time domain to the frequency domain in real time, and the integrated area of the sub-frequency range in the frequency domain is chosen as the relative roughness quantification value to realize the roughness quantification under various terrains. On the other hand, to model the relationship between vehicle speed and relative roughness, iterative search is utilized to create a speed and roughness model, and sliding windows are employed to update the roughness to achieve continuous mapping between speed and roughness. Ultimately, a number of tests were conducted on various rough roads using the oil exploration vehicle EV-56 as the study object. The experimental results show that the proposed method can identify the terrain roughness changes under complex terrain and change their speed within 0.2 m accuracy. keywords: {Point cloud compression;Time-frequency analysis;Roads;Oils;Real-time systems;Surface roughness;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10341375&isnumber=10341342

M. Kim, S. Shin, J. Ahn and J. Park, "Real-Time Motion Planning Framework for Autonomous Vehicles with Learned Committed Trajectory Distribution," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 4797-4803, doi: 10.1109/IROS55552.2023.10342292.Abstract: This study proposes a realtime motion planning framework that leverages the prediction of a portion of the optimal trajectory for sampling-based anytime planning algorithms. Existing algorithms predict the entire optimal path and bias random samples toward it for fast path planning. However, these algorithms may not be suitable for realtime frameworks because the bias-sampling strategy should consider the sequential nature of realtime execution. Therefore, the proposed algorithm predicts a portion of the optimal path, known as the committed trajectory, step by step as a probability distribution using a neural network. This distribution is then used in a sampling-based anytime planning algorithm as a non-stationary way of biasing random samples. The proposed algorithm can sequentially plan the near-optimal motion, al-lowing the vehicle to reach the desired goal pose in a timely and accurate manner. In various test parking scenarios, the proposed algorithm reduces the parking time by approximately 38% compared with conventional motion planning algorithms and by 10% compared with another realtime framework that biases samples toward the entire optimal trajectory. keywords: {Neural networks;Prediction algorithms;Approximation algorithms;Real-time systems;Probability distribution;Trajectory;Planning},URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10342292&isnumber=10341342

